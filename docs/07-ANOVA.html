<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.0.37">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Matthew J. C. Crump">

<title>Answering questions with data - 7&nbsp; ANOVA</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./08-RMANOVA.html" rel="next">
<link href="./06-ttests.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-79429674-3', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta property="og:title" content="Answering questions with data - 7&nbsp; ANOVA">
<meta property="og:description" content="A fun bit of stats history (Salsburg 2001). Sir Ronald Fisher invented the ANOVA, which we learn about in this section. He wanted to publish his new test in the journal Biometrika.">
<meta property="og:site-name" content="Answering questions with data">
<meta name="twitter:title" content="Answering questions with data - 7&nbsp; ANOVA">
<meta name="twitter:description" content="A free textbook teaching introductory statistics for undergraduates in psychology, including a lab manual, and course website. Licensed on CC BY SA 4.0">
<meta name="twitter:image" content="https://crumplab.com/statistics/imgs/TextbookCover.png">
<meta name="twitter:card" content="summary">
<meta name="twitter:image-height" content="1310">
<meta name="twitter:image-width" content="916">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">ANOVA</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Answering questions with data</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/CrumpLab/statistics/" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01-Science_Data.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Why Statistics?</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02-Describing_Data.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Describing Data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03-Correlation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Correlation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04-SamplesPopulations.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Probability, Sampling, and Estimation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05-Foundation_Inference.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Foundations for inference</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06-ttests.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">t-tests</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07-ANOVA.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">ANOVA</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08-RMANOVA.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Repeated Measures ANOVA</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09-FactorialANOVA.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Factorial ANOVA</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10-MixedANOVA.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">More On Factorial Designs</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11-Simulation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Simulating Data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12-Thinking.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Thinking about answering questions with data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13-Gifs.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">GIFs</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#anova-is-analysis-of-variance" id="toc-anova-is-analysis-of-variance" class="nav-link active" data-scroll-target="#anova-is-analysis-of-variance"> <span class="header-section-number">7.1</span> ANOVA is Analysis of Variance</a></li>
  <li><a href="#one-factor-anova" id="toc-one-factor-anova" class="nav-link" data-scroll-target="#one-factor-anova"> <span class="header-section-number">7.2</span> One-factor ANOVA</a>
  <ul class="collapse">
  <li><a href="#computing-the-f-value" id="toc-computing-the-f-value" class="nav-link" data-scroll-target="#computing-the-f-value"> <span class="header-section-number">7.2.1</span> Computing the <span class="math inline">\(F\)</span>-value</a></li>
  <li><a href="#ss-total" id="toc-ss-total" class="nav-link" data-scroll-target="#ss-total"> <span class="header-section-number">7.2.2</span> SS Total</a></li>
  <li><a href="#ss-effect" id="toc-ss-effect" class="nav-link" data-scroll-target="#ss-effect"> <span class="header-section-number">7.2.3</span> SS Effect</a></li>
  <li><a href="#ss-error" id="toc-ss-error" class="nav-link" data-scroll-target="#ss-error"> <span class="header-section-number">7.2.4</span> SS Error</a></li>
  <li><a href="#degrees-of-freedom" id="toc-degrees-of-freedom" class="nav-link" data-scroll-target="#degrees-of-freedom"> <span class="header-section-number">7.2.5</span> Degrees of freedom</a></li>
  <li><a href="#mean-squared-error" id="toc-mean-squared-error" class="nav-link" data-scroll-target="#mean-squared-error"> <span class="header-section-number">7.2.6</span> Mean Squared Error</a></li>
  <li><a href="#calculate-f" id="toc-calculate-f" class="nav-link" data-scroll-target="#calculate-f"> <span class="header-section-number">7.2.7</span> Calculate F</a></li>
  <li><a href="#the-anova-table" id="toc-the-anova-table" class="nav-link" data-scroll-target="#the-anova-table"> <span class="header-section-number">7.2.8</span> The ANOVA TABLE</a></li>
  </ul></li>
  <li><a href="#what-does-f-mean" id="toc-what-does-f-mean" class="nav-link" data-scroll-target="#what-does-f-mean"> <span class="header-section-number">7.3</span> What does F mean?</a>
  <ul class="collapse">
  <li><a href="#making-decisions" id="toc-making-decisions" class="nav-link" data-scroll-target="#making-decisions"> <span class="header-section-number">7.3.1</span> Making Decisions</a></li>
  <li><a href="#fs-and-means" id="toc-fs-and-means" class="nav-link" data-scroll-target="#fs-and-means"> <span class="header-section-number">7.3.2</span> Fs and means</a></li>
  </ul></li>
  <li><a href="#anova-on-real-data" id="toc-anova-on-real-data" class="nav-link" data-scroll-target="#anova-on-real-data"> <span class="header-section-number">7.4</span> ANOVA on Real Data</a>
  <ul class="collapse">
  <li><a href="#tetris-and-bad-memories" id="toc-tetris-and-bad-memories" class="nav-link" data-scroll-target="#tetris-and-bad-memories"> <span class="header-section-number">7.4.1</span> Tetris and bad memories</a></li>
  <li><a href="#comparing-means-after-the-anova" id="toc-comparing-means-after-the-anova" class="nav-link" data-scroll-target="#comparing-means-after-the-anova"> <span class="header-section-number">7.4.2</span> Comparing means after the ANOVA</a></li>
  </ul></li>
  <li><a href="#anova-summary" id="toc-anova-summary" class="nav-link" data-scroll-target="#anova-summary"> <span class="header-section-number">7.5</span> ANOVA Summary</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/CrumpLab/statistics/edit/master/07-ANOVA.qmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">ANOVA</span></h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Matthew J. C. Crump </p>
          </div>
  </div>
    
    
  </div>
  

</header>

<div class="cell" data-hash="cache/unnamed-chunk-2_97a30b4bc0dd5f946ba2425fc5d86ac1">

</div>
<p>A fun bit of stats history <span class="citation" data-cites="salsburg2001lady">(<a href="references.html#ref-salsburg2001lady" role="doc-biblioref">Salsburg 2001</a>)</span>. Sir Ronald Fisher invented the ANOVA, which we learn about in this section. He wanted to publish his new test in the journal Biometrika. The editor at the time was Karl Pearson (remember Pearson’s <span class="math inline">\(r\)</span> for correlation?). Pearson and Fisher were apparently not on good terms, they didn’t like each other. Pearson refused to publish Fisher’s new test. So, Fisher eventually published his work in the Journal of Agricultural Science. Funnily enough, the feud continued onto the next generation. Years after Fisher published his ANOVA, Karl Pearson’s son Egon Pearson, and Jersey Neyman revamped Fisher’s ideas, and re-cast them into what is commonly known as null vs.&nbsp;alternative hypothesis testing. Fisher didn’t like this very much.</p>
<p>We present the ANOVA in the Fisherian sense, and at the end describe the Neyman-Pearson approach that invokes the concept of null vs.&nbsp;alternative hypotheses.</p>
<section id="anova-is-analysis-of-variance" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="anova-is-analysis-of-variance"><span class="header-section-number">7.1</span> ANOVA is Analysis of Variance</h2>
<p>ANOVA stands for Analysis Of Variance. It is a widely used technique for assessing the likelihood that differences found between means in sample data could be produced by chance. You might be thinking, well don’t we have <span class="math inline">\(t\)</span>-tests for that? Why do we need the ANOVA, what do we get that’s new that we didn’t have before?</p>
<p>What’s new with the ANOVA, is the ability to test a wider range of means beyond just two. In all of the <span class="math inline">\(t\)</span>-test examples we were always comparing two things. For example, we might ask whether the difference between two sample means could have been produced by chance. What if our experiment had more than two conditions or groups? We would have more than 2 means. We would have one mean for each group or condition. That could be a lot depending on the experiment. How would we compare all of those means? What should we do, run a lot of <span class="math inline">\(t\)</span>-tests, comparing every possible combination of means? Actually, you could do that. Or, you could do an ANOVA.</p>
<p>In practice, we will combine both the ANOVA test and <span class="math inline">\(t\)</span>-tests when analyzing data with many sample means (from more than two groups or conditions). Just like the <span class="math inline">\(t\)</span>-test, there are different kinds of ANOVAs for different research designs. There is one for between-subjects designs, and a slightly different one for repeated measures designs. We talk about both, beginning with the ANOVA for between-subjects designs.</p>
</section>
<section id="one-factor-anova" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="one-factor-anova"><span class="header-section-number">7.2</span> One-factor ANOVA</h2>
<p>The one-factor ANOVA is sometimes also called a between-subjects ANOVA, an independent factor ANOVA, or a one-way ANOVA (which is a bit of a misnomer as we discuss later). The critical ingredient for a one-factor, between-subjects ANOVA, is that you have one independent variable, with at least two-levels. When you have one IV with two levels, you can run a <span class="math inline">\(t\)</span>-test. You can also run an ANOVA. Interestingly, they give you almost the exact same results. You will get a <span class="math inline">\(p\)</span>-value from both tests that is identical (they are really doing the same thing under the hood). The <span class="math inline">\(t\)</span>-test gives a <span class="math inline">\(t\)</span>-value as the important sample statistic. The ANOVA gives you the <span class="math inline">\(F\)</span>-value (for Fisher, the inventor of the test) as the important sample statistic. It turns out that <span class="math inline">\(t^2\)</span> equals <span class="math inline">\(F\)</span>, when there are only two groups in the design. They are the same test. Side-note, it turns out they are all related to Pearson’s r too (but we haven’t written about this relationship yet in this textbook).</p>
<p>Remember that <span class="math inline">\(t\)</span> is computed directly from the data. It’s like a mean and standard error that we measure from the sample. In fact it’s the mean difference divided by the standard error of the sample. It’s just another descriptive statistic isn’t it.</p>
<p>The same thing is true about <span class="math inline">\(F\)</span>. <span class="math inline">\(F\)</span> is computed directly from the data. In fact, the idea behind <span class="math inline">\(F\)</span> is the same basic idea that goes into making <span class="math inline">\(t\)</span>. Here is the general idea behind the formula, it is again a ratio of the effect we are measuring (in the numerator), and the variation associated with the effect (in the denominator).</p>
<p><span class="math inline">\(\text{name of statistic} = \frac{\text{measure of effect}}{\text{measure of error}}\)</span></p>
<p><span class="math inline">\(\text{F} = \frac{\text{measure of effect}}{\text{measure of error}}\)</span></p>
<p>The difference with <span class="math inline">\(F\)</span>, is that we use variances to describe both the measure of the effect and the measure of error. So, <span class="math inline">\(F\)</span> is a ratio of two variances.</p>
<p>Remember what we said about how these ratios work. When the variance associated with the effect is the same size as the variance associated with sampling error, we will get two of the same numbers, this will result in an <span class="math inline">\(F\)</span>-value of 1. When the variance due to the effect is larger than the variance associated with sampling error, then <span class="math inline">\(F\)</span> will be greater than 1. When the variance associated with the effect is smaller than the variance associated with sampling error, <span class="math inline">\(F\)</span> will be less than one.</p>
<p>Let’s rewrite in plainer English. We are talking about two concepts that we would like to measure from our data. 1) A measure of what we can explain, and 2) a measure of error, or stuff about our data we can’t explain. So, the <span class="math inline">\(F\)</span> formula looks like this:</p>
<p><span class="math inline">\(\text{F} = \frac{\text{Can Explain}}{\text{Can't Explain}}\)</span></p>
<p>When we can explain as much as we can’t explain, <span class="math inline">\(F\)</span> = 1. This isn’t that great of a situation for us to be in. It means we have a lot of uncertainty. When we can explain much more than we can’t we are doing a good job, <span class="math inline">\(F\)</span> will be greater than 1. When we can explain less than what we can’t, we really can’t explain very much, <span class="math inline">\(F\)</span> will be less than 1. That’s the concept behind making <span class="math inline">\(F\)</span>.</p>
<p>If you saw an <span class="math inline">\(F\)</span> in the wild, and it was .6. Then you would automatically know the researchers couldn’t explain much of their data. If you saw an <span class="math inline">\(F\)</span> of 5, then you would know the researchers could explain 5 times more than the couldn’t, that’s pretty good. And the point of this is to give you an intuition about the meaning of an <span class="math inline">\(F\)</span>-value, even before you know how to compute it.</p>
<section id="computing-the-f-value" class="level3" data-number="7.2.1">
<h3 data-number="7.2.1" class="anchored" data-anchor-id="computing-the-f-value"><span class="header-section-number">7.2.1</span> Computing the <span class="math inline">\(F\)</span>-value</h3>
<p>Fisher’s ANOVA is very elegant in my opinion. It starts us off with a big problem we always have with data. We have a lot of numbers, and there is a lot of variation in the numbers, what to do? Wouldn’t it be nice to split up the variation into to kinds, or sources. If we could know what parts of the variation were being caused by our experimental manipulation, and what parts were being caused by sampling error, we would be making really good progress. We would be able to know if our experimental manipulation was causing more change in the data than sampling error, or chance alone. If we could measure those two parts of the total variation, we could make a ratio, and then we would have an <span class="math inline">\(F\)</span> value. This is what the ANOVA does. It splits the total variation in the data into two parts. The formula is:</p>
<p>Total Variation = Variation due to Manipulation + Variation due to sampling error</p>
<p>This is a nice idea, but it is also vague. We haven’t specified our measure of variation. What should we use?</p>
<p>Remember the sums of squares that we used to make the variance and the standard deviation? That’s what we’ll use. Let’s take another look at the formula, using sums of squares for the measure of variation:</p>
<p><span class="math inline">\(SS_\text{total} = SS_\text{Effect} + SS_\text{Error}\)</span></p>
</section>
<section id="ss-total" class="level3" data-number="7.2.2">
<h3 data-number="7.2.2" class="anchored" data-anchor-id="ss-total"><span class="header-section-number">7.2.2</span> SS Total</h3>
<p>The total sums of squares, or <span class="math inline">\(SS\text{Total}\)</span> is a way of thinking about all of the variation in a set of data. It’s pretty straightforward to measure. No tricky business. All we do is find the difference between each score and the grand mean, then we square the differences and add them all up.</p>
<p>Let’s imagine we had some data in three groups, A, B, and C. For example, we might have 3 scores in each group. The data could look like this:</p>
<div class="cell" data-hash="cache/unnamed-chunk-3_73a7c8a36d49f04ba7ddec4836949225">
<div class="cell-output-display">

<table>
 <thead>
  <tr>
   <th style="text-align:left;"> groups </th>
   <th style="text-align:left;"> scores </th>
   <th style="text-align:left;"> diff </th>
   <th style="text-align:left;"> diff_squared </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> A </td>
   <td style="text-align:left;"> 20 </td>
   <td style="text-align:left;"> 13 </td>
   <td style="text-align:left;"> 169 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> A </td>
   <td style="text-align:left;"> 11 </td>
   <td style="text-align:left;"> 4 </td>
   <td style="text-align:left;"> 16 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> A </td>
   <td style="text-align:left;"> 2 </td>
   <td style="text-align:left;"> -5 </td>
   <td style="text-align:left;"> 25 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> B </td>
   <td style="text-align:left;"> 6 </td>
   <td style="text-align:left;"> -1 </td>
   <td style="text-align:left;"> 1 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> B </td>
   <td style="text-align:left;"> 2 </td>
   <td style="text-align:left;"> -5 </td>
   <td style="text-align:left;"> 25 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> B </td>
   <td style="text-align:left;"> 7 </td>
   <td style="text-align:left;"> 0 </td>
   <td style="text-align:left;"> 0 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> C </td>
   <td style="text-align:left;"> 2 </td>
   <td style="text-align:left;"> -5 </td>
   <td style="text-align:left;"> 25 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> C </td>
   <td style="text-align:left;"> 11 </td>
   <td style="text-align:left;"> 4 </td>
   <td style="text-align:left;"> 16 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> C </td>
   <td style="text-align:left;"> 2 </td>
   <td style="text-align:left;"> -5 </td>
   <td style="text-align:left;"> 25 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Sums </td>
   <td style="text-align:left;"> 63 </td>
   <td style="text-align:left;"> 0 </td>
   <td style="text-align:left;"> 302 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Means </td>
   <td style="text-align:left;"> 7 </td>
   <td style="text-align:left;"> 0 </td>
   <td style="text-align:left;"> 33.5555555555556 </td>
  </tr>
</tbody>
</table>

</div>
</div>
<p>The data is organized in long format, so that each row is a single score. There are three scores for the A, B, and C groups. The mean of all of the scores is called the <strong>Grand Mean</strong>. It’s calculated in the table, the Grand Mean = 7.</p>
<p>We also calculated all of the difference scores <strong>from the Grand Mean</strong>. The difference scores are in the column titled <code>diff</code>. Next, we squared the difference scores, and those are in the next column called <code>diff_squared</code>.</p>
<p>Remember, the difference scores are a way of measuring variation. They represent how far each number is from the Grand Mean. If the Grand Mean represents our best guess at summarizing the data, the difference scores represent the error between the guess and each actual data point. The only problem with the difference scores is that they sum to zero (because the mean is the balancing point in the data). So, it is convenient to square the difference scores, this turns all of them into positive numbers. The size of the squared difference scores still represents error between the mean and each score. And, the squaring operation exacerbates the differences as the error grows larger (squaring a big number makes a really big number, squaring a small number still makes a smallish number).</p>
<p>OK fine! We have the squared deviations from the grand mean, we know that they represent the error between the grand mean and each score. What next? SUM THEM UP!</p>
<p>When you add up all of the individual squared deviations (difference scores) you get the sums of squares. That’s why it’s called the sums of squares (SS).</p>
<p>Now, we have the first part of our answer:</p>
<p><span class="math inline">\(SS_\text{total} = SS_\text{Effect} + SS_\text{Error}\)</span></p>
<p><span class="math inline">\(SS_\text{total} = 302\)</span> and</p>
<p><span class="math inline">\(302 = SS_\text{Effect} + SS_\text{Error}\)</span></p>
<p>What next? If you think back to what you learned about algebra, and solving for X, you might notice that we don’t really need to find the answers to both missing parts of the equation. We only need one, and we can solve for the other. For example, if we found <span class="math inline">\(SS_\text{Effect}\)</span>, then we could solve for <span class="math inline">\(SS_\text{Error}\)</span>.</p>
</section>
<section id="ss-effect" class="level3" data-number="7.2.3">
<h3 data-number="7.2.3" class="anchored" data-anchor-id="ss-effect"><span class="header-section-number">7.2.3</span> SS Effect</h3>
<p><span class="math inline">\(SS_\text{Total}\)</span> gave us a number representing all of the change in our data, how all the scores are different from the grand mean.</p>
<p>What we want to do next is estimate how much of the total change in the data might be due to the experimental manipulation. For example, if we ran an experiment that causes causes change in the measurement, then the means for each group will be different from other. As a result, the manipulation forces change onto the numbers, and this will naturally mean that some part of the total variation in the numbers is caused by the manipulation.</p>
<p>The way to isolate the variation due to the manipulation (also called effect) is to look at the means in each group, and calculate the difference scores between each group mean and the grand mean, and then sum the squared deviations to find <span class="math inline">\(SS_\text{Effect}\)</span>.</p>
<p>Consider this table, showing the calculations for <span class="math inline">\(SS_\text{Effect}\)</span>.</p>
<div class="cell" data-hash="cache/unnamed-chunk-4_355bdac9d918acf49cf580934c732964">
<div class="cell-output-display">

<table>
 <thead>
  <tr>
   <th style="text-align:left;"> groups </th>
   <th style="text-align:left;"> scores </th>
   <th style="text-align:left;"> means </th>
   <th style="text-align:left;"> diff </th>
   <th style="text-align:left;"> diff_squared </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> A </td>
   <td style="text-align:left;"> 20 </td>
   <td style="text-align:left;"> 11 </td>
   <td style="text-align:left;"> 4 </td>
   <td style="text-align:left;"> 16 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> A </td>
   <td style="text-align:left;"> 11 </td>
   <td style="text-align:left;"> 11 </td>
   <td style="text-align:left;"> 4 </td>
   <td style="text-align:left;"> 16 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> A </td>
   <td style="text-align:left;"> 2 </td>
   <td style="text-align:left;"> 11 </td>
   <td style="text-align:left;"> 4 </td>
   <td style="text-align:left;"> 16 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> B </td>
   <td style="text-align:left;"> 6 </td>
   <td style="text-align:left;"> 5 </td>
   <td style="text-align:left;"> -2 </td>
   <td style="text-align:left;"> 4 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> B </td>
   <td style="text-align:left;"> 2 </td>
   <td style="text-align:left;"> 5 </td>
   <td style="text-align:left;"> -2 </td>
   <td style="text-align:left;"> 4 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> B </td>
   <td style="text-align:left;"> 7 </td>
   <td style="text-align:left;"> 5 </td>
   <td style="text-align:left;"> -2 </td>
   <td style="text-align:left;"> 4 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> C </td>
   <td style="text-align:left;"> 2 </td>
   <td style="text-align:left;"> 5 </td>
   <td style="text-align:left;"> -2 </td>
   <td style="text-align:left;"> 4 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> C </td>
   <td style="text-align:left;"> 11 </td>
   <td style="text-align:left;"> 5 </td>
   <td style="text-align:left;"> -2 </td>
   <td style="text-align:left;"> 4 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> C </td>
   <td style="text-align:left;"> 2 </td>
   <td style="text-align:left;"> 5 </td>
   <td style="text-align:left;"> -2 </td>
   <td style="text-align:left;"> 4 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Sums </td>
   <td style="text-align:left;"> 63 </td>
   <td style="text-align:left;"> 63 </td>
   <td style="text-align:left;"> 0 </td>
   <td style="text-align:left;"> 72 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Means </td>
   <td style="text-align:left;"> 7 </td>
   <td style="text-align:left;"> 7 </td>
   <td style="text-align:left;"> 0 </td>
   <td style="text-align:left;"> 8 </td>
  </tr>
</tbody>
</table>

</div>
</div>
<p>Notice we created a new column called <code>means</code>. For example, the mean for group A was 11. You can see there are three 11s, one for each observation in row A. The means for group B and C happen to both be 5. So, the rest of the numbers in the means column are 5s.</p>
<p>What we are doing here is thinking of each score in the data from the viewpoint of the group means. The group means are our best attempt to summarize the data in those groups. From the point of view of the mean, all of the numbers are treated as the same. The mean doesn’t know how far off it is from each score, it just knows that all of the scores are centered on the mean.</p>
<blockquote class="blockquote">
<p>Let’s pretend you are the mean for group A. That means you are an 11. Someone asks you “hey, what’s the score for the first data point in group A?”. Because you are the mean, you say, I know that, it’s 11. “What about the second score?”…it’s 11… they’re all 11, so far as I can tell…“Am I missing something…”, asked the mean.</p>
</blockquote>
<p>Now that we have converted each score to it’s mean value we can find the differences between each mean score and the grand mean, then square them, then sum them up. We did that, and found that the <span class="math inline">\(SS_\text{Effect} = 72\)</span>.</p>
<p><span class="math inline">\(SS_\text{Effect}\)</span> represents the amount of variation that is caused by differences between the means. I also refer to this as the amount of variation that the researcher can explain (by the means, which represent differences between groups or conditions that were manipulated by the researcher).</p>
<p>Notice also that <span class="math inline">\(SS_\text{Effect} = 72\)</span>, and that 72 is smaller than <span class="math inline">\(SS_\text{total} = 302\)</span>. That is very important. <span class="math inline">\(SS_\text{Effect}\)</span> by definition can never be larger than <span class="math inline">\(SS_\text{total}\)</span>.</p>
</section>
<section id="ss-error" class="level3" data-number="7.2.4">
<h3 data-number="7.2.4" class="anchored" data-anchor-id="ss-error"><span class="header-section-number">7.2.4</span> SS Error</h3>
<p>Great, we made it to SS Error. We already found SS Total, and SS Effect, so now we can solve for SS Error just like this:</p>
<p><span class="math inline">\(SS_\text{total} = SS_\text{Effect} + SS_\text{Error}\)</span></p>
<p>switching around:</p>
<p>$ SS_ = SS_ - SS_ $</p>
<p>$ SS_ = 302 - 72 = 230 $</p>
<p>We could stop here and show you the rest of the ANOVA, we’re almost there. But, the next step might not make sense unless we show you how to calculate <span class="math inline">\(SS_\text{Error}\)</span> directly from the data, rather than just solving for it. We should do this just to double-check our work anyway.</p>
<div class="cell" data-hash="cache/unnamed-chunk-5_4880fca216e9168122a12f10643370e7">
<div class="cell-output-display">

<table>
 <thead>
  <tr>
   <th style="text-align:left;"> groups </th>
   <th style="text-align:left;"> scores </th>
   <th style="text-align:left;"> means </th>
   <th style="text-align:left;"> diff </th>
   <th style="text-align:left;"> diff_squared </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> A </td>
   <td style="text-align:left;"> 20 </td>
   <td style="text-align:left;"> 11 </td>
   <td style="text-align:left;"> -9 </td>
   <td style="text-align:left;"> 81 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> A </td>
   <td style="text-align:left;"> 11 </td>
   <td style="text-align:left;"> 11 </td>
   <td style="text-align:left;"> 0 </td>
   <td style="text-align:left;"> 0 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> A </td>
   <td style="text-align:left;"> 2 </td>
   <td style="text-align:left;"> 11 </td>
   <td style="text-align:left;"> 9 </td>
   <td style="text-align:left;"> 81 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> B </td>
   <td style="text-align:left;"> 6 </td>
   <td style="text-align:left;"> 5 </td>
   <td style="text-align:left;"> -1 </td>
   <td style="text-align:left;"> 1 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> B </td>
   <td style="text-align:left;"> 2 </td>
   <td style="text-align:left;"> 5 </td>
   <td style="text-align:left;"> 3 </td>
   <td style="text-align:left;"> 9 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> B </td>
   <td style="text-align:left;"> 7 </td>
   <td style="text-align:left;"> 5 </td>
   <td style="text-align:left;"> -2 </td>
   <td style="text-align:left;"> 4 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> C </td>
   <td style="text-align:left;"> 2 </td>
   <td style="text-align:left;"> 5 </td>
   <td style="text-align:left;"> 3 </td>
   <td style="text-align:left;"> 9 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> C </td>
   <td style="text-align:left;"> 11 </td>
   <td style="text-align:left;"> 5 </td>
   <td style="text-align:left;"> -6 </td>
   <td style="text-align:left;"> 36 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> C </td>
   <td style="text-align:left;"> 2 </td>
   <td style="text-align:left;"> 5 </td>
   <td style="text-align:left;"> 3 </td>
   <td style="text-align:left;"> 9 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Sums </td>
   <td style="text-align:left;"> 63 </td>
   <td style="text-align:left;"> 63 </td>
   <td style="text-align:left;"> 0 </td>
   <td style="text-align:left;"> 230 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Means </td>
   <td style="text-align:left;"> 7 </td>
   <td style="text-align:left;"> 7 </td>
   <td style="text-align:left;"> 0 </td>
   <td style="text-align:left;"> 25.5555555555556 </td>
  </tr>
</tbody>
</table>

</div>
</div>
<p>Alright, we did almost the same thing as we did to find <span class="math inline">\(SS_\text{Effect}\)</span>. Can you spot the difference? This time for each score we first found the group mean, then we found the error in the group mean estimate for each score. In other words, the values in the <span class="math inline">\(diff\)</span> column are the differences between each score and it’s group mean. The values in the <code>diff_squared</code> column are the squared deviations. When we sum up the squared deviations, we get another Sums of Squares, this time it’s the <span class="math inline">\(SS_\text{Error}\)</span>. This is an appropriate name, because these deviations are the ones that the group means can’t explain!</p>
</section>
<section id="degrees-of-freedom" class="level3" data-number="7.2.5">
<h3 data-number="7.2.5" class="anchored" data-anchor-id="degrees-of-freedom"><span class="header-section-number">7.2.5</span> Degrees of freedom</h3>
<p>Degrees of freedom come into play again with ANOVA. This time, their purpose is a little bit more clear. <span class="math inline">\(Df\)</span>s can be fairly simple when we are doing a relatively simple ANOVA like this one, but they can become complicated when designs get more complicated.</p>
<p>Let’s talk about the degrees of freedom for the <span class="math inline">\(SS_\text{Effect}\)</span> and <span class="math inline">\(SS_\text{Error}\)</span>.</p>
<p>The formula for the degrees of freedom for <span class="math inline">\(SS_\text{Effect}\)</span> is</p>
<p><span class="math inline">\(df_\text{Effect} = \text{Groups} -1\)</span>, where Groups is the number of groups in the design.</p>
<p>In our example, there are 3 groups, so the df is 3-1 = 2. You can think of the df for the effect this way. When we estimate the grand mean (the overall mean), we are taking away a degree of freedom for the group means. Two of the group means can be anything they want (they have complete freedom), but in order for all three to be consistent with the Grand Mean, the last group mean has to be fixed.</p>
<p>The formula for the degrees of freedom for <span class="math inline">\(SS_\text{Error}\)</span> is</p>
<p><span class="math inline">\(df_\text{Error} = \text{scores} - \text{groups}\)</span>, or the number of scores minus the number of groups. We have 9 scores and 3 groups, so our <span class="math inline">\(df\)</span> for the error term is 9-3 = 6. Remember, when we computed the difference score between each score and its group mean, we had to compute three means (one for each group) to do that. So, that reduces the degrees of freedom by 3. 6 of the difference scores could be anything they want, but the last 3 have to be fixed to match the means from the groups.</p>
</section>
<section id="mean-squared-error" class="level3" data-number="7.2.6">
<h3 data-number="7.2.6" class="anchored" data-anchor-id="mean-squared-error"><span class="header-section-number">7.2.6</span> Mean Squared Error</h3>
<p>OK, so we have the degrees of freedom. What’s next? There are two steps left. First we divide the <span class="math inline">\(SS\)</span>es by their respective degrees of freedom to create something new called Mean Squared Error. Let’s talk about why we do this.</p>
<p>First of all, remember we are trying to accomplish this goal:</p>
<p><span class="math inline">\(\text{F} = \frac{\text{measure of effect}}{\text{measure of error}}\)</span></p>
<p>We want to build a ratio that divides a measure of an effect by a measure of error. Perhaps you noticed that we already have a measure of an effect and error! How about the <span class="math inline">\(SS_\text{Effect}\)</span> and <span class="math inline">\(SS_\text{Error}\)</span>. They both represent the variation due to the effect, and the leftover variation that is unexplained. Why don’t we just do this?</p>
<p><span class="math inline">\(\frac{SS_\text{Effect}}{SS_\text{Error}}\)</span></p>
<p>Well, of course you could do that. What would happen is you can get some really big and small numbers for your inferential statistic. And, the kind of number you would get wouldn’t be readily interpretable like a <span class="math inline">\(t\)</span> value or a <span class="math inline">\(z\)</span> score.</p>
<p>The solution is to <strong>normalize</strong> the <span class="math inline">\(SS\)</span> terms. Don’t worry, normalize is just a fancy word for taking the average, or finding the mean. Remember, the SS terms are all sums. And, each sum represents a different number of underlying properties.</p>
<p>For example, the SS_ represents the sum of variation for three means in our study. We might ask the question, well, what is the average amount of variation for each mean…You might think to divide SS_ by 3, because there are three means, but because we are estimating this property, we divide by the degrees of freedom instead (# groups - 1 = 3-1 = 2). Now we have created something new, it’s called the <span class="math inline">\(MSE_\text{Effect}\)</span>.</p>
<p><span class="math inline">\(MSE_\text{Effect} = \frac{SS_\text{Effect}}{df_\text{Effect}}\)</span></p>
<p><span class="math inline">\(MSE_\text{Effect} = \frac{72}{2} = 36\)</span></p>
<p>This might look alien and seem a bit complicated. But, it’s just another mean. It’s the mean of the sums of squares for the effect. If this reminds you of the formula for the variance, good memory. The <span class="math inline">\(SME_\text{Effect}\)</span> is a measure variance for the change in the data due to changes in the means (which are tied to the experimental conditions).</p>
<p>The <span class="math inline">\(SS_\text{Error}\)</span> represents the sum of variation for nine scores in our study. That’s a lot more scores, so the <span class="math inline">\(SS_\text{Error}\)</span> is often way bigger than than <span class="math inline">\(SS_\text{Effect}\)</span>. If we left our SSes this way and divided them, we would almost always get numbers less than one, because the <span class="math inline">\(SS_\text{Error}\)</span> is so big. What we need to do is bring it down to the average size. So, we might want to divide our <span class="math inline">\(SS_\text{Error}\)</span> by 9, after all there were nine scores. However, because we are estimating this property, we divide by the degrees of freedom instead (scores-groups) = 9-3 = 6). Now we have created something new, it’s called the <span class="math inline">\(MSE_\text{Error}\)</span>.</p>
<p><span class="math inline">\(MSE_\text{Error} = \frac{SS_\text{Error}}{df_\text{Error}}\)</span></p>
<p><span class="math inline">\(MSE_\text{Error} = \frac{230}{6} = 38.33\)</span></p>
</section>
<section id="calculate-f" class="level3" data-number="7.2.7">
<h3 data-number="7.2.7" class="anchored" data-anchor-id="calculate-f"><span class="header-section-number">7.2.7</span> Calculate F</h3>
<p>Now that we have done all of the hard work, calculating <span class="math inline">\(F\)</span> is easy:</p>
<p><span class="math inline">\(\text{F} = \frac{\text{measure of effect}}{\text{measure of error}}\)</span></p>
<p><span class="math inline">\(\text{F} = \frac{MSE_\text{Effect}}{MSE_\text{Error}}\)</span></p>
<p><span class="math inline">\(\text{F} = \frac{36}{38.33} = .939\)</span></p>
<p>Done!</p>
</section>
<section id="the-anova-table" class="level3" data-number="7.2.8">
<h3 data-number="7.2.8" class="anchored" data-anchor-id="the-anova-table"><span class="header-section-number">7.2.8</span> The ANOVA TABLE</h3>
<p>You might suspect we aren’t totally done here. We’ve walked through the steps of computing <span class="math inline">\(F\)</span>. Remember, <span class="math inline">\(F\)</span> is a sample statistic, we computed <span class="math inline">\(F\)</span> directly from the data. There were a whole bunch of pieces we needed, the dfs, the SSes, the MSEs, and then finally the F.</p>
<p>All of these little pieces are conveniently organized by ANOVA tables. ANOVA tables look like this:</p>
<div class="cell" data-hash="cache/unnamed-chunk-6_3f1934219e51e31f785262657cf01f9c">
<div class="cell-output-display">

<table>
 <thead>
  <tr>
   <th style="text-align:left;">   </th>
   <th style="text-align:right;"> Df </th>
   <th style="text-align:right;"> Sum Sq </th>
   <th style="text-align:right;"> Mean Sq </th>
   <th style="text-align:right;"> F value </th>
   <th style="text-align:right;"> Pr(&gt;F) </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> groups </td>
   <td style="text-align:right;"> 2 </td>
   <td style="text-align:right;"> 72 </td>
   <td style="text-align:right;"> 36.00000 </td>
   <td style="text-align:right;"> 0.9391304 </td>
   <td style="text-align:right;"> 0.4417359 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Residuals </td>
   <td style="text-align:right;"> 6 </td>
   <td style="text-align:right;"> 230 </td>
   <td style="text-align:right;"> 38.33333 </td>
   <td style="text-align:right;"> NA </td>
   <td style="text-align:right;"> NA </td>
  </tr>
</tbody>
</table>

</div>
</div>
<p>You are looking at the print-out of an ANOVA summary table from R. Notice, it had columns for <span class="math inline">\(Df\)</span>, <span class="math inline">\(SS\)</span> (Sum Sq), <span class="math inline">\(MSE\)</span> (Mean Sq), <span class="math inline">\(F\)</span>, and a <span class="math inline">\(p\)</span>-value. There are two rows. The <code>groups</code> row is for the Effect (what our means can explain). The <code>Residuals</code> row is for the Error (what our means can’t explain). Different programs give slightly different labels, but they are all attempting to present the same information in the ANOVA table. There isn’t anything special about the ANOVA table, it’s just a way of organizing all the pieces. Notice, the MSE for the effect (36) is placed above the MSE for the error (38.333), and this seems natural because we divide 36/38.33 in or to get the <span class="math inline">\(F\)</span>-value!</p>
</section>
</section>
<section id="what-does-f-mean" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="what-does-f-mean"><span class="header-section-number">7.3</span> What does F mean?</h2>
<p>We’ve just noted that the ANOVA has a bunch of numbers that we calculated straight from the data. All except one, the <span class="math inline">\(p\)</span>-value. We did not calculate the <span class="math inline">\(p\)</span>-value from the data. Where did it come from, what does it mean? How do we use this for statistical inference. Just so you don’t get too worried, the <span class="math inline">\(p\)</span>-value for the ANOVA has the very same general meaning as the <span class="math inline">\(p\)</span>-value for the <span class="math inline">\(t\)</span>-test, or the <span class="math inline">\(p\)</span>-value for any sample statistic. It tells us that the probability that we would observe our test statistic or larger, under the distribution of no differences (the null).</p>
<p>As we keep saying, <span class="math inline">\(F\)</span> is a sample statistic. Can you guess what we do with sample statistics in this textbook? We did it for the Crump Test, the Randomization Test, and the <span class="math inline">\(t\)</span>-test… We make fake data, we simulate it, we compute the sample statistic we are interested in, then we see how it behaves over many replications or simulations.</p>
<p>Let’s do that for <span class="math inline">\(F\)</span>. This will help you understand what <span class="math inline">\(F\)</span> really is, and how it behaves. We are going to created the sampling distribution of <span class="math inline">\(F\)</span>. Once we have that you will be able to see where the <span class="math inline">\(p\)</span>-values come from. It’s the same basic process that we followed for the <span class="math inline">\(t\)</span> tests, except we are measuring <span class="math inline">\(F\)</span> instead of <span class="math inline">\(t\)</span>.</p>
<p>Here is the set-up, we are going to run an experiment with three levels. In our imaginary experiment we are going to test whether a new magic pill can make you smarter. The independent variable is the number of magic pills you take: 1, 2, or 3. We will measure your smartness using a smartness test. We will assume the smartness test has some known properties, the mean score on the test is 100, with a standard deviation of 10 (and the distribution is normal).</p>
<p>The only catch is that our magic pill does NOTHING AT ALL. The fake people in our fake experiment will all take sugar pills that do absolutely nothing to their smartness. Why would we want to simulate such a bunch of nonsense? The answer is that this kind of simulation is critical for making inferences about chance if you were to conduct a real experiment.</p>
<p>Here are some more details for the experiment. Each group will have 10 different subjects, so there will be a total of 30 subjects. We are going to run this experiment 10,000 times. Each time drawing numbers randomly from the very same normal distribution. We are going to calculate <span class="math inline">\(F\)</span> from our sample data every time, and then we are going to draw the histogram of <span class="math inline">\(F\)</span>-values. <a href="#fig-7fnull">Figure&nbsp;<span>7.1</span></a> shows the sampling distribution of <span class="math inline">\(F\)</span> for our situation.</p>
<div class="cell" data-fig.asp="0.5" data-hash="cache/fig-7fnull_c5cbda23c04afb57d14f2be09a2c36d5">
<div class="cell-output-display">
<div id="fig-7fnull" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="07-ANOVA_files/figure-html/fig-7fnull-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Figure 7.1: A simulation of 10,000 experiments from a null distribution where there is no differences. The histogram shows 10,000 <span class="math inline">\(F\)</span>-values, one for each simulation. These are values that F can take in this situation. All of these <span class="math inline">\(F\)</span>-values were produced by random sampling error.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Let’s note a couple things about the <span class="math inline">\(F\)</span> distribution. 1) The smallest value is 0, and there are no negative values. Does this make sense? <span class="math inline">\(F\)</span> can never be negative because it is the ratio of two variances, and variances are always positive because of the squaring operation. So, yes, it makes sense that the sampling distribution of <span class="math inline">\(F\)</span> is always 0 or greater. 2) it does not look normal. No it does not. <span class="math inline">\(F\)</span> can have many different looking shapes, depending on the degrees of freedom in the numerator and denominator. However, these aspects are too important for now.</p>
<p>Remember, before we talked about some intuitive ideas for understanding <span class="math inline">\(F\)</span>, based on the idea that <span class="math inline">\(F\)</span> is a ratio of what we can explain (variance due to mean differences), divided by what we can’t explain (the error variance). When the error variance is higher than the effect variance, then we will always get an <span class="math inline">\(F\)</span>-value less than one. You can see that we often got <span class="math inline">\(F\)</span>-values less than one in the simulation. This is sensible, after all we were simulating samples coming from the very same distribution. On average there should be no differences between the means. So, on average the part of the total variance that is explained by the means should be less than one, or around one, because it should be roughly the same as the amount of error variance (remember, we are simulating no differences).</p>
<p>At the same time, we do see that some <span class="math inline">\(F\)</span>-values are larger than 1. There are little bars that we can see going all the way up to about 5. If you were to get an <span class="math inline">\(F\)</span>-value of 5, you might automatically think, that’s a pretty big <span class="math inline">\(F\)</span>-value. Indeed it kind of is, it means that you can explain 5 times more of variance than you can’t explain. That seems like a lot. You can also see that larger <span class="math inline">\(F\)</span>-values don’t occur very often. As a final reminder, what you are looking at is how the <span class="math inline">\(F\)</span>-statistic (measured from each of 10,000 simulated experiments) behaves when the only thing that can cause differences in the means is random sampling error. Just by chance sometimes the means will be different. You are looking at another chance window. These are the <span class="math inline">\(F\)</span>s that chance can produce.</p>
<section id="making-decisions" class="level3" data-number="7.3.1">
<h3 data-number="7.3.1" class="anchored" data-anchor-id="making-decisions"><span class="header-section-number">7.3.1</span> Making Decisions</h3>
<p>We can use the sampling distribution of <span class="math inline">\(F\)</span> (for the null) to make decisions about the role of chance in a real experiment. For example, we could do the following.</p>
<ol type="1">
<li>Set an alpha criterion of <span class="math inline">\(p\)</span> = 0.05</li>
<li>Find out the critical value for <span class="math inline">\(F\)</span>, for our particular situation (with our <span class="math inline">\(df\)</span>s for the numerator and denominator).</li>
</ol>
<p>Let’s do that. I’ve drawn the line for the critical value onto the histogram in <a href="#fig-7criticalF">Figure&nbsp;<span>7.2</span></a>:</p>
<div class="cell" data-fig.asp="0.5" data-hash="cache/fig-7criticalF_5f7a63c93fd22e6459447703607766b7">
<div class="cell-output-display">
<div id="fig-7criticalF" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="07-ANOVA_files/figure-html/fig-7criticalF-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Figure 7.2: The critical value for <span class="math inline">\(F\)</span> where 5% of all <span class="math inline">\(F\)</span>-values lie beyond this point</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Alright, now we can see that only 5% of all <span class="math inline">\(F\)</span>-values from from this sampling distribution will be 3.35 or larger. We can use this information.</p>
<p>How would we use it? Imagine we ran a real version of this experiment. And, we really used some pills that just might change smartness. If we ran the exact same design, with 30 people in total (10 in each group), we could set an <span class="math inline">\(F\)</span> criterion of 3.35 for determining whether any of our results reflected a causal change in smartness due to the pills, and not due to random chance. For example, if we found an <span class="math inline">\(F\)</span>-value of 3.34, which happens, just less than 5% of the time, we might conclude that random sampling error did not produce the differences between our means. Instead, we might be more confident that the pills actually did something, after all an <span class="math inline">\(F\)</span>-value of 3.34 doesn’t happen very often, it is unlikely (only 5 times out of 100) to occur by chance.</p>
</section>
<section id="fs-and-means" class="level3" data-number="7.3.2">
<h3 data-number="7.3.2" class="anchored" data-anchor-id="fs-and-means"><span class="header-section-number">7.3.2</span> Fs and means</h3>
<p>Up to here we have been building your intuition for understanding <span class="math inline">\(F\)</span>. We went through the calculation of <span class="math inline">\(F\)</span> from sample data. We went through the process of simulating thousands of <span class="math inline">\(F\)</span>s to show you the null distribution. We have not talked so much about what researchers really care about…The MEANS! The actual results from the experiment. Were the means different? that’s often what people want to know. So, now we will talk about the means, and <span class="math inline">\(F\)</span>, together.</p>
<p>Notice, if I told you I ran an experiment with three groups, testing whether some manipulation changes the behavior of the groups, and I told you that I found a big <span class="math inline">\(F\)</span>!, say an <span class="math inline">\(F\)</span> of 6!. And, that the <span class="math inline">\(F\)</span> of 6 had a <span class="math inline">\(p\)</span>-value of .001. What would you know based on that information alone? You would only know that Fs of 6 don’t happen very often by chance. In fact they only happen 0.1% of the time, that’s hardly at all. If someone told me those values, I would believe that the results they found in their experiment were not likely due to chance. However, I still would not know what the results of the experiment were! Nobody told us what the means were in the different groups, we don’t know what happened!</p>
<p>IMPORTANT: even though we don’t know what the means were, we do know something about them, whenever we get <span class="math inline">\(F\)</span>-values and <span class="math inline">\(p\)</span>-values like that (big <span class="math inline">\(F\)</span>s, and very small associated <span class="math inline">\(p\)</span>s)… Can you guess what we know? I’ll tell you. We automatically know that there <strong>must have been some differences between the means</strong>. If there was no differences between the means, then the variance explained by the means (the numerator for <span class="math inline">\(F\)</span>) would not be very large. So, we know that there must be some differences, we just don’t know what they are. Of course, if we had the data, all we would need to do is look at the means for the groups (the ANOVA table doesn’t report this, we need to do it as a separate step).</p>
<section id="anova-is-an-omnibus-test" class="level4" data-number="7.3.2.1">
<h4 data-number="7.3.2.1" class="anchored" data-anchor-id="anova-is-an-omnibus-test"><span class="header-section-number">7.3.2.1</span> ANOVA is an omnibus test</h4>
<p>This property of the ANOVA is why the ANOVA is sometimes called the <strong>omnibus test</strong>. Omnibus is a fun word, it sounds like a bus I’d like to ride. The meaning of omnibus, according to the dictionary, is “comprising several items”. The ANOVA is, in a way, one omnibus test, comprising several little tests.</p>
<p>For example, if you had three groups, A, B, and C. You get could differences between</p>
<ol type="1">
<li>A and B</li>
<li>B and C</li>
<li>A and C</li>
</ol>
<p>That’s three possible differences you could get. You could run separate <span class="math inline">\(t\)</span>-tests, to test whether each of those differences you might have found could have been produced by chance. Or, you could run an ANOVA, like what we have been doing, to ask one more general question about the differences. Here is one way to think about what the omnibus test is testing:</p>
<p>Hypothesis of no differences anywhere: $ A = B = C $</p>
<p>Any differences anywhere:</p>
<ol type="a">
<li>$ A B = C $</li>
<li>$ A = B C $</li>
<li>$ A C = B $</li>
</ol>
<p>The <span class="math inline">\(\neq\)</span> symbol means “does not equal”, it’s an equal sign with a cross through it (no equals allowed!).</p>
<p>How do we put all of this together. Generally, when we get a small <span class="math inline">\(F\)</span>-value, with a large <span class="math inline">\(p\)</span>-value, we will not reject the hypothesis of no differences. We will say that we do not have evidence that the means of the three groups are in any way different, and the differences that are there could easily have been produced by chance. When we get a large F with a small <span class="math inline">\(p\)</span>-value (one that is below our alpha criterion), we will generally reject the hypothesis of no differences. We would then assume that at least one group mean is not equal to one of the others. That is the omnibus test. Rejecting the null in this way is rejecting the idea there are no differences. But, the <span class="math inline">\(F\)</span> test still does not tell you which of the possible group differences are the ones that are different.</p>
</section>
<section id="looking-at-a-bunch-of-group-means" class="level4" data-number="7.3.2.2">
<h4 data-number="7.3.2.2" class="anchored" data-anchor-id="looking-at-a-bunch-of-group-means"><span class="header-section-number">7.3.2.2</span> Looking at a bunch of group means</h4>
<p>We just ran 10,000 experiments and we didn’t even once look at the group means for any of the experiments. Different patterns of group means under the null are shown in <a href="#fig-7manyDiffs">Figure&nbsp;<span>7.3</span></a> for a subset of 10 random simulations.</p>
<div class="cell" data-hash="cache/fig-7manyDiffs_0d839405e3af0781397a0fb5f7a301b4">
<div class="cell-output-display">
<div id="fig-7manyDiffs" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="07-ANOVA_files/figure-html/fig-7manyDiffs-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Figure 7.3: Different patterns of group means under the null (all scores for each group sampled from the same distribution).</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Whoa, that’s a lot to look at. What is going on here? Each little box represents the outcome of a simulated experiment. The dots are the means for each group (whether subjects took 1 , 2, or 3 magic pills). The y-axis shows the mean smartness for each group. The error bars are standard errors of the mean.</p>
<p>You can see that each of the 10 experiments turn out different. Remember, we sampled 10 numbers for each group from the <strong>same</strong> normal distribution with mean = 100, and sd = 10. So, we know that the <strong>correct</strong> means for each sample should actually be 100 every single time. However, they are not 100 every single time because of?…<strong>sampling error</strong> (Our good friend that we talk about all the time).</p>
<p>For most of the simulations the error bars are all overlapping, this suggests visually that the means are not different. However, some of them look like they are not overlapping so much, and this would suggest that they are different. This is the siren song of chance (sirens lured sailors to their deaths at sea…beware of the siren call of chance). If we concluded that any of these sets of means had a true difference, we would be committing a type I error. Because we made the simulation, we know that none of these means are actually different. But, when you are running a real experiment, you don’t get to know this for sure.</p>
</section>
<section id="looking-at-bar-graphs" class="level4" data-number="7.3.2.3">
<h4 data-number="7.3.2.3" class="anchored" data-anchor-id="looking-at-bar-graphs"><span class="header-section-number">7.3.2.3</span> Looking at bar graphs</h4>
<p>Let’s look at the exact same graph as above, but this time use bars to visually illustrate the means, instead of dots. We’ll re-do our simulation of 10 experiments, so the pattern will be a little bit different:</p>
<div class="cell" data-hash="cache/fig-7manyDiffsBar_14ea857d9c6838b90fc8c2b26b85d3a8">
<div class="cell-output-display">
<div id="fig-7manyDiffsBar" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="07-ANOVA_files/figure-html/fig-7manyDiffsBar-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Figure 7.4: Different patterns of group means under the null (all scores for each group sampled from the same distribution).</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>In <a href="#fig-7manyDiffsBar">Figure&nbsp;<span>7.4</span></a> the heights of the bars display the means for each pill group. The pattern across simulations is generally the same. Some of the fake experiments look like there might be differences, and some of them don’t.</p>
</section>
<section id="what-mean-differences-look-like-when-f-is-less-than-1" class="level4" data-number="7.3.2.4">
<h4 data-number="7.3.2.4" class="anchored" data-anchor-id="what-mean-differences-look-like-when-f-is-less-than-1"><span class="header-section-number">7.3.2.4</span> What mean differences look like when <span class="math inline">\(F\)</span> is less than 1</h4>
<p>We are now giving you some visual experience looking at what means look like from a particular experiment. This is for your stats intuition. We’re trying to improve your data senses.</p>
<p>What we are going to do now is similar to what we did before. Except this time we are going to look at 10 simulated experiments, where all of the <span class="math inline">\(F\)</span>-values were less than 1. All of these <span class="math inline">\(F\)</span>-values would also be associated with fairly large <span class="math inline">\(p\)</span>-values. When F is less than one, we would not reject the hypothesis of no differences. So, when we look at patterns of means when F is less than 1, we should see mostly the same means, and no big differences.</p>
<div class="cell" data-hash="cache/fig-7flesshthanone_acfd9cc8222382312457db8c9f1ed0ca">
<div class="cell-output-display">
<div id="fig-7flesshthanone" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="07-ANOVA_files/figure-html/fig-7flesshthanone-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Figure 7.5: Different patterns of group means under the null (sampled from same distribution) when F is less than 1.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>In <a href="#fig-7flesshthanone">Figure&nbsp;<span>7.5</span></a> the numbers in the panels now tell us which simulations actually produced <span class="math inline">\(F\)</span>s of less than 1.</p>
<p>We see here that all the bars aren’t perfectly flat, that’s OK. What’s more important is that for each panel, the error bars for each mean are totally overlapping with all the other error bars. We can see visually that our estimate of the mean for each sample is about the same for all of the bars. That’s good, we wouldn’t make any type I errors here.</p>
</section>
<section id="what-mean-differences-look-like-when-f-3.35" class="level4" data-number="7.3.2.5">
<h4 data-number="7.3.2.5" class="anchored" data-anchor-id="what-mean-differences-look-like-when-f-3.35"><span class="header-section-number">7.3.2.5</span> What mean differences look like when F &gt; 3.35</h4>
<p>Earlier we found that the critical value for <span class="math inline">\(F\)</span> in our situation was 3.35, this was the location on the <span class="math inline">\(F\)</span> distribution where only 5% of <span class="math inline">\(F\)</span>s were 3.35 or greater. We would reject the hypothesis of no differences whenever <span class="math inline">\(F\)</span> was greater than 3.35. In this case, whenever we did that, we would be making a type I error. That is because we are simulating the distribution of no differences (remember all of our sample means are coming from the exact same distribution). So, now we can take a look at what type I errors look like. In other words, we can run some simulations and look at the pattern in the means, only when <span class="math inline">\(F\)</span> happens to be 3.35 or greater (this only happens 5% of the time, so we might have to let the computer simulate for a while). Let’s see what that looks like:</p>
<div class="cell" data-hash="cache/fig-7sigdiffs_87604522ae58632d347408fe597696db">
<div class="cell-output-display">
<div id="fig-7sigdiffs" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="07-ANOVA_files/figure-html/fig-7sigdiffs-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Figure 7.6: Different patterns of group means under the null when F is above critical value (these are all type I Errors).</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The numbers in the panels now tell us which simulations actually produced <span class="math inline">\(F\)</span>s that were greater than 3.35</p>
<p>What do you notice about the pattern of means inside each panel of <a href="#fig-7sigdiffs">Figure&nbsp;<span>7.6</span></a>? Now, every the panels show at least one mean that is different from the others. Specifically, the error bars for one mean do not overlap with the error bars for one or another mean. This is what mistakes looks like. These are all type I errors. They are insidious. When they happen to you by chance, the data really does appear to show a strong pattern, your <span class="math inline">\(F\)</span>-value is large, and your <span class="math inline">\(p\)</span>-value is small! It is easy to be convinced by a type I error (it’s the siren song of chance).</p>
</section>
</section>
</section>
<section id="anova-on-real-data" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="anova-on-real-data"><span class="header-section-number">7.4</span> ANOVA on Real Data</h2>
<p>We’ve covered many fundamentals about the ANOVA, how to calculate the necessary values to obtain an <span class="math inline">\(F\)</span>-statistic, and how to interpret the <span class="math inline">\(F\)</span>-statistic along with it’s associate <span class="math inline">\(p\)</span>-value once we have one. In general, you will be conducting ANOVAs and playing with <span class="math inline">\(F\)</span>s and <span class="math inline">\(p\)</span>s using software that will automatically spit out the numbers for you. It’s important that you understand what the numbers mean, that’s why we’ve spent time on the concepts. We also recommend that you try to compute an ANOVA by hand at least once. It builds character, and let’s you know that you know what you are doing with the numbers.</p>
<p>But, we’ve probably also lost the real thread of all this. The core thread is that when we run an experiment we use our inferential statistics, like ANOVA, to help us determine whether the differences we found are likely due to chance or not. In general, we like to find out that the differences that we find are not due to chance, but instead to due to our manipulation.</p>
<p>So, we return to the application of the ANOVA to a real data set with a real question. This is the same one that you will be learning about in the lab. We give you a brief overview here so you know what to expect.</p>
<section id="tetris-and-bad-memories" class="level3" data-number="7.4.1">
<h3 data-number="7.4.1" class="anchored" data-anchor-id="tetris-and-bad-memories"><span class="header-section-number">7.4.1</span> Tetris and bad memories</h3>
<p>Yup, you read that right. The research you will learn about tests whether playing Tetris after watching a scary movie can help prevent you from having bad memories from the movie <span class="citation" data-cites="james2015computer">(<a href="references.html#ref-james2015computer" role="doc-biblioref">James et al. 2015</a>)</span>. Sometimes in life people have intrusive memories, and they think about things they’d rather not have to think about. This research looks at one method that could reduce the frequency of intrusive memories.</p>
<p>Here’s what they did. Subjects watched a scary movie, then at the end of the week they reported how many intrusive memories about the movie they had. The mean number of intrusive memories was the measurement (the dependent variable). This was a between-subjects experiment with four groups. Each group of subjects received a different treatment following the scary movie. The question was whether any of these treatments would reduce the number of intrusive memories. All of these treatments occurred after watching the scary movie:</p>
<ol type="1">
<li>No-task control: These participants completed a 10-minute music filler task after watching the scary movie.</li>
<li>Reactivation + Tetris: These participants were shown a series of images from the trauma film to reactivate the traumatic memories (i.e., reactivation task). Then, participants played the video game Tetris for 12 minutes.</li>
<li>Tetris Only: These participants played Tetris for 12 minutes, but did not complete the reactivation task.</li>
<li>Reactivation Only: These participants completed the reactivation task, but did not play Tetris.</li>
</ol>
<p>For reasons we elaborate on in the lab, the researchers hypothesized that the <code>Reactivation+Tetris</code> group would have fewer intrusive memories over the week than the other groups.</p>
<p>Let’s look at the findings. Note you will learn how to do all of these steps in the lab. For now, we just show the findings and the ANOVA table. Then we walk through how to interpret it.</p>
<div class="cell" data-fig.asp="0.5" data-hash="cache/fig-7tetrisData_2f1af5a319474f19d75d2a5c65570d48">
<div class="cell-output-display">
<div id="fig-7tetrisData" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="07-ANOVA_files/figure-html/fig-7tetrisData-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Figure 7.7: Mean number of intrusive memories per week as a function of experimental treatments.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>OOooh, look at that. We did something fancy. <a href="#fig-7tetrisData">Figure&nbsp;<span>7.7</span></a> shows the data from the four groups. The height of each bar shows the mean intrusive memories for the week. The dots show the individual scores for each subject in each group (useful to to the spread of the data). The error bars show the standard errors of the mean.</p>
<p>What can we see here? Right away it looks like there is some support for the research hypothesis. The green bar, for the Reactivation + Tetris group had the lowest mean number of intrusive memories. Also, the error bar is not overlapping with any of the other error bars. This implies that the mean for the Reactivation + Tetris group is different from the means for the other groups. And, this difference is probably not very likely by chance.</p>
<p>We can now conduct the ANOVA on the data to ask the omnibus question. If we get a an <span class="math inline">\(F\)</span>-value with an associated <span class="math inline">\(p\)</span>-value of less than .05 (the alpha criterion set by the authors), then we can reject the hypothesis of no differences. Let’s see what happens:</p>
<div class="cell" data-hash="cache/unnamed-chunk-14_b134a4814533e779f00b2adddc2b0f95">
<div class="cell-output-display">

<table>
 <thead>
  <tr>
   <th style="text-align:left;">   </th>
   <th style="text-align:right;"> Df </th>
   <th style="text-align:right;"> Sum Sq </th>
   <th style="text-align:right;"> Mean Sq </th>
   <th style="text-align:right;"> F value </th>
   <th style="text-align:right;"> Pr(&gt;F) </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;"> Condition </td>
   <td style="text-align:right;"> 3 </td>
   <td style="text-align:right;"> 114.8194 </td>
   <td style="text-align:right;"> 38.27315 </td>
   <td style="text-align:right;"> 3.794762 </td>
   <td style="text-align:right;"> 0.0140858 </td>
  </tr>
  <tr>
   <td style="text-align:left;"> Residuals </td>
   <td style="text-align:right;"> 68 </td>
   <td style="text-align:right;"> 685.8333 </td>
   <td style="text-align:right;"> 10.08578 </td>
   <td style="text-align:right;"> NA </td>
   <td style="text-align:right;"> NA </td>
  </tr>
</tbody>
</table>

</div>
</div>
<p>We see the ANOVA table, it’s up there. We could report the results from the ANOVA table like this:</p>
<blockquote class="blockquote">
<p>There was a significant main effect of treatment condition, F(3, 68) = 3.79, MSE = 10.08, p=0.014.</p>
</blockquote>
<p>We called this a significant effect because the <span class="math inline">\(p\)</span>-value was less than 0.05. In other words, the <span class="math inline">\(F\)</span>-value of 3.79 only happens 1.4% of the time when the null is true. Or, the differences we observed in the means only occur by random chance (sampling error) 1.4% of the time. Because chance rarely produces this kind of result, the researchers made the inference that chance DID NOT produce their differences, instead, they were inclined to conclude that the Reactivation + Tetris treatment really did cause a reduction in intrusive memories. That’s pretty neat.</p>
</section>
<section id="comparing-means-after-the-anova" class="level3" data-number="7.4.2">
<h3 data-number="7.4.2" class="anchored" data-anchor-id="comparing-means-after-the-anova"><span class="header-section-number">7.4.2</span> Comparing means after the ANOVA</h3>
<p>Remember that the ANOVA is an omnibus test, it just tells us whether we can reject the idea that all of the means are the same. The F-test (synonym for ANOVA) that we just conducted suggested we could reject the hypothesis of no differences. As we discussed before, that must mean that there are some differences in the pattern of means.</p>
<p>Generally after conducting an ANOVA, researchers will conduct follow-up tests to compare differences between specific means. We will talk more about this practice throughout the textbook. There are many recommended practices for follow-up tests, and there is a lot of debate about what you should do. We are not going to wade into this debate right now. Instead we are going to point out that <strong>you need to do something</strong> to compare the means of interest after you conduct the ANOVA, because the ANOVA is just the beginning…It usually doesn’t tell you want you want to know. You might wonder why bother conducting the ANOVA in the first place…Not a terrible question at all. A good question. You will see as we talk about more complicated designs, why ANOVAs are so useful. In the present example, they are just a common first step. There are required next steps, such as what we do next.</p>
<p>How can you compare the difference between two means, from a between-subjects design, to determine whether or not the difference you observed is likely or unlikely to be produced by chance? We covered this one already, it’s the independent <span class="math inline">\(t\)</span>-test. We’ll do a couple <span class="math inline">\(t\)</span>-tests, showing the process.</p>
<section id="control-vs.-reactivationtetris" class="level4" data-number="7.4.2.1">
<h4 data-number="7.4.2.1" class="anchored" data-anchor-id="control-vs.-reactivationtetris"><span class="header-section-number">7.4.2.1</span> Control vs.&nbsp;Reactivation+Tetris</h4>
<p>What we really want to know is if Reactivation+Tetris caused fewer intrusive memories…but compared to what? Well, if it did something, the Reactivation+Tetris group should have a smaller mean than the Control group. So, let’s do that comparison:</p>
<div class="cell" data-hash="cache/unnamed-chunk-15_89b694e4588a3f514149b3e91bd78bf5">
<pre><code>#&gt; 
#&gt;  Two Sample t-test
#&gt; 
#&gt; data:  Days_One_to_Seven_Number_of_Intrusions by Condition
#&gt; t = 2.9893, df = 34, p-value = 0.005167
#&gt; alternative hypothesis: true difference in means between group Control and group Reactivation+Tetris is not equal to 0
#&gt; 95 percent confidence interval:
#&gt;  1.031592 5.412852
#&gt; sample estimates:
#&gt;             mean in group Control mean in group Reactivation+Tetris 
#&gt;                          5.111111                          1.888889</code></pre>
</div>
<p>We found that there was a significant difference between the control group (M=5.11) and Reactivation + Tetris group (M=1.89), t(34) = 2.99, p=0.005.</p>
<p>Above you just saw an example of reporting another <span class="math inline">\(t\)</span>-test. This sentences does an OK job of telling the reader everything they want to know. It has the means for each group, and the important bits from the <span class="math inline">\(t\)</span>-test.</p>
<p>More important, as we suspected the difference between the control and Reactivation + Tetris group was likely not due to chance.</p>
</section>
<section id="control-vs.-tetris_only" class="level4" data-number="7.4.2.2">
<h4 data-number="7.4.2.2" class="anchored" data-anchor-id="control-vs.-tetris_only"><span class="header-section-number">7.4.2.2</span> Control vs.&nbsp;Tetris_only</h4>
<p>Now we can really start wondering what caused the difference. Was it just playing Tetris? Does just playing Tetris reduce the number of intrusive memories during the week? Let’s compare that to control:</p>
<div class="cell" data-hash="cache/unnamed-chunk-16_3cbe7a575e4b7591eb37a151e4bdfdc5">
<pre><code>#&gt; 
#&gt;  Two Sample t-test
#&gt; 
#&gt; data:  Days_One_to_Seven_Number_of_Intrusions by Condition
#&gt; t = 1.0129, df = 34, p-value = 0.3183
#&gt; alternative hypothesis: true difference in means between group Control and group Tetris_only is not equal to 0
#&gt; 95 percent confidence interval:
#&gt;  -1.230036  3.674480
#&gt; sample estimates:
#&gt;     mean in group Control mean in group Tetris_only 
#&gt;                  5.111111                  3.888889</code></pre>
</div>
<p>Here we did not find a significant difference. We found that no significant difference between the control group (M=5.11) and Tetris Only group (M=3.89), t(34) = 2.99, p=0.318.</p>
<p>So, it seems that not all of the differences between our means are large enough to be called statistically significant. In particular, the difference here, or larger, happens by chance 31.8% of the time.</p>
<p>You could go on doing more comparisons, between all of the different pairs of means. Each time conducting a <span class="math inline">\(t\)</span>-test, and each time saying something more specific about the patterns across the means than you get to say with the omnibus test provided by the ANOVA.</p>
<p>Usually, it is the pattern of differences across the means that you as a researcher are primarily interested in understanding. Your theories will make predictions about how the pattern turns out (e.g., which specific means should be higher or lower and by how much). So, the practice of doing comparisons after an ANOVA is really important for establishing the patterns in the means.</p>
</section>
</section>
</section>
<section id="anova-summary" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="anova-summary"><span class="header-section-number">7.5</span> ANOVA Summary</h2>
<p>We have just finished a rather long introduction to the ANOVA, and the <span class="math inline">\(F\)</span>-test. The next couple of chapters continue to explore properties of the ANOVA for different kinds of experimental designs. In general, the process to follow for all of the more complicated designs is very similar to what we did here, which boils down to two steps:</p>
<ol type="1">
<li>conduct the ANOVA on the data</li>
<li>conduct follow-up tests, looking at differences between particular means</li>
</ol>
<p>So what’s next…the ANOVA for repeated measures designs. See you in the next chapter.</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography" style="display: none">
<div id="ref-james2015computer" class="csl-entry" role="doc-biblioentry">
James, Ella L, Michael B Bonsall, Laura Hoppitt, Elizabeth M Tunbridge, John R Geddes, Amy L Milton, and Emily A Holmes. 2015. <span>“Computer Game Play Reduces Intrusive Memories of Experimental Trauma via Reconsolidation-Update Mechanisms.”</span> <em>Psychological Science</em> 26 (8): 1201–15. <a href="https://doi.org/10.1177/0956797615583071">https://doi.org/10.1177/0956797615583071</a>.
</div>
<div id="ref-salsburg2001lady" class="csl-entry" role="doc-biblioentry">
Salsburg, David. 2001. <em>The Lady Tasting Tea: <span>How</span> Statistics Revolutionized Science in the Twentieth Century</em>. <span>Macmillan</span>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./06-ttests.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">t-tests</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./08-RMANOVA.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Repeated Measures ANOVA</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>