<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Answering questions with data</title>
  <meta name="description" content="An introductory statistics textbook for psychology students">
  <meta name="generator" content="bookdown 0.6 and GitBook 2.6.7">

  <meta property="og:title" content="Answering questions with data" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="An introductory statistics textbook for psychology students" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Answering questions with data" />
  
  <meta name="twitter:description" content="An introductory statistics textbook for psychology students" />
  

<meta name="author" content="Matthew J. C. Crump">


<meta name="date" content="2018-04-11">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="FoundationForInference.html">
<link rel="next" href="inferenceForNumericalData.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script type="text/javascript">
mattcrump=1;
</script>



<link rel="stylesheet" href="tufte.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Programming</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introductionToData.html"><a href="introductionToData.html"><i class="fa fa-check"></i><b>1</b> Introduction to data</a><ul>
<li class="chapter" data-level="1.1" data-path="introductionToData.html"><a href="introductionToData.html#basicExampleOfStentsAndStrokes"><i class="fa fa-check"></i><b>1.1</b> Case study: using stents to prevent strokes</a></li>
<li class="chapter" data-level="1.2" data-path="introductionToData.html"><a href="introductionToData.html#dataBasics"><i class="fa fa-check"></i><b>1.2</b> Data basics</a><ul>
<li class="chapter" data-level="1.2.1" data-path="introductionToData.html"><a href="introductionToData.html#observations-variables-and-data-matrices"><i class="fa fa-check"></i><b>1.2.1</b> Observations, variables, and data matrices</a></li>
<li class="chapter" data-level="1.2.2" data-path="introductionToData.html"><a href="introductionToData.html#variableTypes"><i class="fa fa-check"></i><b>1.2.2</b> Types of variables</a></li>
<li class="chapter" data-level="1.2.3" data-path="introductionToData.html"><a href="introductionToData.html#variableRelations"><i class="fa fa-check"></i><b>1.2.3</b> Relationships between variables</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introductionToData.html"><a href="introductionToData.html#overviewOfDataCollectionPrinciples"><i class="fa fa-check"></i><b>1.3</b> Overview of data collection principles</a><ul>
<li class="chapter" data-level="1.3.1" data-path="introductionToData.html"><a href="introductionToData.html#populationsAndSamples"><i class="fa fa-check"></i><b>1.3.1</b> Populations and samples</a></li>
<li class="chapter" data-level="1.3.2" data-path="introductionToData.html"><a href="introductionToData.html#anecdotalEvidenceSubsection"><i class="fa fa-check"></i><b>1.3.2</b> Anecdotal evidence</a></li>
<li class="chapter" data-level="1.3.3" data-path="introductionToData.html"><a href="introductionToData.html#sampling-from-a-population"><i class="fa fa-check"></i><b>1.3.3</b> Sampling from a population</a></li>
<li class="chapter" data-level="1.3.4" data-path="introductionToData.html"><a href="introductionToData.html#explanatoryAndResponse"><i class="fa fa-check"></i><b>1.3.4</b> Explanatory and response variables</a></li>
<li class="chapter" data-level="1.3.5" data-path="introductionToData.html"><a href="introductionToData.html#introducing-observational-studies-and-experiments"><i class="fa fa-check"></i><b>1.3.5</b> Introducing observational studies and experiments</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introductionToData.html"><a href="introductionToData.html#observational-studies-and-sampling-strategies"><i class="fa fa-check"></i><b>1.4</b> Observational studies and sampling strategies</a><ul>
<li class="chapter" data-level="1.4.1" data-path="introductionToData.html"><a href="introductionToData.html#observational-studies"><i class="fa fa-check"></i><b>1.4.1</b> Observational studies</a></li>
<li class="chapter" data-level="1.4.2" data-path="introductionToData.html"><a href="introductionToData.html#threeSamplingMethods"><i class="fa fa-check"></i><b>1.4.2</b> Three sampling methods (special topic)</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introductionToData.html"><a href="introductionToData.html#experimentsSection"><i class="fa fa-check"></i><b>1.5</b> Experiments</a><ul>
<li class="chapter" data-level="1.5.1" data-path="introductionToData.html"><a href="introductionToData.html#experimentalDesignPrinciples"><i class="fa fa-check"></i><b>1.5.1</b> Principles of experimental design</a></li>
<li class="chapter" data-level="1.5.2" data-path="introductionToData.html"><a href="introductionToData.html#biasInHumanExperiments"><i class="fa fa-check"></i><b>1.5.2</b> Reducing bias in human experiments</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="introductionToData.html"><a href="introductionToData.html#numericalData"><i class="fa fa-check"></i><b>1.6</b> Examining numerical data</a><ul>
<li class="chapter" data-level="1.6.1" data-path="introductionToData.html"><a href="introductionToData.html#scatterPlots"><i class="fa fa-check"></i><b>1.6.1</b> Scatterplots for paired data</a></li>
<li class="chapter" data-level="1.6.2" data-path="introductionToData.html"><a href="introductionToData.html#dotPlot"><i class="fa fa-check"></i><b>1.6.2</b> Dot plots and the mean</a></li>
<li class="chapter" data-level="1.6.3" data-path="introductionToData.html"><a href="introductionToData.html#histogramsAndShape"><i class="fa fa-check"></i><b>1.6.3</b> Histograms and shape</a></li>
<li class="chapter" data-level="1.6.4" data-path="introductionToData.html"><a href="introductionToData.html#variability"><i class="fa fa-check"></i><b>1.6.4</b> Variance and standard deviation</a></li>
<li class="chapter" data-level="1.6.5" data-path="introductionToData.html"><a href="introductionToData.html#box-plots-quartiles-and-the-median"><i class="fa fa-check"></i><b>1.6.5</b> Box plots, quartiles, and the median</a></li>
<li class="chapter" data-level="1.6.6" data-path="introductionToData.html"><a href="introductionToData.html#robust-statistics"><i class="fa fa-check"></i><b>1.6.6</b> Robust statistics</a></li>
<li class="chapter" data-level="1.6.7" data-path="introductionToData.html"><a href="introductionToData.html#transformingDataSubsection"><i class="fa fa-check"></i><b>1.6.7</b> Transforming data (special topic)</a></li>
<li class="chapter" data-level="1.6.8" data-path="introductionToData.html"><a href="introductionToData.html#mapping-data-special-topic"><i class="fa fa-check"></i><b>1.6.8</b> Mapping data (special topic)</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="introductionToData.html"><a href="introductionToData.html#categoricalData"><i class="fa fa-check"></i><b>1.7</b> Considering categorical data</a><ul>
<li class="chapter" data-level="1.7.1" data-path="introductionToData.html"><a href="introductionToData.html#contingency-tables-and-bar-plots"><i class="fa fa-check"></i><b>1.7.1</b> Contingency tables and bar plots</a></li>
<li class="chapter" data-level="1.7.2" data-path="introductionToData.html"><a href="introductionToData.html#row-and-column-proportions"><i class="fa fa-check"></i><b>1.7.2</b> Row and column proportions</a></li>
<li class="chapter" data-level="1.7.3" data-path="introductionToData.html"><a href="introductionToData.html#segmentedBarPlotsAndIndependence"><i class="fa fa-check"></i><b>1.7.3</b> Segmented bar and mosaic plots</a></li>
<li class="chapter" data-level="1.7.4" data-path="introductionToData.html"><a href="introductionToData.html#the-only-pie-chart-you-will-see-in-this-book"><i class="fa fa-check"></i><b>1.7.4</b> The only pie chart you will see in this book</a></li>
<li class="chapter" data-level="1.7.5" data-path="introductionToData.html"><a href="introductionToData.html#comparingAcrossGroups"><i class="fa fa-check"></i><b>1.7.5</b> Comparing numerical data across groups</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="FoundationForInference.html"><a href="FoundationForInference.html"><i class="fa fa-check"></i><b>2</b> Foundation for inference</a><ul>
<li class="chapter" data-level="2.1" data-path="FoundationForInference.html"><a href="FoundationForInference.html#caseStudyGenderDiscrimination"><i class="fa fa-check"></i><b>2.1</b> Randomization case study: gender discrimination</a><ul>
<li class="chapter" data-level="2.1.1" data-path="FoundationForInference.html"><a href="FoundationForInference.html#variabilityWithinData"><i class="fa fa-check"></i><b>2.1.1</b> Variability within data</a></li>
<li class="chapter" data-level="2.1.2" data-path="FoundationForInference.html"><a href="FoundationForInference.html#simulatingTheStudy"><i class="fa fa-check"></i><b>2.1.2</b> Simulating the study</a></li>
<li class="chapter" data-level="2.1.3" data-path="FoundationForInference.html"><a href="FoundationForInference.html#checking-for-independence"><i class="fa fa-check"></i><b>2.1.3</b> Checking for independence</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="FoundationForInference.html"><a href="FoundationForInference.html#caseStudyOpportunityCost"><i class="fa fa-check"></i><b>2.2</b> Randomization case study: opportunity cost</a><ul>
<li class="chapter" data-level="2.2.1" data-path="FoundationForInference.html"><a href="FoundationForInference.html#exploring-the-data-set-before-the-analysis"><i class="fa fa-check"></i><b>2.2.1</b> Exploring the data set before the analysis</a></li>
<li class="chapter" data-level="2.2.2" data-path="FoundationForInference.html"><a href="FoundationForInference.html#results-from-chance-alone"><i class="fa fa-check"></i><b>2.2.2</b> Results from chance alone</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="FoundationForInference.html"><a href="FoundationForInference.html#HypothesisTesting"><i class="fa fa-check"></i><b>2.3</b> Hypothesis testing</a><ul>
<li class="chapter" data-level="2.3.1" data-path="FoundationForInference.html"><a href="FoundationForInference.html#hypothesis-testing-in-the-us-court-system"><i class="fa fa-check"></i><b>2.3.1</b> Hypothesis testing in the US court system</a></li>
<li class="chapter" data-level="2.3.2" data-path="FoundationForInference.html"><a href="FoundationForInference.html#p-value-and-statistical-significance"><i class="fa fa-check"></i><b>2.3.2</b> p-value and statistical significance</a></li>
<li class="chapter" data-level="2.3.3" data-path="FoundationForInference.html"><a href="FoundationForInference.html#decision-errors"><i class="fa fa-check"></i><b>2.3.3</b> Decision errors</a></li>
<li class="chapter" data-level="2.3.4" data-path="FoundationForInference.html"><a href="FoundationForInference.html#significanceLevel"><i class="fa fa-check"></i><b>2.3.4</b> Choosing a significance level</a></li>
<li class="chapter" data-level="2.3.5" data-path="FoundationForInference.html"><a href="FoundationForInference.html#IntroducingTwoSidedHypotheses"><i class="fa fa-check"></i><b>2.3.5</b> Introducing two-sided hypotheses</a></li>
<li class="chapter" data-level="2.3.6" data-path="FoundationForInference.html"><a href="FoundationForInference.html#InflatingType1ErrorRate"><i class="fa fa-check"></i><b>2.3.6</b> Controlling the Type 1 Error rate</a></li>
<li class="chapter" data-level="2.3.7" data-path="FoundationForInference.html"><a href="FoundationForInference.html#how-to-use-a-hypothesis-test"><i class="fa fa-check"></i><b>2.3.7</b> How to use a hypothesis test</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="FoundationForInference.html"><a href="FoundationForInference.html#SimulationCaseStudies"><i class="fa fa-check"></i><b>2.4</b> Simulation case studies</a><ul>
<li class="chapter" data-level="2.4.1" data-path="FoundationForInference.html"><a href="FoundationForInference.html#medical-consultant"><i class="fa fa-check"></i><b>2.4.1</b> Medical consultant</a></li>
<li class="chapter" data-level="2.4.2" data-path="FoundationForInference.html"><a href="FoundationForInference.html#tappers-and-listeners"><i class="fa fa-check"></i><b>2.4.2</b> Tappers and listeners</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="FoundationForInference.html"><a href="FoundationForInference.html#CLTsection"><i class="fa fa-check"></i><b>2.5</b> Central Limit Theorem</a><ul>
<li class="chapter" data-level="2.5.1" data-path="FoundationForInference.html"><a href="FoundationForInference.html#null-distribution-from-the-case-studies"><i class="fa fa-check"></i><b>2.5.1</b> Null distribution from the case studies</a></li>
<li class="chapter" data-level="2.5.2" data-path="FoundationForInference.html"><a href="FoundationForInference.html#examples-of-future-settings-we-will-consider"><i class="fa fa-check"></i><b>2.5.2</b> Examples of future settings we will consider</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="FoundationForInference.html"><a href="FoundationForInference.html#normalDist"><i class="fa fa-check"></i><b>2.6</b> Normal distribution</a><ul>
<li class="chapter" data-level="2.6.1" data-path="FoundationForInference.html"><a href="FoundationForInference.html#NormalDistributionModelSubsection"><i class="fa fa-check"></i><b>2.6.1</b> Normal distribution model</a></li>
<li class="chapter" data-level="2.6.2" data-path="FoundationForInference.html"><a href="FoundationForInference.html#standardizing-with-z-scores"><i class="fa fa-check"></i><b>2.6.2</b> Standardizing with Z scores</a></li>
<li class="chapter" data-level="2.6.3" data-path="FoundationForInference.html"><a href="FoundationForInference.html#normal-probability-table"><i class="fa fa-check"></i><b>2.6.3</b> Normal probability table</a></li>
<li class="chapter" data-level="2.6.4" data-path="FoundationForInference.html"><a href="FoundationForInference.html#normal-probability-examples"><i class="fa fa-check"></i><b>2.6.4</b> Normal probability examples</a></li>
<li class="chapter" data-level="2.6.5" data-path="FoundationForInference.html"><a href="FoundationForInference.html#rule"><i class="fa fa-check"></i><b>2.6.5</b> 68-95-99.7 rule</a></li>
<li class="chapter" data-level="2.6.6" data-path="FoundationForInference.html"><a href="FoundationForInference.html#assessingNormal"><i class="fa fa-check"></i><b>2.6.6</b> Evaluating the normal approximation</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="FoundationForInference.html"><a href="FoundationForInference.html#ApplyingTheNormalModel"><i class="fa fa-check"></i><b>2.7</b> Applying the normal model</a><ul>
<li class="chapter" data-level="2.7.1" data-path="FoundationForInference.html"><a href="FoundationForInference.html#standard-error"><i class="fa fa-check"></i><b>2.7.1</b> Standard error</a></li>
<li class="chapter" data-level="2.7.2" data-path="FoundationForInference.html"><a href="FoundationForInference.html#normal-model-application-opportunity-cost"><i class="fa fa-check"></i><b>2.7.2</b> Normal model application: opportunity cost</a></li>
<li class="chapter" data-level="2.7.3" data-path="FoundationForInference.html"><a href="FoundationForInference.html#normal-model-application-medical-consultant"><i class="fa fa-check"></i><b>2.7.3</b> Normal model application: medical consultant</a></li>
<li class="chapter" data-level="2.7.4" data-path="FoundationForInference.html"><a href="FoundationForInference.html#conditions-for-applying-the-normal-model"><i class="fa fa-check"></i><b>2.7.4</b> Conditions for applying the normal model</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="FoundationForInference.html"><a href="FoundationForInference.html#ConfidenceIntervals"><i class="fa fa-check"></i><b>2.8</b> Confidence intervals</a><ul>
<li class="chapter" data-level="2.8.1" data-path="FoundationForInference.html"><a href="FoundationForInference.html#capturing-the-population-parameter"><i class="fa fa-check"></i><b>2.8.1</b> Capturing the population parameter</a></li>
<li class="chapter" data-level="2.8.2" data-path="FoundationForInference.html"><a href="FoundationForInference.html#constructing-a-95-confidence-interval"><i class="fa fa-check"></i><b>2.8.2</b> Constructing a 95% confidence interval</a></li>
<li class="chapter" data-level="2.8.3" data-path="FoundationForInference.html"><a href="FoundationForInference.html#changingTheConfidenceLevelSection"><i class="fa fa-check"></i><b>2.8.3</b> Changing the confidence level</a></li>
<li class="chapter" data-level="2.8.4" data-path="FoundationForInference.html"><a href="FoundationForInference.html#interpretingCIs"><i class="fa fa-check"></i><b>2.8.4</b> Interpreting confidence intervals</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html"><i class="fa fa-check"></i><b>3</b> Inference for categorical data</a><ul>
<li class="chapter" data-level="3.1" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#singleProportion"><i class="fa fa-check"></i><b>3.1</b> Inference for a single proportion</a><ul>
<li class="chapter" data-level="3.1.1" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#when-the-sample-proportion-is-nearly-normal"><i class="fa fa-check"></i><b>3.1.1</b> When the sample proportion is nearly normal</a></li>
<li class="chapter" data-level="3.1.2" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#confIntForPropSection"><i class="fa fa-check"></i><b>3.1.2</b> Confidence intervals for a proportion</a></li>
<li class="chapter" data-level="3.1.3" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#htForPropSection"><i class="fa fa-check"></i><b>3.1.3</b> Hypothesis testing for a proportion</a></li>
<li class="chapter" data-level="3.1.4" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#choosing-a-sample-size-when-estimating-a-proportion"><i class="fa fa-check"></i><b>3.1.4</b> Choosing a sample size when estimating a proportion</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#differenceOfTwoProportions"><i class="fa fa-check"></i><b>3.2</b> Difference of two proportions</a><ul>
<li class="chapter" data-level="3.2.1" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#SampleDistributionOfTheDiffOfTwoProportions"><i class="fa fa-check"></i><b>3.2.1</b> Sample distribution of the difference of two proportions</a></li>
<li class="chapter" data-level="3.2.2" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#intervals-and-tests-for-p_1--p_2"><i class="fa fa-check"></i><b>3.2.2</b> Intervals and tests for <span class="math inline">\(p_1 -p_2\)</span></a></li>
<li class="chapter" data-level="3.2.3" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#pooledHTForProportionsSection"><i class="fa fa-check"></i><b>3.2.3</b> Hypothesis testing when <span class="math inline">\(H_0: p_1=p_2\)</span></a></li>
</ul></li>
<li><a href="inferenceForCategoricalData.html#oneWayChiSquare"><span class="toc-section-number">3.3</span> Testing for goodness of fit using chi-square<br />
(special topic)</a><ul>
<li class="chapter" data-level="3.3.1" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#creating-a-test-statistic-for-one-way-tables"><i class="fa fa-check"></i><b>3.3.1</b> Creating a test statistic for one-way tables</a></li>
<li class="chapter" data-level="3.3.2" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#chiSquareTestStatistic"><i class="fa fa-check"></i><b>3.3.2</b> The chi-square test statistic</a></li>
<li class="chapter" data-level="3.3.3" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#the-chi-square-distribution-and-finding-areas"><i class="fa fa-check"></i><b>3.3.3</b> The chi-square distribution and finding areas</a></li>
<li class="chapter" data-level="3.3.4" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#pValueForAChiSquareTest"><i class="fa fa-check"></i><b>3.3.4</b> Finding a p-value for a chi-square distribution</a></li>
<li class="chapter" data-level="3.3.5" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#evaluating-goodness-of-fit-for-a-distribution"><i class="fa fa-check"></i><b>3.3.5</b> Evaluating goodness of fit for a distribution</a></li>
</ul></li>
<li><a href="inferenceForCategoricalData.html#twoWayTablesAndChiSquare"><span class="toc-section-number">3.4</span> Testing for independence in two-way tables<br />
(special topic)</a><ul>
<li class="chapter" data-level="3.4.1" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#expected-counts-in-two-way-tables"><i class="fa fa-check"></i><b>3.4.1</b> Expected counts in two-way tables</a></li>
<li class="chapter" data-level="3.4.2" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#the-chi-square-test-for-two-way-tables"><i class="fa fa-check"></i><b>3.4.2</b> The chi-square test for two-way tables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html"><i class="fa fa-check"></i><b>4</b> Inference for numerical data</a><ul>
<li class="chapter" data-level="4.1" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#oneSampleMeansWithTDistribution"><i class="fa fa-check"></i><b>4.1</b> One-sample means with the <span class="math inline">\(t\)</span> distribution</a><ul>
<li class="chapter" data-level="4.1.1" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#two-examples-using-the-normal-distribution"><i class="fa fa-check"></i><b>4.1.1</b> Two examples using the normal distribution</a></li>
<li class="chapter" data-level="4.1.2" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#introducingTheTDistribution"><i class="fa fa-check"></i><b>4.1.2</b> Introducing the <span class="math inline">\(t\)</span> distribution</a></li>
<li class="chapter" data-level="4.1.3" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#tDistSolutionToSEProblem"><i class="fa fa-check"></i><b>4.1.3</b> Applying the <span class="math inline">\(t\)</span> distribution to the single-mean situation</a></li>
<li class="chapter" data-level="4.1.4" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#oneSampleTConfidenceIntervals"><i class="fa fa-check"></i><b>4.1.4</b> One sample <span class="math inline">\(t\)</span> confidence intervals</a></li>
<li class="chapter" data-level="4.1.5" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#oneSampleTTests"><i class="fa fa-check"></i><b>4.1.5</b> One sample <span class="math inline">\(t\)</span> tests</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#pairedData"><i class="fa fa-check"></i><b>4.2</b> Paired data</a><ul>
<li class="chapter" data-level="4.2.1" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#paired-observations"><i class="fa fa-check"></i><b>4.2.1</b> Paired observations</a></li>
<li class="chapter" data-level="4.2.2" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#inference-for-paired-data"><i class="fa fa-check"></i><b>4.2.2</b> Inference for paired data</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#differenceOfTwoMeans"><i class="fa fa-check"></i><b>4.3</b> Difference of two means</a><ul>
<li class="chapter" data-level="4.3.1" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#confidence-interval-for-a-differences-of-means"><i class="fa fa-check"></i><b>4.3.1</b> Confidence interval for a differences of means</a></li>
<li class="chapter" data-level="4.3.2" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#hypothesis-tests-based-on-a-difference-in-means"><i class="fa fa-check"></i><b>4.3.2</b> Hypothesis tests based on a difference in means</a></li>
<li class="chapter" data-level="4.3.3" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#case-study-two-versions-of-a-course-exam"><i class="fa fa-check"></i><b>4.3.3</b> Case study: two versions of a course exam</a></li>
<li class="chapter" data-level="4.3.4" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#summary-for-inference-using-the-t-distribution"><i class="fa fa-check"></i><b>4.3.4</b> Summary for inference using the <span class="math inline">\(t\)</span> distribution</a></li>
<li class="chapter" data-level="4.3.5" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#pooledStandardDeviations"><i class="fa fa-check"></i><b>4.3.5</b> Pooled standard deviation estimate (special topic)</a></li>
</ul></li>
<li><a href="inferenceForNumericalData.html#anovaAndRegrWithCategoricalVariables"><span class="toc-section-number">4.4</span> Comparing many means with ANOVA<br />
(special topic)</a><ul>
<li class="chapter" data-level="4.4.1" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#is-batting-performance-related-to-player-position-in-mlb"><i class="fa fa-check"></i><b>4.4.1</b> Is batting performance related to player position in MLB?</a></li>
<li class="chapter" data-level="4.4.2" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#analysis-of-variance-anova-and-the-f-test"><i class="fa fa-check"></i><b>4.4.2</b> Analysis of variance (ANOVA) and the F test</a></li>
<li class="chapter" data-level="4.4.3" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#reading-an-anova-table-from-software"><i class="fa fa-check"></i><b>4.4.3</b> Reading an ANOVA table from software</a></li>
<li class="chapter" data-level="4.4.4" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#graphical-diagnostics-for-an-anova-analysis"><i class="fa fa-check"></i><b>4.4.4</b> Graphical diagnostics for an ANOVA analysis</a></li>
<li class="chapter" data-level="4.4.5" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#multipleComparisonsAndControllingTheType1ErrorRate"><i class="fa fa-check"></i><b>4.4.5</b> Multiple comparisons and controlling Type 1 Error rate</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#bootstrapping-to-study-the-standard-deviation"><i class="fa fa-check"></i><b>4.5</b> Bootstrapping to study the standard deviation</a><ul>
<li class="chapter" data-level="4.5.1" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#bootstrap-samples-and-distributions"><i class="fa fa-check"></i><b>4.5.1</b> Bootstrap samples and distributions</a></li>
<li class="chapter" data-level="4.5.2" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#inference-using-the-bootstrap"><i class="fa fa-check"></i><b>4.5.2</b> Inference using the bootstrap</a></li>
<li class="chapter" data-level="4.5.3" data-path="inferenceForNumericalData.html"><a href="inferenceForNumericalData.html#frequently-asked-questions"><i class="fa fa-check"></i><b>4.5.3</b> Frequently asked questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html"><i class="fa fa-check"></i><b>5</b> Introduction to linear regression</a><ul>
<li class="chapter" data-level="5.1" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#lineFittingResidualsCorrelation"><i class="fa fa-check"></i><b>5.1</b> Line fitting, residuals, and correlation</a><ul>
<li class="chapter" data-level="5.1.1" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#beginning-with-straight-lines"><i class="fa fa-check"></i><b>5.1.1</b> Beginning with straight lines</a></li>
<li class="chapter" data-level="5.1.2" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#fitting-a-line-by-eye"><i class="fa fa-check"></i><b>5.1.2</b> Fitting a line by eye</a></li>
<li class="chapter" data-level="5.1.3" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#residuals"><i class="fa fa-check"></i><b>5.1.3</b> Residuals</a></li>
<li class="chapter" data-level="5.1.4" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#describing-linear-relationships-with-correlation"><i class="fa fa-check"></i><b>5.1.4</b> Describing linear relationships with correlation</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#fittingALineByLSR"><i class="fa fa-check"></i><b>5.2</b> Fitting a line by least squares regression</a><ul>
<li class="chapter" data-level="5.2.1" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#an-objective-measure-for-finding-the-best-line"><i class="fa fa-check"></i><b>5.2.1</b> An objective measure for finding the best line</a></li>
<li class="chapter" data-level="5.2.2" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#findingTheLeastSquaresLineSection"><i class="fa fa-check"></i><b>5.2.2</b> Finding the least squares line</a></li>
<li class="chapter" data-level="5.2.3" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#interpreting-regression-line-parameter-estimates"><i class="fa fa-check"></i><b>5.2.3</b> Interpreting regression line parameter estimates</a></li>
<li class="chapter" data-level="5.2.4" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#extrapolation-is-treacherous"><i class="fa fa-check"></i><b>5.2.4</b> Extrapolation is treacherous</a></li>
<li class="chapter" data-level="5.2.5" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#using-r2-to-describe-the-strength-of-a-fit"><i class="fa fa-check"></i><b>5.2.5</b> Using <span class="math inline">\(R^2\)</span> to describe the strength of a fit</a></li>
<li class="chapter" data-level="5.2.6" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#categoricalPredictorsWithTwoLevels"><i class="fa fa-check"></i><b>5.2.6</b> Categorical predictors with two levels</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#typesOfOutliersInLinearRegression"><i class="fa fa-check"></i><b>5.3</b> Types of outliers in linear regression</a></li>
<li class="chapter" data-level="5.4" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#inferenceForLinearRegression"><i class="fa fa-check"></i><b>5.4</b> Inference for linear regression</a><ul>
<li class="chapter" data-level="5.4.1" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#conditions-for-the-least-squares-line"><i class="fa fa-check"></i><b>5.4.1</b> Conditions for the least squares line</a></li>
<li class="chapter" data-level="5.4.2" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#midterm-elections-and-unemployment"><i class="fa fa-check"></i><b>5.4.2</b> Midterm elections and unemployment</a></li>
<li class="chapter" data-level="5.4.3" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#testStatisticForTheSlope"><i class="fa fa-check"></i><b>5.4.3</b> Understanding regression output from software</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html"><i class="fa fa-check"></i><b>6</b> Multiple and logistic regression</a><ul>
<li class="chapter" data-level="6.1" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#introductionToMultipleRegression"><i class="fa fa-check"></i><b>6.1</b> Introduction to multiple regression</a><ul>
<li class="chapter" data-level="6.1.1" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#twoSingleVariableModelsForMarioKartData"><i class="fa fa-check"></i><b>6.1.1</b> A single-variable model for the Mario Kart data</a></li>
<li class="chapter" data-level="6.1.2" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#includingAndAssessingManyVariablesInAModel"><i class="fa fa-check"></i><b>6.1.2</b> Including and assessing many variables in a model</a></li>
<li class="chapter" data-level="6.1.3" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#adjusted-r2-as-a-better-estimate-of-explained-variance"><i class="fa fa-check"></i><b>6.1.3</b> Adjusted <span class="math inline">\(R^2\)</span> as a better estimate of explained variance</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#modelSelection"><i class="fa fa-check"></i><b>6.2</b> Model selection</a><ul>
<li class="chapter" data-level="6.2.1" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#identifying-variables-in-the-model-that-may-not-be-helpful"><i class="fa fa-check"></i><b>6.2.1</b> Identifying variables in the model that may not be helpful</a></li>
<li class="chapter" data-level="6.2.2" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#two-model-selection-strategies"><i class="fa fa-check"></i><b>6.2.2</b> Two model selection strategies</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#multipleRegressionModelAssumptions"><i class="fa fa-check"></i><b>6.3</b> Checking model assumptions using graphs</a></li>
<li class="chapter" data-level="6.4" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#logisticRegression"><i class="fa fa-check"></i><b>6.4</b> Logistic regression</a><ul>
<li class="chapter" data-level="6.4.1" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#email-data"><i class="fa fa-check"></i><b>6.4.1</b> Email data</a></li>
<li class="chapter" data-level="6.4.2" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#modelingTheProbabilityOfAnEvent"><i class="fa fa-check"></i><b>6.4.2</b> Modeling the probability of an event</a></li>
<li class="chapter" data-level="6.4.3" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#practical-decisions-in-the-email-application"><i class="fa fa-check"></i><b>6.4.3</b> Practical decisions in the email application</a></li>
<li class="chapter" data-level="6.4.4" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#diagnostics-for-the-email-classifier"><i class="fa fa-check"></i><b>6.4.4</b> Diagnostics for the email classifier</a></li>
<li class="chapter" data-level="6.4.5" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#improvingTheSetOfVariablesForASpamFilter"><i class="fa fa-check"></i><b>6.4.5</b> Improving the set of variables for a spam filter</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Answering questions with data</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="inferenceForCategoricalData" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Inference for categorical data</h1>
<p>Chapter [inferenceForCategoricalData] provides a more complete framework for statistical techniques suitable for categorical data. We’ll continue working with the normal model in the context of inference for proportions, and we’ll also encounter a new technique and distribution suitable for working with frequency and contingency tables in Sections [oneWayChiSquare] and [twoWayTablesAndChiSquare].</p>
<div id="singleProportion" class="section level2">
<h2><span class="header-section-number">3.1</span> Inference for a single proportion</h2>
<p>Before we get started, we’ll introduce a little terminology and notation.</p>
<p>In the tappers-listeners study, one person tapped a tune on the table and the listener tried to guess the game. In this study, each game can be thought of as a <strong>trial</strong>. We could label each trial a <strong>success</strong> if the listener successfully guessed the tune, and we could label a trial a <strong>failure</strong> if the listener was unsuccessful.</p>
<p><span> A single event that leads to an outcome can be called a <em>trial</em>. If the trial has two possible outcomes, e.g. heads or tails when flipping a coin, we typically label one of those outcome a <em>success</em> and the other a <em>failure</em>. The choice of which outcome is labeled a success and which a failure is arbitrary, and it will not impact the results of our analyses.</span></p>
<p>When a proportion is recorded, it is common to use a 1 to represent a “success” and a 0 to represent a “failure” and then write down a <strong>key</strong> to communicate what each value represents. This notation is also convenient for calculations. For example, if we have 10 trials with 6 success (1’s) and 4 failures (0’s), the sample proportion can be computed using the mean of the zeros and ones:</p>
<p><span class="math display">\[\begin{aligned}
\hat{p} = \frac{\ 1 + 1 + 1 + 1 + 1 + 1 + 0 + 0 + 0 + 0\ }{10} = 0.6\end{aligned}\]</span></p>
<p>Next we’ll take a look at when we can apply our normal distribution framework to the distribution of the sample proportion, <span class="math inline">\(\hat{p}\)</span>.</p>
<div id="when-the-sample-proportion-is-nearly-normal" class="section level3">
<h3><span class="header-section-number">3.1.1</span> When the sample proportion is nearly normal</h3>
<p>The sampling distribution for <span class="math inline">\(\hat{p}\)</span>, taken from a sample of size <span class="math inline">\(n\)</span> from a population with a true proportion <span class="math inline">\(p\)</span>, is nearly normal when</p>
<ol style="list-style-type: decimal">
<li><p>the sample observations are independent and</p></li>
<li><p>we expected to see at least 10 successes and 10 failures in our sample, i.e. <span class="math inline">\(np\geq10\)</span> and <span class="math inline">\(n(1-p)\geq10\)</span>. This is called the <strong>success-failure condition</strong>.</p></li>
</ol>
<p>If these conditions are met, then the sampling distribution of <span class="math inline">\(\hat{p}\)</span> is nearly normal with mean <span class="math inline">\(p\)</span> and standard error</p>
<p><span class="math display">\[\begin{aligned}
SE_{\hat{p}} = \sqrt{\frac{\ p(1-p)\ }{n}}
\label{seOfPHat}\end{aligned}\]</span></p>
<p>[</p>
<p><span class="math inline">\(\hat{p}\)</span></p>
<p><br />
sample<br />
proportion</p>
<p><br />
<span class="math inline">\(p\)</span></p>
<p><br />
population<br />
proportion]</p>
<p><span class="math inline">\(\hat{p}\)</span></p>
<p><br />
sample<br />
proportion</p>
<p><br />
<span class="math inline">\(p\)</span></p>
<p><br />
population<br />
proportion</p>
<p>Typically we do not know the true proportion, <span class="math inline">\(p\)</span>, so we substitute some value to check conditions and to estimate the standard error. For confidence intervals, usually <span class="math inline">\(\hat{p}\)</span> is used to check the success-failure condition and compute the standard error. For hypothesis tests, typically the null value <span class="math inline">\(p_0\)</span> is used in place of <span class="math inline">\(p\)</span>. Examples are presented for each of these cases in Sections [confIntForPropSection] and [htForPropSection].</p>
<p><span> If data come from a simple random sample and consist of less than 10% of the population, then the independence assumption is reasonable. Or, for example, if the data come from an experiment where each user was randomly assigned to the treatment or control group and users do not interact, then the observations in each group are typically independent.</span></p>
</div>
<div id="confIntForPropSection" class="section level3">
<h3><span class="header-section-number">3.1.2</span> Confidence intervals for a proportion</h3>
<p>According to a New York Times / CBS News poll in June 2012, only about 44% of the American public approves of the job the Supreme Court is doing.<a href="#fn97" class="footnoteRef" id="fnref97"><sup>97</sup></a> This poll included responses of 976 randomly sampled adults.</p>
<p>We want a confidence interval for the proportion of Americans who approve of the job the Supreme Court is doing. Our point estimate, based on a simple random sample of size <span class="math inline">\(n = 976\)</span> from the NYTimes/CBS poll, is <span class="math inline">\(\hat{p} = 0.44\)</span>. To use our confidence interval formula from Section [ConfidenceIntervals], we must first check whether the sampling distribution of <span class="math inline">\(\hat{p}\)</span> is nearly normal and calculate the standard error of the estimate.</p>
<p>The data are based on a simple random sample and consist of far fewer than 10% of the U.S. population, so independence is confirmed. The sample size must also be sufficiently large, which is checked via the success-failure condition: there were approximately <span class="math inline">\(976\times \hat{p}=429\)</span> “successes” and <span class="math inline">\(976\times (1-\hat{p})=547\)</span> “failures” in the sample, both easily greater than 10.</p>
<p>With the conditions met, we are assured that the sampling distribution of <span class="math inline">\(\hat{p}\)</span> is nearly normal. Next, a standard error for <span class="math inline">\(\hat{p}\)</span> is needed, and then we can employ the usual method to construct a confidence interval.</p>
<p>[seOfPropOfAmericansJobApprovalOfSupremeCourt] Estimate the standard error of <span class="math inline">\(\hat{p}=0.44\)</span> using Equation . Because <span class="math inline">\(p\)</span> is unknown and the standard error is for a confidence interval, use <span class="math inline">\(\hat{p}\)</span> in place of <span class="math inline">\(p\)</span>. <a href="#fn98" class="footnoteRef" id="fnref98"><sup>98</sup></a></p>
<p><span>Construct a 95% confidence interval for <span class="math inline">\(p\)</span>, the proportion of Americans who approve of the job the Supreme Court is doing.</span> Using the standard error estimate from Guided Practice [seOfPropOfAmericansJobApprovalOfSupremeCourt], the point estimate 0.44, and <span class="math inline">\(z^{\star} = 1.96\)</span> for a 95% confidence interval, the confidence interval can be computed as</p>
<p><span class="math display">\[\begin{aligned}
\text{point estimate } \ \pm\ z^{\star}SE \quad\to\quad 0.44 \ \pm\ 1.96\times 0.016 \quad\to\quad (0.409, 0.471)\end{aligned}\]</span></p>
<p>We are 95% confident that the true proportion of Americans who approve of the job of the Supreme Court (in June 2012) is between 0.409 and 0.471. At the time this poll was taken, we can say with high confidence that the job approval of the Supreme Court was below 50%.</p>
<ul>
<li><p>Verify the observations are independent and also verify the success-failure condition using <span class="math inline">\(\hat{p}\)</span> and <span class="math inline">\(n\)</span>.</p></li>
<li><p>If the conditions are met, then the Central Limit Theorem applies, and the sampling distribution of <span class="math inline">\(\hat{p}\)</span> is well-approximated by the normal model.</p></li>
<li><p>Construct the standard error using <span class="math inline">\(\hat{p}\)</span> in place of <span class="math inline">\(p\)</span> and apply the general confidence interval formula.</p></li>
</ul>
</div>
<div id="htForPropSection" class="section level3">
<h3><span class="header-section-number">3.1.3</span> Hypothesis testing for a proportion</h3>
<p>To apply the same normal distribution framework in the context of a hypothesis test for a proportion, the independence and success-failure conditions must also be satisfied. However, in a hypothesis test, the success-failure condition is checked using the null proportion: we verify <span class="math inline">\(np_0\)</span> and <span class="math inline">\(n(1-p_0)\)</span> are at least 10, where <span class="math inline">\(p_0\)</span> is the null value.</p>
<p>Deborah Toohey is running for Congress, and her campaign manager claims she has more than 50% support from the district’s electorate. Ms. Toohey’s opponent claimed that Ms. Toohey has <em>less</em> than 50%. Set up a hypothesis test to evaluate who is right.<a href="#fn99" class="footnoteRef" id="fnref99"><sup>99</sup></a></p>
<p><span>A newspaper collects a simple random sample of 500 likely voters in the district and estimates Toohey’s support to be 52%. Does this provide convincing evidence for the claim of Toohey’s manager at the 5% significance level?</span> [TooheyInferenceExample]</p>
<p>Because this is a simple random sample that includes fewer than 10% of the population, the observations are independent. In a one-proportion hypothesis test, the success-failure condition is checked using the null proportion, <span class="math inline">\(p_0=0.5\)</span>: <span class="math inline">\(np_0 = n(1-p_0) = 500\times 0.5 = 250 &gt; 10\)</span>. With these conditions verified, the normal model may be applied to <span class="math inline">\(\hat{p}\)</span>.</p>
<p>Next the standard error can be computed. The null value is used again here, because this is a hypothesis test for a single proportion. <span class="math display">\[SE = \sqrt{\frac{p_0\times (1-p_0)}{n}} = \sqrt{\frac{0.5\times (1-0.5)}{500}} = 0.022\]</span> A picture of the normal model is shown in Figure [pValueForCampaignManagerClaimOfMoreThan50PercentSupport] with the p-value represented by both shaded tails. Based on the normal model, we can compute a test statistic as the Z score of the point estimate: <span class="math display">\[Z = \frac{\text{point estimate} - \text{null value}}{SE} = \frac{0.52 - 0.50}{0.022} = 0.89\]</span> The right tail area is 0.1867, and the p-value is <span class="math inline">\(2 \times 0.1867 = 0.3734\)</span>. Because the p-value is larger than 0.05, we do not reject the null hypothesis, and we do not find convincing evidence to support the campaign manager’s claim.</p>
<div class="figure">
<img src="03/figures/pValueForCampaignManagerClaimOfMoreThan50PercentSupport/pValueForCampaignManagerClaimOfMoreThan50PercentSupport" alt="Sampling distribution of the sample proportion if the null hypothesis is true for Example [TooheyInferenceExample]. The p-value for the test is shaded." />
<p class="caption">Sampling distribution of the sample proportion if the null hypothesis is true for Example [TooheyInferenceExample]. The p-value for the test is shaded.</p>
</div>
<p>[pValueForCampaignManagerClaimOfMoreThan50PercentSupport]</p>
<p><span> Set up hypotheses and verify the conditions using the null value, <span class="math inline">\(p_0\)</span>, to ensure <span class="math inline">\(\hat{p}\)</span> is nearly normal under <span class="math inline">\(H_0\)</span>. If the conditions hold, construct the standard error, again using <span class="math inline">\(p_0\)</span>, and show the p-value in a drawing. Lastly, compute the p-value and evaluate the hypotheses.</span></p>
</div>
<div id="choosing-a-sample-size-when-estimating-a-proportion" class="section level3">
<h3><span class="header-section-number">3.1.4</span> Choosing a sample size when estimating a proportion</h3>
<p>Frequently statisticians find themselves in a position to not only analyze data, but to help others determine how to most effectively collect data and also how much data should be collected. We can perform sample size calculations that are helpful in planning a study. Our task will be to identify an appropriate sample size that ensures the margin of error <span class="math inline">\(ME = z^{\star} SE\)</span> will be no larger than some value <span class="math inline">\(m\)</span>. For example, we might be asked to find a sample size so the margin of error is no larger than <span class="math inline">\(m = 0.04\)</span>, in which case, we write</p>
<p><span class="math display">\[\begin{aligned}
z^{\star} SE \leq 0.04\end{aligned}\]</span></p>
<p>Generally, we plug in a suitable value for <span class="math inline">\(z^{\star}\)</span> for the confidence level we plan to use, write in the formula for the standard error, and then solve for the sample size <span class="math inline">\(n\)</span>. In the case of a single proportion, we use <span class="math inline">\(\sqrt{p(1-p) / n\ }\)</span> for the standard error (<span class="math inline">\(SE\)</span>).</p>
<p><span>If we are conducting a university survey to determine whether students support a $200 per year increase in fees to pay for a new football stadium, how big of a sample is needed to ensure the margin of error is less than 0.04 using a 95% confidence level?</span> For a 95% confidence level, the value <span class="math inline">\(z^{\star}\)</span> corresponds to 1.96, and we can write the margin of error expression as follows:</p>
<p><span class="math display">\[\begin{aligned}
ME = z^{\star}SE = 1.96\times \sqrt{\frac{p(1-p)}{n}} \leq 0.04\end{aligned}\]</span></p>
<p>There are two unknowns in the equation: <span class="math inline">\(p\)</span> and <span class="math inline">\(n\)</span>. If we have an estimate of <span class="math inline">\(p\)</span>, perhaps from a similar survey, we could use that value. If we have no such estimate, we must use some other value for <span class="math inline">\(p\)</span>. The margin of error for a proportion is largest when <span class="math inline">\(p\)</span> is 0.5, so we typically use this <em>worst case estimate</em> if no other estimate is available:</p>
<p><span class="math display">\[\begin{aligned}
    1.96\times \sqrt{\frac{0.5(1-0.5)}{n}} &amp;\leq 0.04 \\
    1.96^2\times \frac{0.5(1-0.5)}{n} &amp;\leq 0.04^2 \\
    1.96^2\times \frac{0.5(1-0.5)}{0.04^2} &amp;\leq n \\
    600.25 &amp;\leq n\end{aligned}\]</span></p>
<p>We would need at least 600.25 participants, which means we need 601 participants or more, to ensure the sample proportion is within 0.04 of the true proportion with 95% confidence. Notice that in such calculations, we always round up for the sample size!</p>
<p>As noted in the example, if we have an estimate of the proportion, we should use it in place of the worst case estimate of the proportion, 0.5.</p>
<p>A manager is about to oversee the mass production of a new tire model in her factory, and she would like to estimate what proportion of these tires will be rejected through quality control. The quality control team has monitored the last three tire models produced by the factory, failing 1.7% of tires in the first model, 6.2% of the second model, and 1.3% of the third model. The manager would like to examine enough tires to estimate the failure rate of the new tire model to within about 2% with a 90% confidence level.<a href="#fn100" class="footnoteRef" id="fnref100"><sup>100</sup></a></p>
<ul>
<li><p>There are three different failure rates to choose from. Perform the sample size computation for each separately, and identify three sample sizes to consider.</p></li>
<li><p>The sample sizes vary widely. Which of the three would you suggest using? What would influence your choice?</p></li>
</ul>
<p>A recent estimate of Congress’ approval rating was 17%.<a href="#fn101" class="footnoteRef" id="fnref101"><sup>101</sup></a> If we were to conduct a new poll and wanted an estimate with a margin of error smaller than about 0.04 with 95% confidence, how big of a sample should we use?<a href="#fn102" class="footnoteRef" id="fnref102"><sup>102</sup></a></p>
</div>
</div>
<div id="differenceOfTwoProportions" class="section level2">
<h2><span class="header-section-number">3.2</span> Difference of two proportions</h2>
<p>We would like to make conclusions about the difference in two population proportions (<span class="math inline">\(p_1 - p_2\)</span>) using the normal model. In this section we consider three such examples. In the first, we compare the approval of the 2010 healthcare law under two different question phrasings. In the second application, a company weighs whether they should switch to a higher quality parts manufacturer. In the last example, we examine the cancer risk to dogs from the use of yard herbicides.</p>
<p>In our investigations, we first identify a reasonable point estimate of <span class="math inline">\(p_1 - p_2\)</span> based on the sample. You may have already guessed its form: <span class="math inline">\(\hat{p}_1 - \hat{p}_2\)</span>. Next, in each example we verify that the point estimate follows the normal model by checking certain conditions; as before, these conditions relate to independence of observations and checking for sufficiently large sample size. Finally, we compute the estimate’s standard error and apply our inferential framework.</p>
<div id="SampleDistributionOfTheDiffOfTwoProportions" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Sample distribution of the difference of two proportions</h3>
<p>We must check two conditions before applying the normal model to <span class="math inline">\(\hat{p}_1 - \hat{p}_2\)</span>. First, the sampling distribution for each sample proportion must be nearly normal, and secondly, the samples must be independent. Under these two conditions, the sampling distribution of <span class="math inline">\(\hat{p}_1 - \hat{p}_2\)</span> may be well approximated using the normal model.</p>
<p>The difference <span class="math inline">\(\hat{p}_1 - \hat{p}_2\)</span> tends to follow a normal model when</p>
<ul>
<li><p>each proportion separately follows a normal model, and</p></li>
<li><p>the two samples are independent of each other.</p></li>
</ul>
<p>The standard error of the difference in sample proportions is</p>
<p><span class="math display">\[\begin{aligned}
SE_{\hat{p}_1 - \hat{p}_2}
    = \sqrt{SE_{\hat{p}_1}^2 + SE_{\hat{p}_2}^2}
    = \sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}
\label{seForDiffOfProp}\end{aligned}\]</span></p>
<p>where <span class="math inline">\(p_1\)</span> and <span class="math inline">\(p_2\)</span> represent the population proportions, and <span class="math inline">\(n_1\)</span> and <span class="math inline">\(n_2\)</span> represent the sample sizes.</p>
</div>
<div id="intervals-and-tests-for-p_1--p_2" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Intervals and tests for <span class="math inline">\(p_1 -p_2\)</span></h3>
<p>In the setting of confidence intervals, the sample proportions are used to verify the success-failure condition and also compute standard error, just as was the case with a single proportion.</p>
<p>The way a question is phrased can influence a person’s response. For example, Pew Research Center conducted a survey with the following question:<a href="#fn103" class="footnoteRef" id="fnref103"><sup>103</sup></a></p>
<blockquote>
<p>As you may know, by 2014 nearly all Americans will be required to have health insurance. [People who do not buy insurance will pay a penalty] while [People who cannot afford it will receive financial help from the government]. Do you approve or disapprove of this policy?</p>
</blockquote>
<p>For each randomly sampled respondent, the statements in brackets were randomized: either they were kept in the order given above, or the two statements were reversed. Table [pewPollResultsForRandomizedStatementOrdering] shows the results of this experiment. Create and interpret a 90% confidence interval of the difference in approval.</p>
<p><span>p<span>50mm</span>c p<span>13mm</span>p<span>14mm</span>p<span>16.5mm</span>c</span> &amp; &amp; Sample size (<span class="math inline">\(n_i\)</span>) &amp; Approve law (%) &amp; Disapprove law (%) &amp; Other<br />
“people who cannot afford it will receive financial help from the government” is given second</p>
<p>&amp; &amp; 771 &amp; 47 &amp; 49 &amp; 3<br />
“people who do not buy it will pay a penalty” is given second &amp; &amp; 732 &amp; 34 &amp; 63 &amp; 3<br />
[pewPollResultsForRandomizedStatementOrdering]</p>
<p>First the conditions must be verified. Because each group is a simple random sample from less than 10% of the population, the observations are independent, both within the samples and between the samples. The success-failure condition also holds for each sample. Because all conditions are met, the normal model can be used for the point estimate of the difference in support, where <span class="math inline">\(p_1\)</span> corresponds to the original ordering and <span class="math inline">\(p_2\)</span> to the reversed ordering: <span class="math display">\[\hat{p}_{1} - \hat{p}_{2} = 0.47 - 0.34 = 0.13\]</span> The standard error may be computed from Equation  using the sample proportions: <span class="math display">\[SE \approx \sqrt{\frac{0.47(1-0.47)}{771} + \frac{0.34(1-0.34)}{732}} = 0.025\]</span> For a 90% confidence interval, we use <span class="math inline">\(z^{\star} = 1.65\)</span>: <span class="math display">\[\text{point estimate} \ \pm\ z^{\star}SE \quad \to \quad 0.13 \ \pm\ 1.65 \times  0.025 \quad \to \quad (0.09, 0.17)\]</span> We are 90% confident that the approval rating for the 2010 healthcare law changes between 9% and 17% due to the ordering of the two statements in the survey question. The Pew Research Center reported that this modestly large difference suggests that the opinions of much of the public are still fluid on the health insurance mandate.</p>
<p>[carWheelGearManufacturer] A remote control car company is considering a new manufacturer for wheel gears. The new manufacturer would be more expensive but their higher quality gears are more reliable, resulting in happier customers and fewer warranty claims. However, management must be convinced that the more expensive gears are worth the conversion before they approve the switch. If there is strong evidence of a more than 3% improvement in the percent of gears that pass inspection, management says they will switch suppliers, otherwise they will maintain the current supplier. Set up appropriate hypotheses for the test.<a href="#fn104" class="footnoteRef" id="fnref104"><sup>104</sup></a></p>
<p><span>The quality control engineer from Guided Practice [carWheelGearManufacturer] collects a sample of gears, examining 1000 gears from each company and finds that 899 gears pass inspection from the current supplier and 958 pass inspection from the prospective supplier. Using these data, evaluate the hypothesis setup of Guided Practice [carWheelGearManufacturer] using a significance level of 5%.</span> First, we check the conditions. The sample is not necessarily random, so to proceed we must assume the gears are all independent; for this sample we will suppose this assumption is reasonable, but the engineer would be more knowledgeable as to whether this assumption is appropriate. The success-failure condition also holds for each sample. Thus, the difference in sample proportions, <span class="math inline">\(0.958-0.899=0.059\)</span>, can be said to come from a nearly normal distribution.</p>
<p>The standard error can be found using Equation : <span class="math display">\[SE = \sqrt{\frac{0.958(1-0.958)}{1000} + \frac{0.899(1-0.899)}{1000}} = 0.0114\]</span> In this hypothesis test, the sample proportions were used. We will discuss this choice more in Section [pooledHTForProportionsSection].</p>
<p>Next, we compute the test statistic and use it to find the p-value, which is depicted in Figure [gearsTwoSampleHTPValueQC]. <span class="math display">\[Z = \frac{\text{point estimate} - \text{null value}}{SE} = \frac{0.059 - 0.03}{0.0114} = 2.54\]</span> Using the normal model for this test statistic, we identify the right tail area as 0.006. Since this is a one-sided test, this single tail area is also the p-value, and we reject the null hypothesis because 0.006 is less than 0.05. That is, we have statistically significant evidence that the higher quality gears actually do pass inspection more than 3% as often as the currently used gears. Based on these results, management will approve the switch to the new supplier.</p>
<div class="figure">
<img src="03/figures/gearsTwoSampleHTPValueQC/gearsTwoSampleHTPValueQC" alt="Distribution of the test statistic if the null hypothesis was true. The p-value is represented by the shaded area." />
<p class="caption">Distribution of the test statistic if the null hypothesis was true. The p-value is represented by the shaded area.</p>
</div>
<p>[gearsTwoSampleHTPValueQC]</p>
</div>
<div id="pooledHTForProportionsSection" class="section level3">
<h3><span class="header-section-number">3.2.3</span> Hypothesis testing when <span class="math inline">\(H_0: p_1=p_2\)</span></h3>
<p>Here we use a new example to examine a special estimate of standard error when <span class="math inline">\(H_0: p_1 = p_2\)</span>. We investigate whether there is an increased risk of cancer in dogs that are exposed to the herbicide 2,4-dichlorophenoxyacetic acid (2,4-D). A study in 1994 examined 491 dogs that had developed cancer and 945 dogs as a control group.<a href="#fn105" class="footnoteRef" id="fnref105"><sup>105</sup></a> Of these two groups, researchers identified which dogs had been exposed to 2,4-D in their owner’s yard. The results are shown in Table [24DAndCancerInDogs].</p>
<table>
<caption>Summary results for cancer in dogs and the use of 2,4-D by the dog’s owner.</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">cancer</th>
<th align="right">no cancer</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2,4-D</td>
<td align="right">191</td>
<td align="right">304</td>
</tr>
<tr class="even">
<td>no 2,4-D</td>
<td align="right">300</td>
<td align="right">641</td>
</tr>
</tbody>
</table>
<p>[24DAndCancerInDogs]</p>
<p>Is this study an experiment or an observational study?<a href="#fn106" class="footnoteRef" id="fnref106"><sup>106</sup></a></p>
<p>[htFor24DAndCancerInDogs] Set up hypotheses to test whether 2,4-D and the occurrence of cancer in dogs are related. Use a one-sided test and compare across the cancer and no cancer groups.<a href="#fn107" class="footnoteRef" id="fnref107"><sup>107</sup></a></p>
<p><span>Are the conditions met to use the normal model and make inference on the results?</span>[condFor24DAndCancerInDogsNormalInference] (1) It is unclear whether this is a random sample. However, if we believe the dogs in both the cancer and no cancer groups are representative of each respective population and that the dogs in the study do not interact in any way, then we may find it reasonable to assume independence between observations. (2) The success-failure condition holds for each sample.</p>
<p>Under the assumption of independence, we can use the normal model and make statements regarding the canine population based on the data.</p>
<p>In your hypotheses for Guided Practice [htFor24DAndCancerInDogs], the null is that the proportion of dogs with exposure to 2,4-D is the same in each group. The point estimate of the difference in sample proportions is <span class="math inline">\(\hat{p}_c - \hat{p}_n = 0.067\)</span>. To identify the p-value for this test, we first check conditions (Example [condFor24DAndCancerInDogsNormalInference]) and compute the standard error of the difference: <span class="math display">\[SE = \sqrt{\frac{p_c(1-p_c)}{n_c} + \frac{p_n(1-p_n)}{n_n}}\]</span> In a hypothesis test, the distribution of the test statistic is always examined as though the null hypothesis is true, i.e. in this case, <span class="math inline">\(p_c = p_n\)</span>. The standard error formula should reflect this equality in the null hypothesis. We will use <span class="math inline">\(p\)</span> to represent the common rate of dogs that are exposed to 2,4-D in the two groups: <span class="math display">\[SE = \sqrt{\frac{p(1-p)}{n_c} + \frac{p(1-p)}{n_n}}\]</span> We don’t know the exposure rate, <span class="math inline">\(p\)</span>, but we can obtain a good estimate of it by <em>pooling</em> the results of both samples: <span class="math display">\[\hat{p} = \frac{\text{\# of ``successes&#39;&#39;}}{\text{\# of cases}} = \frac{191 + 304}{191+300+304+641} = 0.345\]</span> This is called the <strong>pooled estimate</strong> of the sample proportion, and we use it to compute the standard error when the null hypothesis is that <span class="math inline">\(p_1 = p_2\)</span> (e.g. <span class="math inline">\(p_c = p_n\)</span> or <span class="math inline">\(p_c - p_n = 0\)</span>). We also typically use it to verify the success-failure condition.</p>
<p>When the null hypothesis is <span class="math inline">\(p_1 = p_2\)</span>, it is useful to find the pooled estimate of the shared proportion:</p>
<p><span class="math display">\[\begin{aligned}
\hat{p} = \frac{\text{number of ``successes&#39;&#39;}}{\text{number of cases}} = \frac{\hat{p}_1n_1 + \hat{p}_2n_2}{n_1 + n_2}\end{aligned}\]</span></p>
<p>Here <span class="math inline">\(\hat{p}_1n_1\)</span> represents the number of successes in sample 1 since</p>
<p><span class="math display">\[\begin{aligned}
\hat{p}_1 = \frac{\text{number of successes in sample 1}}{n_1}\end{aligned}\]</span></p>
<p>Similarly, <span class="math inline">\(\hat{p}_2n_2\)</span> represents the number of successes in sample 2.</p>
<p>When the null hypothesis suggests the proportions are equal, we use the pooled proportion estimate (<span class="math inline">\(\hat{p}\)</span>) to verify the success-failure condition and also to estimate the standard error:</p>
<p><span class="math display">\[\begin{aligned}
SE = \sqrt{\frac{\hat{p}(1-\hat{p})}{n_1} + \frac{\hat{p}(1-\hat{p})}{n_2}} 
\label{seOfDiffInPropUsingPooledEstimate}\end{aligned}\]</span></p>
<p>[verifySEOfPooledEstimateOf24DWithCancerNoCancerDogs] Using Equation , <span class="math inline">\(\hat{p}=0.345\)</span>, <span class="math inline">\(n_1 = 491\)</span>, and <span class="math inline">\(n_2=945\)</span>, verify the estimate for the standard error is <span class="math inline">\(SE = 0.026\)</span>. Next, complete the hypothesis test using a significance level of 0.05. Be certain to draw a picture, compute the p-value, and state your conclusion in both statistical language and plain language.<a href="#fn108" class="footnoteRef" id="fnref108"><sup>108</sup></a></p>
</div>
</div>
<div id="oneWayChiSquare" class="section level2">
<h2><span class="header-section-number">3.3</span> Testing for goodness of fit using chi-square<br />
(special topic)</h2>
<p>In this section, we develop a method for assessing a null model when the data are binned. This technique is commonly used in two circumstances:</p>
<ul>
<li><p>Given a sample of cases that can be classified into several groups, determine if the sample is representative of the general population.</p></li>
<li><p>Evaluate whether data resemble a particular distribution, such as a normal distribution or a geometric distribution. (Background on the geometric distribution is not necessary.)</p></li>
</ul>
<p>Each of these scenarios can be addressed using the same statistical test: a chi-square test.</p>
<p>In the first case, we consider data from a random sample of 275 jurors in a small county. Jurors identified their racial group, as shown in Table [juryRepresentationAndCityRepresentationForRace], and we would like to determine if these jurors are racially representative of the population. If the jury is representative of the population, then the proportions in the sample should roughly reflect the population of eligible jurors, i.e. registered voters.</p>
<p><span>ll ccc c ll</span> Race &amp;</p>
<p>&amp; White &amp; Black &amp; Hispanic &amp; Other &amp;</p>
<p>&amp; Total<br />
Representation in juries &amp; &amp; 205 &amp; 26 &amp; 25 &amp; 19 &amp; &amp; 275<br />
Registered voters &amp; &amp; 0.72 &amp; 0.07 &amp; 0.12 &amp; 0.09 &amp; &amp; 1.00<br />
[juryRepresentationAndCityRepresentationForRace]</p>
<p>While the proportions in the juries do not precisely represent the population proportions, it is unclear whether these data provide convincing evidence that the sample is not representative. If the jurors really were randomly sampled from the registered voters, we might expect small differences due to chance. However, unusually large differences may provide convincing evidence that the juries were not representative.</p>
<p>A second application, assessing the fit of a distribution, is presented at the end of this section. Daily stock returns from the S&amp;P500 for the years 1990-2011 are used to assess whether stock activity each day is independent of the stock’s behavior on previous days.</p>
<p>In these problems, we would like to examine all bins simultaneously, not simply compare one or two bins at a time, which will require us to develop a new test statistic.</p>
<div id="creating-a-test-statistic-for-one-way-tables" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Creating a test statistic for one-way tables</h3>
<p><span>Of the people in the city, 275 served on a jury. If the individuals are randomly selected to serve on a jury, about how many of the 275 people would we expect to be white? How many would we expect to be black?</span> About 72% of the population is white, so we would expect about 72% of the jurors to be white: <span class="math inline">\(0.72\times 275 = 198\)</span>.</p>
<p>Similarly, we would expect about 7% of the jurors to be black, which would correspond to about <span class="math inline">\(0.07\times 275 = 19.25\)</span> black jurors.</p>
<p>Twelve percent of the population is Hispanic and 9% represent other races. How many of the 275 jurors would we expect to be Hispanic or from another race? Answers can be found in Table [expectedJuryRepresentationIfNoBias].</p>
<p><span>ll ccc c ll</span> Race &amp;</p>
<p>&amp; White &amp; Black &amp; Hispanic &amp; Other &amp;</p>
<p>&amp; Total<br />
Observed data &amp; &amp; 205 &amp; 26 &amp; 25 &amp; 19 &amp; &amp; 275<br />
Expected counts &amp; &amp; 198 &amp; 19.25 &amp; 33 &amp; 24.75 &amp; &amp; 275<br />
[expectedJuryRepresentationIfNoBias]</p>
<p>The sample proportion represented from each race among the 275 jurors was not a precise match for any ethnic group. While some sampling variation is expected, we would expect the sample proportions to be fairly similar to the population proportions if there is no bias on juries. We need to test whether the differences are strong enough to provide convincing evidence that the jurors are not a random sample. These ideas can be organized into hypotheses:</p>
<ul>
<li><p>The jurors are a random sample, i.e. there is no racial bias in who serves on a jury, and the observed counts reflect natural sampling fluctuation.</p></li>
<li><p>The jurors are not randomly sampled, i.e. there is racial bias in juror selection.</p></li>
</ul>
<p>To evaluate these hypotheses, we quantify how different the observed counts are from the expected counts. Strong evidence for the alternative hypothesis would come in the form of unusually large deviations in the groups from what would be expected based on sampling variation alone.</p>
</div>
<div id="chiSquareTestStatistic" class="section level3">
<h3><span class="header-section-number">3.3.2</span> The chi-square test statistic</h3>
<p>In previous hypothesis tests, we constructed a test statistic of the following form: <span class="math display">\[\frac{\text{point estimate} - \text{null value}}{\text{SE of point estimate}}\]</span> This construction was based on (1) identifying the difference between a point estimate and an expected value if the null hypothesis was true, and (2) standardizing that difference using the standard error of the point estimate. These two ideas will help in the construction of an appropriate test statistic for count data.</p>
<p>Our strategy will be to first compute the difference between the observed counts and the counts we would expect if the null hypothesis was true, then we will standardize the difference:</p>
<p><span class="math display">\[\begin{aligned}
Z_{1} = \frac{\text{observed white count} - \text{null white count}}
                {\text{SE of observed white count}}\end{aligned}\]</span></p>
<p>The standard error for the point estimate of the count in binned data is the square root of the count under the null.<a href="#fn109" class="footnoteRef" id="fnref109"><sup>109</sup></a> Therefore:</p>
<p><span class="math display">\[\begin{aligned}
Z_1 = \frac{205 - 198}{\sqrt{198}} = 0.50\end{aligned}\]</span></p>
<p>The fraction is very similar to previous test statistics: first compute a difference, then standardize it. These computations should also be completed for the black, Hispanic, and other groups:</p>
<p><span class="math display">\[\begin{aligned}
&amp;Black &amp;&amp; Hispanic  &amp;&amp;Other \\
&amp; Z_2 = \frac{26-19.25}{\sqrt{19.25}}=1.54\ \ \ \ 
    &amp;&amp; Z_3 = \frac{25-33}{\sqrt{33}}=-1.39\ \ \ \ 
    &amp;&amp; Z_4 = \frac{19-24.75}{\sqrt{24.75}}=-1.16 \\\end{aligned}\]</span></p>
<p>We would like to use a single test statistic to determine if these four standardized differences are irregularly far from zero. That is, <span class="math inline">\(Z_1\)</span>, <span class="math inline">\(Z_2\)</span>, <span class="math inline">\(Z_3\)</span>, and <span class="math inline">\(Z_4\)</span> must be combined somehow to help determine if they – as a group – tend to be unusually far from zero. A first thought might be to take the absolute value of these four standardized differences and add them up:</p>
<p><span class="math display">\[\begin{aligned}
|Z_1| + |Z_2| + |Z_3| + |Z_4| = 4.58\end{aligned}\]</span></p>
<p>Indeed, this does give one number summarizing how far the actual counts are from what was expected. However, it is more common to add the squared values:</p>
<p><span class="math display">\[\begin{aligned}
Z_1^2 + Z_2^2 + Z_3^2 + Z_4^2 = 5.89\end{aligned}\]</span></p>
<p>Squaring each standardized difference before adding them together does two things:</p>
<ul>
<li><p>Any standardized difference that is squared will now be positive.</p></li>
<li><p>Differences that already look unusual – e.g. a standardized difference of 2.5 – will become much larger after being squared.</p></li>
</ul>
<p>The test statistic <span class="math inline">\(X^2\)</span>[</p>
<p><span class="math inline">\(X^2\)</span></p>
<p><br />
chi-square<br />
test statistic]</p>
<p><span class="math inline">\(X^2\)</span></p>
<p><br />
chi-square<br />
test statistic</p>
<p>, which is the sum of the <span class="math inline">\(Z^2\)</span> values, is generally used for these reasons. We can also write an equation for <span class="math inline">\(X^2\)</span> using the observed counts and null counts: The final number <span class="math inline">\(X^2\)</span> summarizes how strongly the observed counts tend to deviate from the null counts. In Section [pValueForAChiSquareTest], we will see that if the null hypothesis is true, then <span class="math inline">\(X^2\)</span> follows a new distribution called a <em>chi-square distribution</em>. Using this distribution, we will be able to obtain a p-value to evaluate the hypotheses.</p>
</div>
<div id="the-chi-square-distribution-and-finding-areas" class="section level3">
<h3><span class="header-section-number">3.3.3</span> The chi-square distribution and finding areas</h3>
<p>The <strong>chi-square distribution</strong> is sometimes used to characterize data sets and statistics that are always positive and typically right skewed. Recall the normal distribution had two parameters – mean and standard deviation – that could be used to describe its exact characteristics. The chi-square distribution has just one parameter called , which influences the shape, center, and spread of the distribution.</p>
<p>[exerChiSquareDistributionDescriptionWithMoreDOF] Figure [chiSquareDistributionWithInceasingDF] shows three chi-square distributions. (a) How does the center of the distribution change when the degrees of freedom is larger? (b) What about the variability (spread)? (c) How does the shape change?<a href="#fn110" class="footnoteRef" id="fnref110"><sup>110</sup></a></p>
<div class="figure">
<img src="03/figures/chiSquareDistributionWithInceasingDF/chiSquareDistributionWithInceasingDF" alt="Three chi-square distributions with varying degrees of freedom." />
<p class="caption">Three chi-square distributions with varying degrees of freedom.</p>
</div>
<p>[chiSquareDistributionWithInceasingDF]</p>
<p>Figure [chiSquareDistributionWithInceasingDF] and Guided Practice [exerChiSquareDistributionDescriptionWithMoreDOF] demonstrate three general properties of chi-square distributions as the degrees of freedom increases: the distribution becomes more symmetric, the center moves to the right, and the variability inflates.</p>
<p>Our principal interest in the chi-square distribution is the calculation of p-values, which (as we have seen before) is related to finding the relevant area in the tail of a distribution. To do so, a new table is needed: the <strong>chi-square table</strong>, partially shown in Table [chiSquareProbabilityTableShort]. A more complete table is presented in Appendix . Using this table, we identify a range for the area, and we examine a particular row for distributions with different degrees of freedom. One important quality of this table: the chi-square table only provides upper tail values.</p>
<table style="width:98%;">
<caption>A section of the chi-square table. A complete table is listed in Appendix .</caption>
<colgroup>
<col width="53%" />
<col width="5%" />
<col width="4%" />
<col width="4%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="6%" />
<col width="6%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">Upper tail</th>
<th align="right">0.3</th>
<th align="right">0.2</th>
<th align="right">0.1</th>
<th align="right">0.05</th>
<th align="right">0.02</th>
<th align="right">0.01</th>
<th align="right">0.005</th>
<th align="right">0.001</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">df 2</td>
<td align="right">2.41</td>
<td align="right"></td>
<td align="right"></td>
<td align="right">5.99</td>
<td align="right">7.82</td>
<td align="right">9.21</td>
<td align="right">10.60</td>
<td align="right">13.82</td>
</tr>
<tr class="even">
<td align="right"><em>3 &amp; </em>3.66 &amp; <em>4.64 &amp; </em>&amp; <em>7.81 &amp; </em>9.84 &amp; <em>11.34 &amp; </em>12.84 &amp; <em>16.27<br />
4 &amp; 4.88 &amp; 5.99 &amp; 7.78 &amp; 9.49 &amp; 11.67 &amp; 13.28 &amp; 14.86 &amp; 18.47<br />
5 &amp; 6.06 &amp; 7.29 &amp; 9.24 &amp; 11.07 &amp; 13.39 &amp; 15.09 &amp; 16.75 &amp; 20.52<br />
6 &amp; 7.23 &amp; 8.56 &amp; 10.64 &amp; 12.59 &amp; 15.03 &amp; 16.81 &amp; 18.55 &amp; 22.46<br />
7 &amp; 8.38 &amp; 9.80 &amp; 12.02 &amp; 14.07 &amp; 16.62 &amp; 18.48 &amp; 20.28 &amp; 24.32<br />
</em>********</td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
<td align="right"></td>
</tr>
</tbody>
</table>
<p>[chiSquareProbabilityTableShort]</p>
<p><span>Figure [chiSquareAreaAbove6Point25WithDF3] shows a chi-square distribution with 3 degrees of freedom and an upper shaded tail starting at 6.25. Use Table [chiSquareProbabilityTableShort] to estimate the shaded area.</span>[chisquaredistexample01] This distribution has three degrees of freedom, so only the row with 3 degrees of freedom (df) is relevant. This row has been italicized in the table. Next, we see that the value – 6.25 – falls in the column with upper tail area 0.1. That is, the shaded upper tail of Figure [chiSquareAreaAbove6Point25WithDF3] has area 0.1.</p>
<p>[arrayOfFigureAreasForChiSquareDistribution]</p>
<p><span>We rarely observe the <em>exact</em> value in the table. For instance, Figure [chiSquareAreaAbove4Point3WithDF2] shows the upper tail of a chi-square distribution with 2 degrees of freedom. The bound for this upper tail is at 4.3, which does not fall in Table [chiSquareProbabilityTableShort]. Find the approximate tail area.</span>[chisquaredistexample02] The cutoff 4.3 falls between the second and third columns in the 2 degrees of freedom row. Because these columns correspond to tail areas of 0.2 and 0.1, we can be certain that the area shaded in Figure [chiSquareAreaAbove4Point3WithDF2] is between 0.1 and 0.2.</p>
<p><span>Figure [chiSquareAreaAbove5Point1WithDF5] shows an upper tail for a chi-square distribution with 5 degrees of freedom and a cutoff of 5.1. Find the tail area.</span>[chisquaredistexample03] Looking in the row with 5 df, 5.1 falls below the smallest cutoff for this row (6.06). That means we can only say that the area is <em>greater than 0.3</em>.</p>
<p>[ChiSquareDistGuidedPractice01] Figure [chiSquareAreaAbove11Point7WithDF7] shows a cutoff of 11.7 on a chi-square distribution with 7 degrees of freedom. Find the area of the upper tail.<a href="#fn111" class="footnoteRef" id="fnref111"><sup>111</sup></a></p>
<p>[ChiSquareDistGuidedPractice02] Figure [chiSquareAreaAbove10WithDF4] shows a cutoff of 10 on a chi-square distribution with 4 degrees of freedom. Find the area of the upper tail.<a href="#fn112" class="footnoteRef" id="fnref112"><sup>112</sup></a></p>
<p>[ChiSquareDistGuidedPractice03] Figure [chiSquareAreaAbove9Point21WithDF3] shows a cutoff of 9.21 with a chi-square distribution with 3 df. Find the area of the upper tail.<a href="#fn113" class="footnoteRef" id="fnref113"><sup>113</sup></a></p>
</div>
<div id="pValueForAChiSquareTest" class="section level3">
<h3><span class="header-section-number">3.3.4</span> Finding a p-value for a chi-square distribution</h3>
<p>In Section [chiSquareTestStatistic], we identified a new test statistic (<span class="math inline">\(X^2\)</span>) within the context of assessing whether there was evidence of racial bias in how jurors were sampled. The null hypothesis represented the claim that jurors were randomly sampled and there was no racial bias. The alternative hypothesis was that there was racial bias in how the jurors were sampled.</p>
<p>We determined that a large <span class="math inline">\(X^2\)</span> value would suggest strong evidence favoring the alternative hypothesis: that there was racial bias. However, we could not quantify what the chance was of observing such a large test statistic (<span class="math inline">\(X^2=5.89\)</span>) if the null hypothesis actually was true. This is where the chi-square distribution becomes useful. If the null hypothesis was true and there was no racial bias, then <span class="math inline">\(X^2\)</span> would follow a chi-square distribution, with three degrees of freedom in this case. Under certain conditions, the statistic <span class="math inline">\(X^2\)</span> follows a chi-square distribution with <span class="math inline">\(k-1\)</span> degrees of freedom, where <span class="math inline">\(k\)</span> is the number of bins.</p>
<p><span>How many categories were there in the juror example? How many degrees of freedom should be associated with the chi-square distribution used for <span class="math inline">\(X^2\)</span>?</span> In the jurors example, there were <span class="math inline">\(k=4\)</span> categories: white, black, Hispanic, and other. According to the rule above, the test statistic <span class="math inline">\(X^2\)</span> should then follow a chi-square distribution with <span class="math inline">\(k-1 = 3\)</span> degrees of freedom if <span class="math inline">\(H_0\)</span> is true.</p>
<p>Just like we checked sample size conditions to use the normal model in earlier sections, we must also check a sample size condition to safely apply the chi-square distribution for <span class="math inline">\(X^2\)</span>. Each expected count must be at least 5. In the juror example, the expected counts were 198, 19.25, 33, and 24.75, all easily above 5, so we can apply the chi-square model to the test statistic, <span class="math inline">\(X^2=5.89\)</span>.</p>
<p><span>If the null hypothesis is true, the test statistic <span class="math inline">\(X^2=5.89\)</span> would be closely associated with a chi-square distribution with three degrees of freedom. Using this distribution and test statistic, identify the p-value.</span> The chi-square distribution and p-value are shown in Figure [jurorHTPValueShown]. Because larger chi-square values correspond to stronger evidence against the null hypothesis, we shade the upper tail to represent the p-value. Using the chi-square table in Appendix [chiSquareProbabilityTable] or the short table on page , we can determine that the area is between 0.1 and 0.2. That is, the p-value is larger than 0.1 but smaller than 0.2. Generally we do not reject the null hypothesis with such a large p-value. In other words, the data do not provide convincing evidence of racial bias in the juror selection.</p>
<div class="figure">
<img src="03/figures/jurorHTPValueShown/jurorHTPValueShown" alt="The p-value for the juror hypothesis test is shaded in the chi-square distribution with df=3." />
<p class="caption">The p-value for the juror hypothesis test is shaded in the chi-square distribution with <span class="math inline">\(df=3\)</span>.</p>
</div>
<p>[jurorHTPValueShown]</p>
<p>Suppose we are to evaluate whether there is convincing evidence that a set of observed counts <span class="math inline">\(O_1\)</span>, <span class="math inline">\(O_2\)</span>, …, <span class="math inline">\(O_k\)</span> in <span class="math inline">\(k\)</span> categories are unusually different from what might be expected under a null hypothesis. Call the <em>expected counts</em> that are based on the null hypothesis <span class="math inline">\(E_1\)</span>, <span class="math inline">\(E_2\)</span>, …, <span class="math inline">\(E_k\)</span>. If each expected count is at least 5 and the null hypothesis is true, then the test statistic below follows a chi-square distribution with <span class="math inline">\(k-1\)</span> degrees of freedom:</p>
<p><span class="math display">\[\begin{aligned}
X^2 = \frac{(O_1 - E_1)^2}{E_1} + \frac{(O_2 - E_2)^2}{E_2} + \cdots + \frac{(O_k - E_k)^2}{E_k}\end{aligned}\]</span></p>
<p>The p-value for this test statistic is found by looking at the upper tail of this chi-square distribution. We consider the upper tail because larger values of <span class="math inline">\(X^2\)</span> would provide greater evidence against the null hypothesis.</p>
<p>There are three conditions that must be checked before performing a chi-square test:</p>
<dl>
<dt>Independence.</dt>
<dd><p>Each case that contributes a count to the table must be independent of all the other cases in the table.</p>
</dd>
<dt>Sample size / distribution.</dt>
<dd><p>Each particular scenario (i.e. cell count) must have at least 5 expected cases.</p>
</dd>
<dt>Degrees of freedom</dt>
<dd><p>We only apply the chi-square technique when the table is associated with a chi-square distribution with 2 or more degrees of freedom.</p>
</dd>
</dl>
<p>Failing to check conditions may affect the test’s error rates.</p>
<p>When examining a table with just two bins, pick a single bin and use the one-proportion methods introduced in Section [singleProportion].</p>
</div>
<div id="evaluating-goodness-of-fit-for-a-distribution" class="section level3">
<h3><span class="header-section-number">3.3.5</span> Evaluating goodness of fit for a distribution</h3>
<p>We can apply our new chi-square testing framework to the second problem in this section: evaluating whether a certain statistical model fits a data set. Daily stock returns from the S&amp;P500 for 1990-2011 can be used to assess whether stock activity each day is independent of the stock’s behavior on previous days. This sounds like a very complex question, and it is, but a chi-square test can be used to study the problem. We will label each day as or () depending on whether the market was up or down that day. For example, consider the following changes in price, their new labels of up and down, and then the number of days that must be observed before each day:</p>
<p><span>lc ccc ccc ccc cc</span> Change in price &amp;</p>
<p>&amp; 2.52 &amp; -1.46 &amp; 0.51 &amp; -4.07 &amp; 3.36 &amp; 1.10 &amp; -5.46 &amp; -1.03 &amp; -2.99 &amp; 1.71<br />
Outcome &amp;</p>
<p>&amp; Up &amp; D &amp; Up &amp; D &amp; Up &amp; Up &amp; D &amp; D &amp; D &amp; Up<br />
Days to Up &amp;</p>
<p>&amp; 1 &amp; - &amp; 2 &amp; - &amp; 2 &amp; 1 &amp; - &amp; - &amp; - &amp; 4<br />
If the days really are independent, then the number of days until a positive trading day should follow a geometric distribution. The geometric distribution describes the probability of waiting for the <span class="math inline">\(k^{th}\)</span> trial to observe the first success. Here each up day (Up) represents a success, and down (D) days represent failures. In the data above, it took only one day until the market was up, so the first wait time was 1 day. It took two more days before we observed our next trading day, and two more for the third day. We would like to determine if these counts (1, 2, 2, 1, 4, and so on) follow the geometric distribution. Table [sAndP500For1990To2011TimeToPosTrade] shows the number of waiting days for a positive trading day during 1990-2011 for the S&amp;P500.</p>
<p><span>ll ccc ccc c ll</span> Days &amp;</p>
<p>&amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7+ &amp;</p>
<p>&amp; Total<br />
Observed &amp; &amp; 1532 &amp; 760 &amp; 338 &amp; 194 &amp; 74 &amp; 33 &amp; 17 &amp; &amp; 2948<br />
[sAndP500For1990To2011TimeToPosTrade]</p>
<p>We consider how many days one must wait until observing an day on the S&amp;P500 stock exchange. If the stock activity was independent from one day to the next and the probability of a positive trading day was constant, then we would expect this waiting time to follow a <em>geometric distribution</em>. We can organize this into a hypothesis framework:</p>
<ul>
<li><p>The stock market being up or down on a given day is independent from all other days. We will consider the number of days that pass until an day is observed. Under this hypothesis, the number of days until an day should follow a geometric distribution.</p></li>
<li><p>The stock market being up or down on a given day is not independent from all other days. Since we know the number of days until an day would follow a geometric distribution under the null, we look for deviations from the geometric distribution, which would support the alternative hypothesis.</p></li>
</ul>
<p>There are important implications in our result for stock traders: if information from past trading days is useful in telling what will happen today, that information may provide an advantage over other traders.</p>
<p>We consider data for the S&amp;P500 from 1990 to 2011 and summarize the waiting times in Table [sAndP500For1990To2011TimeToPosTrade2] and Figure [geomFitEvaluationForSP500For1990To2011]. The S&amp;P500 was positive on 53.2% of those days.</p>
<p><span>ll ccc ccc c ll</span> Days &amp;</p>
<p>&amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7+ &amp;</p>
<p>&amp; Total<br />
Observed &amp; &amp; 1532 &amp; 760 &amp; 338 &amp; 194 &amp; 74 &amp; 33 &amp; 17 &amp; &amp; 2948<br />
Geometric Model &amp; &amp; 1569 &amp; 734 &amp; 343 &amp; 161 &amp; 75 &amp; 35 &amp; 31 &amp; &amp; 2948<br />
[sAndP500For1990To2011TimeToPosTrade2]</p>
<div class="figure">
<img src="03/figures/geomFitEvaluationForSP500For1990To2011/geomFitEvaluationForSP500For1990To2011" alt="Side-by-side bar plot of the observed and expected counts for each waiting time." />
<p class="caption">Side-by-side bar plot of the observed and expected counts for each waiting time.</p>
</div>
<p>[geomFitEvaluationForSP500For1990To2011]</p>
<p>Because applying the chi-square framework requires expected counts to be at least 5, we have <em>binned</em> together all the cases where the waiting time was at least 7 days to ensure each expected count is well above this minimum. The actual data, shown in the <em>Observed</em> row in Table [sAndP500For1990To2011TimeToPosTrade2], can be compared to the expected counts from the <em>Geometric Model</em> row. The method for computing expected counts is discussed in Table [sAndP500For1990To2011TimeToPosTrade2]. In general, the expected counts are determined by (1) identifying the null proportion associated with each bin, then (2) multiplying each null proportion by the total count to obtain the expected counts. That is, this strategy identifies what proportion of the total count we would expect to be in each bin.</p>
<p><span>Do you notice any unusually large deviations in the graph? Can you tell if these deviations are due to chance just by looking?</span> It is not obvious whether differences in the observed counts and the expected counts from the geometric distribution are significantly different. That is, it is not clear whether these deviations might be due to chance or whether they are so strong that the data provide convincing evidence against the null hypothesis. However, we can perform a chi-square test using the counts in Table [sAndP500For1990To2011TimeToPosTrade2].</p>
<p>Table [sAndP500For1990To2011TimeToPosTrade2] provides a set of count data for waiting times (<span class="math inline">\(O_1=1532\)</span>, <span class="math inline">\(O_2=760\)</span>, …) and expected counts under the geometric distribution (<span class="math inline">\(E_1=1569\)</span>, <span class="math inline">\(E_2=734\)</span>, …). Compute the chi-square test statistic, <span class="math inline">\(X^2\)</span>.<a href="#fn114" class="footnoteRef" id="fnref114"><sup>114</sup></a></p>
<p>Because the expected counts are all at least 5, we can safely apply the chi-square distribution to <span class="math inline">\(X^2\)</span>. However, how many degrees of freedom should we use?<a href="#fn115" class="footnoteRef" id="fnref115"><sup>115</sup></a></p>
<p><span>If the observed counts follow the geometric model, then the chi-square test statistic <span class="math inline">\(X^2=15.08\)</span> would closely follow a chi-square distribution with <span class="math inline">\(df=6\)</span>. Using this information, compute a p-value.</span> [RejectGeomModelForSP500StockDataFor1990To2011] Figure [geomFitPValueForSP500For1990To2011] shows the chi-square distribution, cutoff, and the shaded p-value. If we look up the statistic <span class="math inline">\(X^2=15.08\)</span> in Appendix [chiSquareProbabilityTable], we find that the p-value is between 0.01 and 0.02. In other words, we have sufficient evidence to reject the notion that the wait times follow a geometric distribution, i.e. trading days are not independent and past days may help predict what the stock market will do today.</p>
<div class="figure">
<img src="03/figures/geomFitPValueForSP500For1990To2011/geomFitPValueForSP500For1990To2011" alt="Chi-square distribution with 6 degrees of freedom. The p-value for the stock analysis is shaded." />
<p class="caption">Chi-square distribution with 6 degrees of freedom. The p-value for the stock analysis is shaded.</p>
</div>
<p>[geomFitPValueForSP500For1990To2011]</p>
<p><span>In Example [RejectGeomModelForSP500StockDataFor1990To2011], we rejected the null hypothesis that the trading days are independent. Why is this so important?</span> Because the data provided strong evidence that the geometric distribution is not appropriate, we reject the claim that trading days are independent. While it is not obvious how to exploit this information, it suggests there are some hidden patterns in the data that could be interesting and possibly useful to a stock trader.</p>
</div>
</div>
<div id="twoWayTablesAndChiSquare" class="section level2">
<h2><span class="header-section-number">3.4</span> Testing for independence in two-way tables<br />
(special topic)</h2>
<p>Google is constantly running experiments to test new search algorithms. For example, Google might test three algorithms using a sample of 10,000 google.com search queries. Table [googleSearchAlgorithmByAlgorithmOnly] shows an example of 10,000 queries split into three algorithm groups.<a href="#fn116" class="footnoteRef" id="fnref116"><sup>116</sup></a> The group sizes were specified before the start of the experiment to be 5000 for the current algorithm and 2500 for each test algorithm.</p>
<p><span>ll ccc ll</span> Search algorithm &amp;</p>
<p>&amp; current &amp; test 1 &amp; test 2 &amp;</p>
<p>&amp; Total<br />
Counts &amp; &amp; 5000 &amp; 2500 &amp; 2500 &amp; &amp; 10000<br />
[googleSearchAlgorithmByAlgorithmOnly]</p>
<p><span>What is the ultimate goal of the Google experiment? What are the null and alternative hypotheses, in regular words?</span> The ultimate goal is to see whether there is a difference in the performance of the algorithms. The hypotheses can be described as the following:</p>
<ul>
<li><p>The algorithms each perform equally well.</p></li>
<li><p>The algorithms do not perform equally well.</p></li>
</ul>
<p>In this experiment, the explanatory variable is the search algorithm. However, an outcome variable is also needed. This outcome variable should somehow reflect whether the search results align with the user’s interests. One possible way to quantify this is to determine whether (1) the user clicked one of the links provided and did not try a new search, or (2) the user performed a related search. Under scenario (1), we might think that the user was satisfied with the search results. Under scenario (2), the search results probably were not relevant, so the user tried a second search.</p>
<p>Table [googleSearchAlgorithmByAlgorithmAndPerformanceWithTotals] provides the results from the experiment. These data are very similar to the count data in Section [oneWayChiSquare]. However, now the different combinations of two variables are binned in a <em>two-way</em> table. In examining these data, we want to evaluate whether there is strong evidence that at least one algorithm is performing better than the others. To do so, we apply a chi-square test to this two-way table. The ideas of this test are similar to those ideas in the one-way table case. However, degrees of freedom and expected counts are computed a little differently than before.</p>
<p><span>ll ccc ll</span> Search algorithm &amp;</p>
<p>&amp; current &amp; test 1 &amp; test 2 &amp;</p>
<p>&amp; Total<br />
No new search &amp; &amp; 3511 &amp; 1749 &amp; 1818 &amp; &amp; 7078<br />
New search &amp; &amp; 1489 &amp; 751 &amp; 682 &amp; &amp; 2922<br />
Total &amp; &amp; 5000 &amp; 2500 &amp; 2500 &amp; &amp; 10000<br />
[googleSearchAlgorithmByAlgorithmAndPerformanceWithTotals]</p>
<p><span> A one-way table describes counts for each outcome in a single variable. A two-way table describes counts for <em>combinations</em> of outcomes for two variables. When we consider a two-way table, we often would like to know, are these variables related in any way? That is, are they dependent (versus independent)?</span></p>
<p>The hypothesis test for this Google experiment is really about assessing whether there is statistically significant evidence that the choice of the algorithm affects whether a user performs a second search. In other words, the goal is to check whether the <strong>search</strong> variable is independent of the <strong>algorithm</strong> variable.</p>
<div id="expected-counts-in-two-way-tables" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Expected counts in two-way tables</h3>
<p><span>From the experiment, we estimate the proportion of users who were satisfied with their initial search (no new search) as <span class="math inline">\(7078/10000 = 0.7078\)</span>. If there really is no difference among the algorithms and 70.78% of people are satisfied with the search results, how many of the 5000 people in the “current algorithm” group would be expected to not perform a new search?</span> [googleExampleComputingTheExpectedNumberOfCurrentGroupWithNoNewSearch] About 70.78% of the 5000 would be satisfied with the initial search: <span class="math display">\[0.7078\times 5000 = 3539\text{ users}\]</span> That is, if there was no difference between the three groups, then we would expect 3539 of the current algorithm users not to perform a new search.</p>
<p>[googleExampleComputingTheExpectedNumberOfNewAlgGroupWithNoNewSearch] Using the same rationale described in Example [googleExampleComputingTheExpectedNumberOfCurrentGroupWithNoNewSearch], about how many users in each test group would not perform a new search if the algorithms were equally helpful?<a href="#fn117" class="footnoteRef" id="fnref117"><sup>117</sup></a></p>
<p>We can compute the expected number of users who would perform a new search for each group using the same strategy employed in Example [googleExampleComputingTheExpectedNumberOfCurrentGroupWithNoNewSearch] and Guided Practice [googleExampleComputingTheExpectedNumberOfNewAlgGroupWithNoNewSearch]. These expected counts were used to construct Table [googleSearchAlgorithmByAlgorithmAndPerformanceWithExpectedCounts], which is the same as Table [googleSearchAlgorithmByAlgorithmAndPerformanceWithTotals], except now the expected counts have been added in parentheses.</p>
<p><span>l lll lll lll l</span> Search algorithm</p>
<p>&amp; &amp;&amp; &amp;&amp; &amp;</p>
<p>&amp; Total<br />
No new search &amp; 3511 &amp; &amp;&amp; 1749 &amp; &amp;&amp; 1818 &amp; &amp; &amp; 7078<br />
New search &amp; 1489 &amp; &amp;&amp; 751 &amp; &amp;&amp; 682 &amp; &amp; &amp; 2922<br />
Total &amp; 5000 &amp;&amp;&amp; 2500 &amp;&amp;&amp; 2500 &amp;&amp;&amp; 10000<br />
[googleSearchAlgorithmByAlgorithmAndPerformanceWithExpectedCounts]</p>
<p>The examples and guided practice above provided some help in computing expected counts. In general, expected counts for a two-way table may be computed using the row totals, column totals, and the table total. For instance, if there was no difference between the groups, then about 70.78% of each column should be in the first row:</p>
<p><span class="math display">\[\begin{aligned}
0.7078\times (\text{column 1 total}) &amp;= 3539 \\
0.7078\times (\text{column 2 total}) &amp;= 1769.5 \\
0.7078\times (\text{column 3 total}) &amp;= 1769.5\end{aligned}\]</span></p>
<p>Looking back to how the fraction 0.7078 was computed – as the fraction of users who did not perform a new search (<span class="math inline">\(7078/10000\)</span>) – these three expected counts could have been computed as</p>
<p><span class="math display">\[\begin{aligned}
\left(\frac{\text{row 1 total}}{\text{table total}}\right)\text{(column 1 total)} &amp;= 3539 \\
\left(\frac{\text{row 1 total}}{\text{table total}}\right)\text{(column 2 total)} &amp;= 1769.5 \\
\left(\frac{\text{row 1 total}}{\text{table total}}\right)\text{(column 3 total)} &amp;= 1769.5\end{aligned}\]</span></p>
<p>This leads us to a general formula for computing expected counts in a two-way table when we would like to test whether there is strong evidence of an association between the column variable and row variable.</p>
<p>To identify the expected count for the <span class="math inline">\(i^{th}\)</span> row and <span class="math inline">\(j^{th}\)</span> column, compute $$<sub>i,j</sub> =</p>
<p>$$</p>
</div>
<div id="the-chi-square-test-for-two-way-tables" class="section level3">
<h3><span class="header-section-number">3.4.2</span> The chi-square test for two-way tables</h3>
<p>The chi-square test statistic for a two-way table is found the same way it is found for a one-way table. For each table count, compute</p>
<p><span class="math display">\[\begin{aligned}
&amp;\text{General formula}&amp; &amp;\frac{(\text{observed count } - \text{ expected count})^2}{\text{expected count}} \\
&amp;\text{Row 1, Col 1}&amp; &amp;\frac{(3511 - 3539)^2}{3539} = 0.222 \\
&amp;\text{Row 1, Col 2}&amp; &amp;\frac{(1749 - 1769.5)^2}{1769.5} = 0.237 \\
&amp; \hspace{9mm}\vdots &amp; &amp;\hspace{13mm}\vdots \\
&amp;\text{Row 2, Col 3}&amp; &amp;\frac{(682 - 730.5)^2}{730.5} = 3.220\end{aligned}\]</span></p>
<p>Adding the computed value for each cell gives the chi-square test statistic <span class="math inline">\(X^2\)</span>: <span class="math display">\[X^2 = 0.222 + 0.237 + \dots + 3.220 = 6.120\]</span> Just like before, this test statistic follows a chi-square distribution. However, the degrees of freedom are computed a little differently for a two-way table.<a href="#fn118" class="footnoteRef" id="fnref118"><sup>118</sup></a> For two way tables, the degrees of freedom is equal to</p>
<p><span class="math display">\[\begin{aligned}
df = \text{(number of rows minus 1)}\times \text{(number of columns minus 1)}\end{aligned}\]</span></p>
<p>In our example, the degrees of freedom parameter is</p>
<p><span class="math display">\[\begin{aligned}
df = (2-1)\times (3-1) = 2\end{aligned}\]</span></p>
<p>If the null hypothesis is true (i.e. the algorithms are equally useful), then the test statistic <span class="math inline">\(X^2 = 6.12\)</span> closely follows a chi-square distribution with 2 degrees of freedom. Using this information, we can compute the p-value for the test, which is depicted in Figure [googleHTForDiffAlgPerformancePValue].</p>
<p><span> When applying the chi-square test to a two-way table, we use <span class="math display">\[df = (R-1)\times (C-1)\]</span> where <span class="math inline">\(R\)</span> is the number of rows in the table and <span class="math inline">\(C\)</span> is the number of columns.</span></p>
<p><span> When analyzing 2-by-2 contingency tables, use the two-proportion methods introduced in Section [differenceOfTwoProportions].</span></p>
<div class="figure">
<img src="03/figures/googleHTForDiffAlgPerformancePValue/googleHTForDiffAlgPerformancePValue" alt="Computing the p-value for the Google hypothesis test." />
<p class="caption">Computing the p-value for the Google hypothesis test.</p>
</div>
<p>[googleHTForDiffAlgPerformancePValue]</p>
<p><span>Compute the p-value and draw a conclusion about whether the search algorithms have different performances.</span> Looking in Appendix [chiSquareProbabilityTable] on page , we examine the row corresponding to 2 degrees of freedom. The test statistic, <span class="math inline">\(X^2=6.120\)</span>, falls between the fourth and fifth columns, which means the p-value is between 0.02 and 0.05. Because we typically test at a significance level of <span class="math inline">\(\alpha=0.05\)</span> and the p-value is less than 0.05, the null hypothesis is rejected. That is, the data provide convincing evidence that there is some difference in performance among the algorithms.</p>
<p><span>Table [pewResearchPollOnApprovalRatingsForChiSquareSectionExampleAndExercises] summarizes the results of a Pew Research poll.<a href="#fn119" class="footnoteRef" id="fnref119"><sup>119</sup></a> We would like to determine if there are actually differences in the approval ratings of Barack Obama, Democrats in Congress, and Republicans in Congress. What are appropriate hypotheses for such a test?</span>[hypothesisTestSetupForPewResearchPollOnApprovalRatingsForChiSquareSection]</p>
<ul>
<li><p>There is no difference in approval ratings between the three groups.</p></li>
<li><p>There is some difference in approval ratings between the three groups, e.g. perhaps Obama’s approval differs from Democrats in Congress.</p></li>
</ul>
<p><span>ll ccc ll</span> &amp; &amp; &amp; &amp;<br />
&amp;</p>
<p>&amp; Obama &amp; Democrats &amp; Republicans &amp;</p>
<p>&amp; Total<br />
Approve &amp; &amp; 842 &amp; 736 &amp; 541 &amp; &amp; 2119<br />
Disapprove &amp; &amp; 616 &amp; 646 &amp; 842 &amp; &amp; 2104<br />
Total &amp; &amp; 1458 &amp; 1382 &amp; 1383 &amp; &amp; 4223<br />
[pewResearchPollOnApprovalRatingsForChiSquareSectionExampleAndExercises]</p>
<p>A chi-square test for a two-way table may be used to test the hypotheses in Example [hypothesisTestSetupForPewResearchPollOnApprovalRatingsForChiSquareSection]. As a first step, compute the expected values for each of the six table cells.<a href="#fn120" class="footnoteRef" id="fnref120"><sup>120</sup></a></p>
<p>Compute the chi-square test statistic.<a href="#fn121" class="footnoteRef" id="fnref121"><sup>121</sup></a></p>
<p>Because there are 2 rows and 3 columns, the degrees of freedom for the test is <span class="math inline">\(df=(2-1)\times (3-1) = 2\)</span>. Use <span class="math inline">\(X^2=106.4\)</span>, <span class="math inline">\(df=2\)</span>, and the chi-square table on page  to evaluate whether to reject the null hypothesis.<a href="#fn122" class="footnoteRef" id="fnref122"><sup>122</sup></a></p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="97">
<li id="fn97"><p>Diez DM, Barr CD, and Çetinkaya-Rundel M. 2012. <em>openintro</em>: OpenIntro data sets and supplemental functions. <a href="http://cran.r-project.org/web/packages/openintro">cran.r-project.org/web/packages/openintro</a>.<a href="inferenceForCategoricalData.html#fnref97">↩</a></p></li>
<li id="fn98"><p>Yes. Constant variability, nearly normal residuals, and linearity all appear reasonable.<a href="inferenceForCategoricalData.html#fnref98">↩</a></p></li>
<li id="fn99"><p><span class="math inline">\(\hat{y} = 36.21 + 5.13x_1 + 1.08x_2 - 0.03x_3 + 7.29x_4\)</span>, and there are <span class="math inline">\(k=4\)</span> predictor variables.<a href="inferenceForCategoricalData.html#fnref99">↩</a></p></li>
<li id="fn100"><p>It is the average difference in auction price for each additional Wii wheel included when holding the other variables constant. The point estimate is <span class="math inline">\(b_4 = 7.29\)</span>.<a href="inferenceForCategoricalData.html#fnref100">↩</a></p></li>
<li id="fn101"><p><span class="math inline">\(e_i = y_i - \hat{y_i} = 51.55 - 49.62 = 1.93\)</span>, where 49.62 was computed using the variables values from the observation and the equation identified in Guided Practice [eqForMultipleRegrOfTotalPrForAllPredictorsWithCoefficients].<a href="inferenceForCategoricalData.html#fnref101">↩</a></p></li>
<li id="fn102"><p>Three of the variables (, , and <strong>wheels</strong>) do take value 0, but the auction duration is always one or more days. If the auction is not up for any days, then no one can bid on it! That means the total auction price would always be zero for such an auction; the interpretation of the intercept in this setting is not insightful.<a href="inferenceForCategoricalData.html#fnref102">↩</a></p></li>
<li id="fn103"><p><span class="math inline">\(R^2 = 1 - \frac{23.34}{83.06} = 0.719\)</span>.<a href="inferenceForCategoricalData.html#fnref103">↩</a></p></li>
<li id="fn104"><p>In multiple regression, the degrees of freedom associated with the variance of the estimate of the residuals is <span class="math inline">\(n-k-1\)</span>, not <span class="math inline">\(n-1\)</span>. For instance, if we were to make predictions for new data using our current model, we would find that the unadjusted <span class="math inline">\(R^2\)</span> is an overly optimistic estimate of the reduction in variance in the response, and using the degrees of freedom in the adjusted <span class="math inline">\(R^2\)</span> formula helps correct this bias.<a href="inferenceForCategoricalData.html#fnref104">↩</a></p></li>
<li id="fn105"><p><span class="math inline">\(R_{adj}^2 = 1 - \frac{23.34}{83.06}\times \frac{141-1}{141-4-1} = 0.711\)</span>.<a href="inferenceForCategoricalData.html#fnref105">↩</a></p></li>
<li id="fn106"><p>The unadjusted <span class="math inline">\(R^2\)</span> would stay the same and the adjusted <span class="math inline">\(R^2\)</span> would go down.<a href="inferenceForCategoricalData.html#fnref106">↩</a></p></li>
<li id="fn107"><p>The p-value for the auction duration is 0.8882, which indicates that there is not statistically significant evidence that the duration is related to the total auction price when accounting for the other variables. The p-value for the Wii wheels variable is about zero, indicating that this variable is associated with the total auction price.<a href="inferenceForCategoricalData.html#fnref107">↩</a></p></li>
<li id="fn108"><p>An especially rigorous check would use <strong>time series</strong> methods. For instance, we could check whether consecutive residuals are correlated. Doing so with these residuals yields no statistically significant correlations.<a href="inferenceForCategoricalData.html#fnref108">↩</a></p></li>
<li id="fn109"><p>Recall from Chapter [linRegrForTwoVar] that if outliers are present in predictor variables, the corresponding observations may be especially influential on the resulting model. This is the motivation for omitting the numerical variables, such as the number of characters and line breaks in emails, that we saw in Chapter [introductionToData]. These variables exhibited extreme skew. We could resolve this issue by transforming these variables (e.g. using a log-transformation), but we will omit this further investigation for brevity.<a href="inferenceForCategoricalData.html#fnref109">↩</a></p></li>
<li id="fn110"><p>The new estimate is different: -2.87. This new value represents the estimated coefficient when we are also accounting for other variables in the logistic regression model.<a href="inferenceForCategoricalData.html#fnref110">↩</a></p></li>
<li id="fn111"><p>In this particular application, we should err on the side of sending more mail to the inbox rather than mistakenly putting good messages in the spambox. So, in summary: emails in the first and last categories go to the regular inbox, and those in the second scenario go to the spambox.<a href="inferenceForCategoricalData.html#fnref111">↩</a></p></li>
<li id="fn112"><p>First, note that we proposed a cutoff for the predicted probability of 0.95 for spam. In a worst case scenario, all the messages in the spambox had the minimum probability equal to about 0.95. Thus, we should expect to find about 5 or fewer legitimate messages among the 100 messages placed in the spambox.<a href="inferenceForCategoricalData.html#fnref112">↩</a></p></li>
<li id="fn113"><p>Absolutely not. It is possible that there is some difference but we did not detect it. If there is a difference, we made a Type 2 Error. Notice: we also don’t have enough information to, if there is an actual difference difference, confidently say which direction that difference would be in.<a href="inferenceForCategoricalData.html#fnref113">↩</a></p></li>
<li id="fn114"><p>We could have collected more data. If the sample sizes are larger, we tend to have a better shot at finding a difference if one exists.<a href="inferenceForCategoricalData.html#fnref114">↩</a></p></li>
<li id="fn115"><p>Because the teacher did not expect one exam to be more difficult prior to examining the test results, she should use a two-sided hypothesis test. <span class="math inline">\(H_0\)</span>: the exams are equally difficult, on average. <span class="math inline">\(\mu_A - \mu_B = 0\)</span>. <span class="math inline">\(H_A\)</span>: one exam was more difficult than the other, on average. <span class="math inline">\(\mu_A - \mu_B \neq 0\)</span>.<a href="inferenceForCategoricalData.html#fnref115">↩</a></p></li>
<li id="fn116"><p>(a) It is probably reasonable to conclude the scores are independent, provided there was no cheating. (b) The summary statistics suggest the data are roughly symmetric about the mean, and it doesn’t seem unreasonable to suggest the data might be normal. Note that since these samples are each nearing 30, moderate skew in the data would be acceptable. (c) It seems reasonable to suppose that the samples are independent since the exams were handed out randomly.<a href="inferenceForCategoricalData.html#fnref116">↩</a></p></li>
<li id="fn117"><p><span class="math inline">\(H_0\)</span>: The average on-base percentage is equal across the four positions. <span class="math inline">\(H_A\)</span>: The average on-base percentage varies across some (or all) groups.<a href="inferenceForCategoricalData.html#fnref117">↩</a></p></li>
<li id="fn118"><p>See, for example, <a href="http://www.stat.columbia.edu/~cook/movabletype/archives/2007/05/the_prosecutors.html">www.stat.columbia.edu/<span class="math inline">\(\sim\)</span>cook/movabletype/archives/2007/05/the_prosecutors.html</a>.<a href="inferenceForCategoricalData.html#fnref118">↩</a></p></li>
<li id="fn119"><p>Let <span class="math inline">\(\bar{x}\)</span> represent the mean of outcomes across all groups. Then the mean square between groups is computed as</p>
<p><span class="math display">\[\begin{aligned}
MSG = \frac{1}{df_{G}}SSG = \frac{1}{k-1}\sum_{i=1}^{k} n_{i}\left(\bar{x}_{i} - \bar{x}\right)^2\end{aligned}\]</span></p>
<p>where <span class="math inline">\(SSG\)</span> is called the <strong>sum of squares between groups</strong> and <span class="math inline">\(n_{i}\)</span> is the sample size of group <span class="math inline">\(i\)</span>.<a href="inferenceForCategoricalData.html#fnref119">↩</a></p></li>
<li id="fn120"><p>Let <span class="math inline">\(\bar{x}\)</span> represent the mean of outcomes across all groups. Then the <strong>sum of squares total (<span class="math inline">\(SST\)</span>)</strong> is computed as <span class="math inline">\(SST = \sum_{i=1}^{n} \left(x_{i} - \bar{x}\right)^2\)</span>, where the sum is over all observations in the data set. Then we compute the <strong>sum of squared errors (<span class="math inline">\(SSE\)</span>)</strong> in one of two equivalent ways:</p>
<p><span class="math display">\[\begin{aligned}
SSE = SST - SSG = (n_1-1)s_1^2 + (n_2-1)s_2^2 + \cdots + (n_k-1)s_k^2\end{aligned}\]</span></p>
<p>where <span class="math inline">\(s_i^2\)</span> is the sample variance (square of the standard deviation) of the residuals in group <span class="math inline">\(i\)</span>. Then the <span class="math inline">\(MSE\)</span> is the standardized form of <span class="math inline">\(SSE\)</span>: <span class="math inline">\(MSE = \frac{1}{df_{E}}SSE\)</span>.<a href="inferenceForCategoricalData.html#fnref120">↩</a></p></li>
<li id="fn121"><p>There are <span class="math inline">\(k=4\)</span> groups, so <span class="math inline">\(df_{G} = k-1 = 3\)</span>. There are <span class="math inline">\(n = n_1 + n_2 + n_3 + n_4 = 327\)</span> total observations, so <span class="math inline">\(df_{E} = n - k = 323\)</span>. Then the <span class="math inline">\(F\)</span> statistic is computed as the ratio of <span class="math inline">\(MSG\)</span> and <span class="math inline">\(MSE\)</span>: <span class="math inline">\(F = \frac{MSG}{MSE} = \frac{0.00252}{0.00127} = 1.984 \approx 1.994\)</span>. (<span class="math inline">\(F=1.994\)</span> was computed by using values for <span class="math inline">\(MSG\)</span> and <span class="math inline">\(MSE\)</span> that were not rounded.)<a href="inferenceForCategoricalData.html#fnref121">↩</a></p></li>
<li id="fn122"><p> </p>
<p><br />
<img src="04/figures/fDist3And323/fDist3And323Shaded" alt="image" /><a href="inferenceForCategoricalData.html#fnref122">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="FoundationForInference.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="inferenceForNumericalData.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/CrumpLab/programmingforpsych/blob/master/03-V01.Rmd",
"text": "Edit"
},
"download": ["Programming_Crump.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
