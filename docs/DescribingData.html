<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Answering questions with data</title>
  <meta name="description" content="An introductory statistics textbook for psychology students">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Answering questions with data" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="An introductory statistics textbook for psychology students" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Answering questions with data" />
  
  <meta name="twitter:description" content="An introductory statistics textbook for psychology students" />
  

<meta name="author" content="Author List, TBD">
<meta name="author" content="Current Contributions, Matthew J. C. Crump">
<meta name="author" content="Adapted work so far from Navarro, D., Diaz, Barr, &amp; Cetinkaya-Rundel">
<meta name="author" content="In Draft subject to change, we will get all attributions and licenses done correctly">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="why-statistics.html">
<link rel="next" href="Correlation.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-79429674-3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-79429674-3');
</script>


<script type="text/javascript">
mattcrump=1;
</script>



<link rel="stylesheet" href="tufte.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#important-notes"><i class="fa fa-check"></i><b>0.1</b> Important notes</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="why-statistics.html"><a href="why-statistics.html"><i class="fa fa-check"></i><b>1</b> Why Statistics?</a><ul>
<li class="chapter" data-level="1.1" data-path="why-statistics.html"><a href="why-statistics.html#on-the-psychology-of-statistics"><i class="fa fa-check"></i><b>1.1</b> On the psychology of statistics</a><ul>
<li class="chapter" data-level="1.1.1" data-path="why-statistics.html"><a href="why-statistics.html#the-curse-of-belief-bias"><i class="fa fa-check"></i><b>1.1.1</b> The curse of belief bias</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="why-statistics.html"><a href="why-statistics.html#the-cautionary-tale-of-simpsons-paradox"><i class="fa fa-check"></i><b>1.2</b> The cautionary tale of Simpson’s paradox</a></li>
<li class="chapter" data-level="1.3" data-path="why-statistics.html"><a href="why-statistics.html#statistics-in-psychology"><i class="fa fa-check"></i><b>1.3</b> Statistics in psychology</a></li>
<li class="chapter" data-level="1.4" data-path="why-statistics.html"><a href="why-statistics.html#statistics-in-everyday-life"><i class="fa fa-check"></i><b>1.4</b> Statistics in everyday life</a></li>
<li class="chapter" data-level="1.5" data-path="why-statistics.html"><a href="why-statistics.html#theres-more-to-research-methods-than-statistics"><i class="fa fa-check"></i><b>1.5</b> There’s more to research methods than statistics</a></li>
<li class="chapter" data-level="1.6" data-path="why-statistics.html"><a href="why-statistics.html#a-brief-introduction-to-research-designchstudydesign"><i class="fa fa-check"></i><b>1.6</b> A brief introduction to research design[ch:studydesign]</a><ul>
<li class="chapter" data-level="1.6.1" data-path="why-statistics.html"><a href="why-statistics.html#introduction-to-psychological-measurementsecmeasurement"><i class="fa fa-check"></i><b>1.6.1</b> Introduction to psychological measurement [sec:measurement]</a></li>
<li class="chapter" data-level="1.6.2" data-path="why-statistics.html"><a href="why-statistics.html#scales-of-measurementsecscales"><i class="fa fa-check"></i><b>1.6.2</b> Scales of measurement[sec:scales]</a></li>
<li class="chapter" data-level="1.6.3" data-path="why-statistics.html"><a href="why-statistics.html#assessing-the-reliability-of-a-measurementsecreliability"><i class="fa fa-check"></i><b>1.6.3</b> Assessing the reliability of a measurement [sec:reliability]</a></li>
<li class="chapter" data-level="1.6.4" data-path="why-statistics.html"><a href="why-statistics.html#the-role-of-variables-predictors-and-outcomes-secivdv"><i class="fa fa-check"></i><b>1.6.4</b> The “role” of variables: predictors and outcomes [sec:ivdv]</a></li>
<li class="chapter" data-level="1.6.5" data-path="why-statistics.html"><a href="why-statistics.html#experimental-and-non-experimental-researchsecresearchdesigns"><i class="fa fa-check"></i><b>1.6.5</b> Experimental and non-experimental research [sec:researchdesigns]</a></li>
<li class="chapter" data-level="1.6.6" data-path="why-statistics.html"><a href="why-statistics.html#assessing-the-validity-of-a-studysecvalidity"><i class="fa fa-check"></i><b>1.6.6</b> Assessing the validity of a study [sec:validity]</a></li>
<li class="chapter" data-level="1.6.7" data-path="why-statistics.html"><a href="why-statistics.html#confounds-artifacts-and-other-threats-to-validity"><i class="fa fa-check"></i><b>1.6.7</b> Confounds, artifacts and other threats to validity</a></li>
<li class="chapter" data-level="1.6.8" data-path="why-statistics.html"><a href="why-statistics.html#summary"><i class="fa fa-check"></i><b>1.6.8</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="why-statistics.html"><a href="why-statistics.html#basicExampleOfStentsAndStrokes"><i class="fa fa-check"></i><b>1.7</b> Case study: using stents to prevent strokes</a></li>
<li class="chapter" data-level="1.8" data-path="why-statistics.html"><a href="why-statistics.html#dataBasics"><i class="fa fa-check"></i><b>1.8</b> Data basics</a><ul>
<li class="chapter" data-level="1.8.1" data-path="why-statistics.html"><a href="why-statistics.html#observations-variables-and-data-matrices"><i class="fa fa-check"></i><b>1.8.1</b> Observations, variables, and data matrices</a></li>
<li class="chapter" data-level="1.8.2" data-path="why-statistics.html"><a href="why-statistics.html#variableTypes"><i class="fa fa-check"></i><b>1.8.2</b> Types of variables</a></li>
<li class="chapter" data-level="1.8.3" data-path="why-statistics.html"><a href="why-statistics.html#variableRelations"><i class="fa fa-check"></i><b>1.8.3</b> Relationships between variables</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="why-statistics.html"><a href="why-statistics.html#overviewOfDataCollectionPrinciples"><i class="fa fa-check"></i><b>1.9</b> Overview of data collection principles</a><ul>
<li class="chapter" data-level="1.9.1" data-path="why-statistics.html"><a href="why-statistics.html#populationsAndSamples"><i class="fa fa-check"></i><b>1.9.1</b> Populations and samples</a></li>
<li class="chapter" data-level="1.9.2" data-path="why-statistics.html"><a href="why-statistics.html#anecdotalEvidenceSubsection"><i class="fa fa-check"></i><b>1.9.2</b> Anecdotal evidence</a></li>
<li class="chapter" data-level="1.9.3" data-path="why-statistics.html"><a href="why-statistics.html#sampling-from-a-population"><i class="fa fa-check"></i><b>1.9.3</b> Sampling from a population</a></li>
<li class="chapter" data-level="1.9.4" data-path="why-statistics.html"><a href="why-statistics.html#explanatoryAndResponse"><i class="fa fa-check"></i><b>1.9.4</b> Explanatory and response variables</a></li>
<li class="chapter" data-level="1.9.5" data-path="why-statistics.html"><a href="why-statistics.html#introducing-observational-studies-and-experiments"><i class="fa fa-check"></i><b>1.9.5</b> Introducing observational studies and experiments</a></li>
</ul></li>
<li class="chapter" data-level="1.10" data-path="why-statistics.html"><a href="why-statistics.html#observational-studies-and-sampling-strategies"><i class="fa fa-check"></i><b>1.10</b> Observational studies and sampling strategies</a><ul>
<li class="chapter" data-level="1.10.1" data-path="why-statistics.html"><a href="why-statistics.html#observational-studies"><i class="fa fa-check"></i><b>1.10.1</b> Observational studies</a></li>
<li class="chapter" data-level="1.10.2" data-path="why-statistics.html"><a href="why-statistics.html#threeSamplingMethods"><i class="fa fa-check"></i><b>1.10.2</b> Three sampling methods (special topic)</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="why-statistics.html"><a href="why-statistics.html#experimentsSection"><i class="fa fa-check"></i><b>1.11</b> Experiments</a><ul>
<li class="chapter" data-level="1.11.1" data-path="why-statistics.html"><a href="why-statistics.html#experimentalDesignPrinciples"><i class="fa fa-check"></i><b>1.11.1</b> Principles of experimental design</a></li>
<li class="chapter" data-level="1.11.2" data-path="why-statistics.html"><a href="why-statistics.html#biasInHumanExperiments"><i class="fa fa-check"></i><b>1.11.2</b> Reducing bias in human experiments</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="DescribingData.html"><a href="DescribingData.html"><i class="fa fa-check"></i><b>2</b> Describing Data</a><ul>
<li class="chapter" data-level="2.1" data-path="DescribingData.html"><a href="DescribingData.html#this-is-what-too-many-numbers-looks-like"><i class="fa fa-check"></i><b>2.1</b> This is what too many numbers looks like</a></li>
<li class="chapter" data-level="2.2" data-path="DescribingData.html"><a href="DescribingData.html#look-at-the-data"><i class="fa fa-check"></i><b>2.2</b> Look at the data</a><ul>
<li class="chapter" data-level="2.2.1" data-path="DescribingData.html"><a href="DescribingData.html#stop-plotting-time-o-o-oh-u-can-plot-this"><i class="fa fa-check"></i><b>2.2.1</b> Stop, plotting time (o o oh) U can plot this</a></li>
<li class="chapter" data-level="2.2.2" data-path="DescribingData.html"><a href="DescribingData.html#histograms"><i class="fa fa-check"></i><b>2.2.2</b> Histograms</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="DescribingData.html"><a href="DescribingData.html#important-ideas-distribution-central-tendency-and-variance"><i class="fa fa-check"></i><b>2.3</b> Important Ideas: Distribution, Central Tendency, and Variance</a></li>
<li class="chapter" data-level="2.4" data-path="DescribingData.html"><a href="DescribingData.html#measures-of-central-tendency-sameness"><i class="fa fa-check"></i><b>2.4</b> Measures of Central Tendency (Sameness)</a><ul>
<li class="chapter" data-level="2.4.1" data-path="DescribingData.html"><a href="DescribingData.html#from-many-numbers-to-one"><i class="fa fa-check"></i><b>2.4.1</b> From many numbers to one</a></li>
<li class="chapter" data-level="2.4.2" data-path="DescribingData.html"><a href="DescribingData.html#mode"><i class="fa fa-check"></i><b>2.4.2</b> Mode</a></li>
<li class="chapter" data-level="2.4.3" data-path="DescribingData.html"><a href="DescribingData.html#median"><i class="fa fa-check"></i><b>2.4.3</b> Median</a></li>
<li class="chapter" data-level="2.4.4" data-path="DescribingData.html"><a href="DescribingData.html#mean"><i class="fa fa-check"></i><b>2.4.4</b> Mean</a></li>
<li class="chapter" data-level="2.4.5" data-path="DescribingData.html"><a href="DescribingData.html#what-does-the-mean-mean"><i class="fa fa-check"></i><b>2.4.5</b> What does the mean mean?</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="DescribingData.html"><a href="DescribingData.html#measures-of-variation-differentness"><i class="fa fa-check"></i><b>2.5</b> Measures of Variation (Differentness)</a><ul>
<li class="chapter" data-level="2.5.1" data-path="DescribingData.html"><a href="DescribingData.html#the-range"><i class="fa fa-check"></i><b>2.5.1</b> The Range</a></li>
<li class="chapter" data-level="2.5.2" data-path="DescribingData.html"><a href="DescribingData.html#the-difference-scores"><i class="fa fa-check"></i><b>2.5.2</b> The Difference Scores</a></li>
<li class="chapter" data-level="2.5.3" data-path="DescribingData.html"><a href="DescribingData.html#the-variance"><i class="fa fa-check"></i><b>2.5.3</b> The Variance</a></li>
<li class="chapter" data-level="2.5.4" data-path="DescribingData.html"><a href="DescribingData.html#the-standard-deviation"><i class="fa fa-check"></i><b>2.5.4</b> The Standard Deviation</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="DescribingData.html"><a href="DescribingData.html#using-descriptive-statistics-with-data"><i class="fa fa-check"></i><b>2.6</b> Using Descriptive Statistics with data</a></li>
<li class="chapter" data-level="2.7" data-path="DescribingData.html"><a href="DescribingData.html#rolling-your-own-descriptive-statistics"><i class="fa fa-check"></i><b>2.7</b> Rolling your own descriptive statistics</a><ul>
<li class="chapter" data-level="2.7.1" data-path="DescribingData.html"><a href="DescribingData.html#absolute-deviations"><i class="fa fa-check"></i><b>2.7.1</b> Absolute deviations</a></li>
<li class="chapter" data-level="2.7.2" data-path="DescribingData.html"><a href="DescribingData.html#other-sign-inverting-operations"><i class="fa fa-check"></i><b>2.7.2</b> Other sign-inverting operations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Correlation.html"><a href="Correlation.html"><i class="fa fa-check"></i><b>3</b> Correlation</a><ul>
<li class="chapter" data-level="3.1" data-path="Correlation.html"><a href="Correlation.html#if-something-caused-something-else-to-change-what-would-that-look-like"><i class="fa fa-check"></i><b>3.1</b> If something caused something else to change, what would that look like?</a><ul>
<li class="chapter" data-level="3.1.1" data-path="Correlation.html"><a href="Correlation.html#charlie-and-the-chocolate-factory"><i class="fa fa-check"></i><b>3.1.1</b> Charlie and the Chocolate factory</a></li>
<li class="chapter" data-level="3.1.2" data-path="Correlation.html"><a href="Correlation.html#scatterplots"><i class="fa fa-check"></i><b>3.1.2</b> Scatterplots</a></li>
<li class="chapter" data-level="3.1.3" data-path="Correlation.html"><a href="Correlation.html#positive-negative-and-no-correlation"><i class="fa fa-check"></i><b>3.1.3</b> Positive, Negative, and No-Correlation</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="Correlation.html"><a href="Correlation.html#pearsons-r"><i class="fa fa-check"></i><b>3.2</b> Pearson’s r</a><ul>
<li class="chapter" data-level="3.2.1" data-path="Correlation.html"><a href="Correlation.html#the-idea-of-co-variance"><i class="fa fa-check"></i><b>3.2.1</b> The idea of co-variance</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="Correlation.html"><a href="Correlation.html#turning-the-numbers-into-a-measure-of-co-variance"><i class="fa fa-check"></i><b>3.3</b> Turning the numbers into a measure of co-variance</a><ul>
<li class="chapter" data-level="3.3.1" data-path="Correlation.html"><a href="Correlation.html#co-variance-the-measure"><i class="fa fa-check"></i><b>3.3.1</b> Co-variance, the measure</a></li>
<li class="chapter" data-level="3.3.2" data-path="Correlation.html"><a href="Correlation.html#pearsons-r-we-there-yet"><i class="fa fa-check"></i><b>3.3.2</b> Pearson’s r we there yet</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="Correlation.html"><a href="Correlation.html#examples-with-data"><i class="fa fa-check"></i><b>3.4</b> Examples with Data</a></li>
<li class="chapter" data-level="3.5" data-path="Correlation.html"><a href="Correlation.html#regression-a-mini-intro"><i class="fa fa-check"></i><b>3.5</b> Regression: A mini intro</a><ul>
<li class="chapter" data-level="3.5.1" data-path="Correlation.html"><a href="Correlation.html#the-best-fit-line"><i class="fa fa-check"></i><b>3.5.1</b> The best fit line</a></li>
<li class="chapter" data-level="3.5.2" data-path="Correlation.html"><a href="Correlation.html#lines"><i class="fa fa-check"></i><b>3.5.2</b> Lines</a></li>
<li class="chapter" data-level="3.5.3" data-path="Correlation.html"><a href="Correlation.html#computing-the-best-fit-line"><i class="fa fa-check"></i><b>3.5.3</b> Computing the best fit line</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="Correlation.html"><a href="Correlation.html#interpreting-correlations"><i class="fa fa-check"></i><b>3.6</b> Interpreting Correlations</a><ul>
<li class="chapter" data-level="3.6.1" data-path="Correlation.html"><a href="Correlation.html#correlation-does-not-equal-causation"><i class="fa fa-check"></i><b>3.6.1</b> Correlation does not equal causation</a></li>
<li class="chapter" data-level="3.6.2" data-path="Correlation.html"><a href="Correlation.html#correlation-and-random-chance"><i class="fa fa-check"></i><b>3.6.2</b> Correlation and Random chance</a></li>
<li class="chapter" data-level="3.6.3" data-path="Correlation.html"><a href="Correlation.html#some-more-movies"><i class="fa fa-check"></i><b>3.6.3</b> Some more movies</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html"><i class="fa fa-check"></i><b>4</b> Sampling and estimation</a><ul>
<li class="chapter" data-level="4.1" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html#samples-populations-and-sampling"><i class="fa fa-check"></i><b>4.1</b> Samples, populations and sampling</a><ul>
<li class="chapter" data-level="4.1.1" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html#defining-a-population"><i class="fa fa-check"></i><b>4.1.1</b> Defining a population</a></li>
<li class="chapter" data-level="4.1.2" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html#simple-random-samples"><i class="fa fa-check"></i><b>4.1.2</b> Simple random samples</a></li>
<li class="chapter" data-level="4.1.3" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html#most-samples-are-not-simple-random-samples"><i class="fa fa-check"></i><b>4.1.3</b> Most samples are not simple random samples</a></li>
<li class="chapter" data-level="4.1.4" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html#how-much-does-it-matter-if-you-dont-have-a-simple-random-sample"><i class="fa fa-check"></i><b>4.1.4</b> How much does it matter if you don’t have a simple random sample?</a></li>
<li class="chapter" data-level="4.1.5" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html#population-parameters-and-sample-statistics"><i class="fa fa-check"></i><b>4.1.5</b> Population parameters and sample statistics</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html#the-law-of-large-numbers"><i class="fa fa-check"></i><b>4.2</b> The law of large numbers</a></li>
<li class="chapter" data-level="4.3" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html#sampling-distributions-and-the-central-limit-theorem"><i class="fa fa-check"></i><b>4.3</b> Sampling distributions and the central limit theorem</a><ul>
<li class="chapter" data-level="4.3.1" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html#sampling-distribution-of-the-sample-means"><i class="fa fa-check"></i><b>4.3.1</b> Sampling distribution of the sample means</a></li>
<li class="chapter" data-level="4.3.2" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html#sampling-distributions-exist-for-any-sample-statistic"><i class="fa fa-check"></i><b>4.3.2</b> Sampling distributions exist for any sample statistic!</a></li>
<li class="chapter" data-level="4.3.3" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>4.3.3</b> The central limit theorem</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html#estimating-population-parameters"><i class="fa fa-check"></i><b>4.4</b> Estimating population parameters</a><ul>
<li class="chapter" data-level="4.4.1" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html#concrete-popopulation-parameters"><i class="fa fa-check"></i><b>4.4.1</b> Concrete popopulation parameters</a></li>
<li class="chapter" data-level="4.4.2" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html#abstract-population-parameters"><i class="fa fa-check"></i><b>4.4.2</b> Abstract population parameters</a></li>
<li class="chapter" data-level="4.4.3" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html#experiments-and-population-parameters"><i class="fa fa-check"></i><b>4.4.3</b> Experiments and Population parameters</a></li>
<li class="chapter" data-level="4.4.4" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html#interim-summary"><i class="fa fa-check"></i><b>4.4.4</b> Interim summary</a></li>
<li class="chapter" data-level="4.4.5" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html#estimating-the-population-mean"><i class="fa fa-check"></i><b>4.4.5</b> Estimating the population mean</a></li>
<li class="chapter" data-level="4.4.6" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html#estimating-the-population-standard-deviation"><i class="fa fa-check"></i><b>4.4.6</b> Estimating the population standard deviation</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html#estimating-a-confidence-intervalsecci"><i class="fa fa-check"></i><b>4.5</b> Estimating a confidence interval[sec:ci]</a><ul>
<li class="chapter" data-level="4.5.1" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html#a-slight-mistake-in-the-formula"><i class="fa fa-check"></i><b>4.5.1</b> A slight mistake in the formula</a></li>
<li class="chapter" data-level="4.5.2" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html#looking-at-confidence-intervals"><i class="fa fa-check"></i><b>4.5.2</b> Looking at confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="sampling-and-estimation.html"><a href="sampling-and-estimation.html#summary-1"><i class="fa fa-check"></i><b>4.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html"><i class="fa fa-check"></i><b>5</b> Foundations for inference</a><ul>
<li class="chapter" data-level="5.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#brief-review-of-experiments"><i class="fa fa-check"></i><b>5.1</b> Brief review of Experiments</a></li>
<li class="chapter" data-level="5.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#the-data-came-from-a-distribution"><i class="fa fa-check"></i><b>5.2</b> The data came from a distribution</a><ul>
<li class="chapter" data-level="5.2.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#uniform-distribution"><i class="fa fa-check"></i><b>5.2.1</b> Uniform distribution</a></li>
<li class="chapter" data-level="5.2.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#not-all-samples-are-the-same-they-are-usually-quite-different"><i class="fa fa-check"></i><b>5.2.2</b> Not all samples are the same, they are usually quite different</a></li>
<li class="chapter" data-level="5.2.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#large-samples-are-more-like-the-distribution-they-came-from"><i class="fa fa-check"></i><b>5.2.3</b> Large samples are more like the distribution they came from</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#playing-with-distributions"><i class="fa fa-check"></i><b>5.3</b> Playing with distributions</a></li>
<li class="chapter" data-level="5.4" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#is-there-a-difference"><i class="fa fa-check"></i><b>5.4</b> Is there a difference?</a><ul>
<li class="chapter" data-level="5.4.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#chance-can-produce-differences"><i class="fa fa-check"></i><b>5.4.1</b> Chance can produce differences</a></li>
<li class="chapter" data-level="5.4.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#differences-due-to-chance-can-be-simulated"><i class="fa fa-check"></i><b>5.4.2</b> Differences due to chance can be simulated</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#chance-makes-some-differences-more-likely-than-others"><i class="fa fa-check"></i><b>5.5</b> Chance makes some differences more likely than others</a></li>
<li class="chapter" data-level="5.6" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#the-crump-test"><i class="fa fa-check"></i><b>5.6</b> The Crump Test</a><ul>
<li class="chapter" data-level="5.6.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#intuitive-methods"><i class="fa fa-check"></i><b>5.6.1</b> Intuitive methods</a></li>
<li class="chapter" data-level="5.6.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#part-1-frequency-based-intuition-about-occurence"><i class="fa fa-check"></i><b>5.6.2</b> Part 1: Frequency based intuition about occurence</a></li>
<li class="chapter" data-level="5.6.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#part-2-simulating-chance"><i class="fa fa-check"></i><b>5.6.3</b> Part 2: Simulating chance</a></li>
<li class="chapter" data-level="5.6.4" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#part-3-judgment-and-decision-making"><i class="fa fa-check"></i><b>5.6.4</b> Part 3: Judgment and Decision-making</a></li>
<li class="chapter" data-level="5.6.5" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#part-4-experiment-design"><i class="fa fa-check"></i><b>5.6.5</b> Part 4: Experiment Design</a></li>
<li class="chapter" data-level="5.6.6" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#part-5-i-have-the-power"><i class="fa fa-check"></i><b>5.6.6</b> Part 5: I have the power</a></li>
<li class="chapter" data-level="5.6.7" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#summary-of-crump-test"><i class="fa fa-check"></i><b>5.6.7</b> Summary of Crump Test</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#the-randomization-test-permutation-test"><i class="fa fa-check"></i><b>5.7</b> The randomization test (permutation test)</a><ul>
<li class="chapter" data-level="5.7.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#pretend-example-does-chewing-gum-improve-your-grades"><i class="fa fa-check"></i><b>5.7.1</b> Pretend example does chewing gum improve your grades?</a></li>
<li class="chapter" data-level="5.7.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#take-homes-so-far"><i class="fa fa-check"></i><b>5.7.2</b> Take homes so far</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#caseStudyGenderDiscrimination"><i class="fa fa-check"></i><b>5.8</b> Randomization case study: gender discrimination</a><ul>
<li class="chapter" data-level="5.8.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#variabilityWithinData"><i class="fa fa-check"></i><b>5.8.1</b> Variability within data</a></li>
<li class="chapter" data-level="5.8.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#simulatingTheStudy"><i class="fa fa-check"></i><b>5.8.2</b> Simulating the study</a></li>
<li class="chapter" data-level="5.8.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#checking-for-independence"><i class="fa fa-check"></i><b>5.8.3</b> Checking for independence</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#caseStudyOpportunityCost"><i class="fa fa-check"></i><b>5.9</b> Randomization case study: opportunity cost</a><ul>
<li class="chapter" data-level="5.9.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#exploring-the-data-set-before-the-analysis"><i class="fa fa-check"></i><b>5.9.1</b> Exploring the data set before the analysis</a></li>
<li class="chapter" data-level="5.9.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#results-from-chance-alone"><i class="fa fa-check"></i><b>5.9.2</b> Results from chance alone</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#HypothesisTesting"><i class="fa fa-check"></i><b>5.10</b> Hypothesis testing</a><ul>
<li class="chapter" data-level="5.10.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#hypothesis-testing-in-the-us-court-system"><i class="fa fa-check"></i><b>5.10.1</b> Hypothesis testing in the US court system</a></li>
<li class="chapter" data-level="5.10.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#p-value-and-statistical-significance"><i class="fa fa-check"></i><b>5.10.2</b> p-value and statistical significance</a></li>
<li class="chapter" data-level="5.10.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#decision-errors"><i class="fa fa-check"></i><b>5.10.3</b> Decision errors</a></li>
<li class="chapter" data-level="5.10.4" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#significanceLevel"><i class="fa fa-check"></i><b>5.10.4</b> Choosing a significance level</a></li>
<li class="chapter" data-level="5.10.5" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#IntroducingTwoSidedHypotheses"><i class="fa fa-check"></i><b>5.10.5</b> Introducing two-sided hypotheses</a></li>
<li class="chapter" data-level="5.10.6" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#InflatingType1ErrorRate"><i class="fa fa-check"></i><b>5.10.6</b> Controlling the Type 1 Error rate</a></li>
<li class="chapter" data-level="5.10.7" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#how-to-use-a-hypothesis-test"><i class="fa fa-check"></i><b>5.10.7</b> How to use a hypothesis test</a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#SimulationCaseStudies"><i class="fa fa-check"></i><b>5.11</b> Simulation case studies</a><ul>
<li class="chapter" data-level="5.11.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#medical-consultant"><i class="fa fa-check"></i><b>5.11.1</b> Medical consultant</a></li>
<li class="chapter" data-level="5.11.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#tappers-and-listeners"><i class="fa fa-check"></i><b>5.11.2</b> Tappers and listeners</a></li>
</ul></li>
<li class="chapter" data-level="5.12" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#CLTsection"><i class="fa fa-check"></i><b>5.12</b> Central Limit Theorem</a><ul>
<li class="chapter" data-level="5.12.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#null-distribution-from-the-case-studies"><i class="fa fa-check"></i><b>5.12.1</b> Null distribution from the case studies</a></li>
<li class="chapter" data-level="5.12.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#examples-of-future-settings-we-will-consider"><i class="fa fa-check"></i><b>5.12.2</b> Examples of future settings we will consider</a></li>
</ul></li>
<li class="chapter" data-level="5.13" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#normalDist"><i class="fa fa-check"></i><b>5.13</b> Normal distribution</a><ul>
<li class="chapter" data-level="5.13.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#NormalDistributionModelSubsection"><i class="fa fa-check"></i><b>5.13.1</b> Normal distribution model</a></li>
<li class="chapter" data-level="5.13.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#standardizing-with-z-scores"><i class="fa fa-check"></i><b>5.13.2</b> Standardizing with Z scores</a></li>
<li class="chapter" data-level="5.13.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#normal-probability-table"><i class="fa fa-check"></i><b>5.13.3</b> Normal probability table</a></li>
<li class="chapter" data-level="5.13.4" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#normal-probability-examples"><i class="fa fa-check"></i><b>5.13.4</b> Normal probability examples</a></li>
<li class="chapter" data-level="5.13.5" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#rule"><i class="fa fa-check"></i><b>5.13.5</b> 68-95-99.7 rule</a></li>
<li class="chapter" data-level="5.13.6" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#assessingNormal"><i class="fa fa-check"></i><b>5.13.6</b> Evaluating the normal approximation</a></li>
</ul></li>
<li class="chapter" data-level="5.14" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#ApplyingTheNormalModel"><i class="fa fa-check"></i><b>5.14</b> Applying the normal model</a><ul>
<li class="chapter" data-level="5.14.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#standard-error"><i class="fa fa-check"></i><b>5.14.1</b> Standard error</a></li>
<li class="chapter" data-level="5.14.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#normal-model-application-opportunity-cost"><i class="fa fa-check"></i><b>5.14.2</b> Normal model application: opportunity cost</a></li>
<li class="chapter" data-level="5.14.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#normal-model-application-medical-consultant"><i class="fa fa-check"></i><b>5.14.3</b> Normal model application: medical consultant</a></li>
<li class="chapter" data-level="5.14.4" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#conditions-for-applying-the-normal-model"><i class="fa fa-check"></i><b>5.14.4</b> Conditions for applying the normal model</a></li>
</ul></li>
<li class="chapter" data-level="5.15" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#ConfidenceIntervals"><i class="fa fa-check"></i><b>5.15</b> Confidence intervals</a><ul>
<li class="chapter" data-level="5.15.1" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#capturing-the-population-parameter"><i class="fa fa-check"></i><b>5.15.1</b> Capturing the population parameter</a></li>
<li class="chapter" data-level="5.15.2" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#constructing-a-95-confidence-interval"><i class="fa fa-check"></i><b>5.15.2</b> Constructing a 95% confidence interval</a></li>
<li class="chapter" data-level="5.15.3" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#changingTheConfidenceLevelSection"><i class="fa fa-check"></i><b>5.15.3</b> Changing the confidence level</a></li>
<li class="chapter" data-level="5.15.4" data-path="foundations-for-inference.html"><a href="foundations-for-inference.html#interpretingCIs"><i class="fa fa-check"></i><b>5.15.4</b> Interpreting confidence intervals</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="t-tests.html"><a href="t-tests.html"><i class="fa fa-check"></i><b>6</b> t-Tests</a><ul>
<li class="chapter" data-level="6.1" data-path="t-tests.html"><a href="t-tests.html#check-your-confidence-in-your-mean"><i class="fa fa-check"></i><b>6.1</b> Check your confidence in your mean</a></li>
<li class="chapter" data-level="6.2" data-path="t-tests.html"><a href="t-tests.html#one-sample-t-test-a-new-t-test"><i class="fa fa-check"></i><b>6.2</b> One-sample t-test: A new t-test</a><ul>
<li class="chapter" data-level="6.2.1" data-path="t-tests.html"><a href="t-tests.html#formulas-for-one-sample-t-test"><i class="fa fa-check"></i><b>6.2.1</b> Formulas for one-sample t-test</a></li>
<li class="chapter" data-level="6.2.2" data-path="t-tests.html"><a href="t-tests.html#what-does-t-represent"><i class="fa fa-check"></i><b>6.2.2</b> What does t represent?</a></li>
<li class="chapter" data-level="6.2.3" data-path="t-tests.html"><a href="t-tests.html#calculating-t-from-data"><i class="fa fa-check"></i><b>6.2.3</b> Calculating t from data</a></li>
<li class="chapter" data-level="6.2.4" data-path="t-tests.html"><a href="t-tests.html#how-does-t-behave"><i class="fa fa-check"></i><b>6.2.4</b> How does <span class="math inline">\(t\)</span> behave?</a></li>
<li class="chapter" data-level="6.2.5" data-path="t-tests.html"><a href="t-tests.html#making-a-decision"><i class="fa fa-check"></i><b>6.2.5</b> Making a decision</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="t-tests.html"><a href="t-tests.html#paired-samples-t-test"><i class="fa fa-check"></i><b>6.3</b> Paired-samples <span class="math inline">\(t\)</span>-test</a><ul>
<li class="chapter" data-level="6.3.1" data-path="t-tests.html"><a href="t-tests.html#mehr-song-and-spelke-2016"><i class="fa fa-check"></i><b>6.3.1</b> Mehr, Song, and Spelke (2016)</a></li>
<li class="chapter" data-level="6.3.2" data-path="t-tests.html"><a href="t-tests.html#the-data"><i class="fa fa-check"></i><b>6.3.2</b> The data</a></li>
<li class="chapter" data-level="6.3.3" data-path="t-tests.html"><a href="t-tests.html#the-difference-scores-1"><i class="fa fa-check"></i><b>6.3.3</b> The difference scores</a></li>
<li class="chapter" data-level="6.3.4" data-path="t-tests.html"><a href="t-tests.html#the-mean-difference"><i class="fa fa-check"></i><b>6.3.4</b> The mean difference</a></li>
<li class="chapter" data-level="6.3.5" data-path="t-tests.html"><a href="t-tests.html#calculate-t"><i class="fa fa-check"></i><b>6.3.5</b> Calculate <span class="math inline">\(t\)</span></a></li>
<li class="chapter" data-level="6.3.6" data-path="t-tests.html"><a href="t-tests.html#interpreting-ts"><i class="fa fa-check"></i><b>6.3.6</b> Interpreting <span class="math inline">\(t\)</span>s</a></li>
<li class="chapter" data-level="6.3.7" data-path="t-tests.html"><a href="t-tests.html#getting-the-p-values-for-t-values"><i class="fa fa-check"></i><b>6.3.7</b> Getting the p-values for t-values</a></li>
<li class="chapter" data-level="6.3.8" data-path="t-tests.html"><a href="t-tests.html#one-tailed-tests"><i class="fa fa-check"></i><b>6.3.8</b> One-tailed tests</a></li>
<li class="chapter" data-level="6.3.9" data-path="t-tests.html"><a href="t-tests.html#two-tailed-tests"><i class="fa fa-check"></i><b>6.3.9</b> Two-tailed tests</a></li>
<li class="chapter" data-level="6.3.10" data-path="t-tests.html"><a href="t-tests.html#one-or-two-tailed-which-one"><i class="fa fa-check"></i><b>6.3.10</b> One or two tailed, which one?</a></li>
<li class="chapter" data-level="6.3.11" data-path="t-tests.html"><a href="t-tests.html#degrees-of-freedom"><i class="fa fa-check"></i><b>6.3.11</b> Degrees of freedom</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="t-tests.html"><a href="t-tests.html#the-paired-samples-t-test-strikes-back"><i class="fa fa-check"></i><b>6.4</b> The paired samples t-test strikes back</a></li>
<li class="chapter" data-level="6.5" data-path="t-tests.html"><a href="t-tests.html#independent-samples-t-test-the-return-of-the-t-test"><i class="fa fa-check"></i><b>6.5</b> Independent samples t-test: The return of the t-test?</a></li>
<li class="chapter" data-level="6.6" data-path="t-tests.html"><a href="t-tests.html#by-hand-using-r-r-code"><i class="fa fa-check"></i><b>6.6</b> By “hand” using R r code</a></li>
<li class="chapter" data-level="6.7" data-path="t-tests.html"><a href="t-tests.html#simulating-data-for-t-tests"><i class="fa fa-check"></i><b>6.7</b> Simulating data for t-tests</a><ul>
<li class="chapter" data-level="6.7.1" data-path="t-tests.html"><a href="t-tests.html#simulating-a-one-sample-t-test"><i class="fa fa-check"></i><b>6.7.1</b> Simulating a one-sample t-test</a></li>
<li class="chapter" data-level="6.7.2" data-path="t-tests.html"><a href="t-tests.html#simulating-a-paired-samples-test"><i class="fa fa-check"></i><b>6.7.2</b> Simulating a paired samples test</a></li>
<li class="chapter" data-level="6.7.3" data-path="t-tests.html"><a href="t-tests.html#simulating-an-independent-samples-t.test"><i class="fa fa-check"></i><b>6.7.3</b> Simulating an independent samples t.test</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="t-tests.html"><a href="t-tests.html#oneSampleMeansWithTDistribution"><i class="fa fa-check"></i><b>6.8</b> One-sample means with the <span class="math inline">\(t\)</span> distribution</a><ul>
<li class="chapter" data-level="6.8.1" data-path="t-tests.html"><a href="t-tests.html#two-examples-using-the-normal-distribution"><i class="fa fa-check"></i><b>6.8.1</b> Two examples using the normal distribution</a></li>
<li class="chapter" data-level="6.8.2" data-path="t-tests.html"><a href="t-tests.html#introducingTheTDistribution"><i class="fa fa-check"></i><b>6.8.2</b> Introducing the <span class="math inline">\(t\)</span> distribution</a></li>
<li class="chapter" data-level="6.8.3" data-path="t-tests.html"><a href="t-tests.html#tDistSolutionToSEProblem"><i class="fa fa-check"></i><b>6.8.3</b> Applying the <span class="math inline">\(t\)</span> distribution to the single-mean situation</a></li>
<li class="chapter" data-level="6.8.4" data-path="t-tests.html"><a href="t-tests.html#oneSampleTConfidenceIntervals"><i class="fa fa-check"></i><b>6.8.4</b> One sample <span class="math inline">\(t\)</span> confidence intervals</a></li>
<li class="chapter" data-level="6.8.5" data-path="t-tests.html"><a href="t-tests.html#oneSampleTTests"><i class="fa fa-check"></i><b>6.8.5</b> One sample <span class="math inline">\(t\)</span> tests</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="t-tests.html"><a href="t-tests.html#pairedData"><i class="fa fa-check"></i><b>6.9</b> Paired data</a><ul>
<li class="chapter" data-level="6.9.1" data-path="t-tests.html"><a href="t-tests.html#paired-observations"><i class="fa fa-check"></i><b>6.9.1</b> Paired observations</a></li>
<li class="chapter" data-level="6.9.2" data-path="t-tests.html"><a href="t-tests.html#inference-for-paired-data"><i class="fa fa-check"></i><b>6.9.2</b> Inference for paired data</a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="t-tests.html"><a href="t-tests.html#differenceOfTwoMeans"><i class="fa fa-check"></i><b>6.10</b> Difference of two means</a><ul>
<li class="chapter" data-level="6.10.1" data-path="t-tests.html"><a href="t-tests.html#confidence-interval-for-a-differences-of-means"><i class="fa fa-check"></i><b>6.10.1</b> Confidence interval for a differences of means</a></li>
<li class="chapter" data-level="6.10.2" data-path="t-tests.html"><a href="t-tests.html#hypothesis-tests-based-on-a-difference-in-means"><i class="fa fa-check"></i><b>6.10.2</b> Hypothesis tests based on a difference in means</a></li>
<li class="chapter" data-level="6.10.3" data-path="t-tests.html"><a href="t-tests.html#case-study-two-versions-of-a-course-exam"><i class="fa fa-check"></i><b>6.10.3</b> Case study: two versions of a course exam</a></li>
<li class="chapter" data-level="6.10.4" data-path="t-tests.html"><a href="t-tests.html#summary-for-inference-using-the-t-distribution"><i class="fa fa-check"></i><b>6.10.4</b> Summary for inference using the <span class="math inline">\(t\)</span> distribution</a></li>
<li class="chapter" data-level="6.10.5" data-path="t-tests.html"><a href="t-tests.html#pooledStandardDeviations"><i class="fa fa-check"></i><b>6.10.5</b> Pooled standard deviation estimate (special topic)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="anova.html"><a href="anova.html"><i class="fa fa-check"></i><b>7</b> ANOVA</a><ul>
<li class="chapter" data-level="7.1" data-path="anova.html"><a href="anova.html#anova-is-analysis-of-variance"><i class="fa fa-check"></i><b>7.1</b> ANOVA is Analysis of Variance</a></li>
<li class="chapter" data-level="7.2" data-path="anova.html"><a href="anova.html#one-factor-anova"><i class="fa fa-check"></i><b>7.2</b> One-factor ANOVA</a><ul>
<li class="chapter" data-level="7.2.1" data-path="anova.html"><a href="anova.html#computing-the-f-value"><i class="fa fa-check"></i><b>7.2.1</b> Computing the F-value</a></li>
<li class="chapter" data-level="7.2.2" data-path="anova.html"><a href="anova.html#ss-total"><i class="fa fa-check"></i><b>7.2.2</b> SS Total</a></li>
<li class="chapter" data-level="7.2.3" data-path="anova.html"><a href="anova.html#ss-effect"><i class="fa fa-check"></i><b>7.2.3</b> SS Effect</a></li>
<li class="chapter" data-level="7.2.4" data-path="anova.html"><a href="anova.html#ss-error"><i class="fa fa-check"></i><b>7.2.4</b> SS Error</a></li>
<li class="chapter" data-level="7.2.5" data-path="anova.html"><a href="anova.html#degrees-of-freedom-1"><i class="fa fa-check"></i><b>7.2.5</b> Degrees of freedom</a></li>
<li class="chapter" data-level="7.2.6" data-path="anova.html"><a href="anova.html#mean-squared-error"><i class="fa fa-check"></i><b>7.2.6</b> Mean Squared Error</a></li>
<li class="chapter" data-level="7.2.7" data-path="anova.html"><a href="anova.html#calculate-f"><i class="fa fa-check"></i><b>7.2.7</b> Calculate F</a></li>
<li class="chapter" data-level="7.2.8" data-path="anova.html"><a href="anova.html#the-anova-table"><i class="fa fa-check"></i><b>7.2.8</b> The ANOVA TABLE</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="anova.html"><a href="anova.html#what-does-f-mean"><i class="fa fa-check"></i><b>7.3</b> What does F mean?</a><ul>
<li class="chapter" data-level="7.3.1" data-path="anova.html"><a href="anova.html#making-decisions"><i class="fa fa-check"></i><b>7.3.1</b> Making Decisions</a></li>
<li class="chapter" data-level="7.3.2" data-path="anova.html"><a href="anova.html#fs-and-means"><i class="fa fa-check"></i><b>7.3.2</b> Fs and means</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="anova.html"><a href="anova.html#anova-on-real-data"><i class="fa fa-check"></i><b>7.4</b> ANOVA on Real Data</a><ul>
<li class="chapter" data-level="7.4.1" data-path="anova.html"><a href="anova.html#tetris-and-bad-memories"><i class="fa fa-check"></i><b>7.4.1</b> Tetris and bad memories</a></li>
<li class="chapter" data-level="7.4.2" data-path="anova.html"><a href="anova.html#comparing-means-after-the-anova"><i class="fa fa-check"></i><b>7.4.2</b> Comparing means after the ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="anova.html"><a href="anova.html#anova-summmary"><i class="fa fa-check"></i><b>7.5</b> ANOVA Summmary</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html"><i class="fa fa-check"></i><b>8</b> Repeated Measures ANOVA</a><ul>
<li class="chapter" data-level="8.1" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#repeated-measures-design"><i class="fa fa-check"></i><b>8.1</b> Repeated measures design</a></li>
<li class="chapter" data-level="8.2" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#partioning-the-sums-of-squares"><i class="fa fa-check"></i><b>8.2</b> Partioning the Sums of Squares</a></li>
<li class="chapter" data-level="8.3" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#calculating-the-rm-anova"><i class="fa fa-check"></i><b>8.3</b> Calculating the RM ANOVA</a><ul>
<li class="chapter" data-level="8.3.1" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#ss-total-1"><i class="fa fa-check"></i><b>8.3.1</b> SS Total</a></li>
<li class="chapter" data-level="8.3.2" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#ss-effect-1"><i class="fa fa-check"></i><b>8.3.2</b> SS Effect</a></li>
<li class="chapter" data-level="8.3.3" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#ss-error-within-conditions"><i class="fa fa-check"></i><b>8.3.3</b> SS Error (within-conditions)</a></li>
<li class="chapter" data-level="8.3.4" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#ss-subjects"><i class="fa fa-check"></i><b>8.3.4</b> SS Subjects</a></li>
<li class="chapter" data-level="8.3.5" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#ss-error-left-over"><i class="fa fa-check"></i><b>8.3.5</b> SS Error (left-over)</a></li>
<li class="chapter" data-level="8.3.6" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#check-our-work"><i class="fa fa-check"></i><b>8.3.6</b> Check our work</a></li>
<li class="chapter" data-level="8.3.7" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#compute-the-mses"><i class="fa fa-check"></i><b>8.3.7</b> Compute the MSEs</a></li>
<li class="chapter" data-level="8.3.8" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#compute-f"><i class="fa fa-check"></i><b>8.3.8</b> Compute F</a></li>
<li class="chapter" data-level="8.3.9" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#p-value"><i class="fa fa-check"></i><b>8.3.9</b> p-value</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#things-worth-knowing"><i class="fa fa-check"></i><b>8.4</b> Things worth knowing</a><ul>
<li class="chapter" data-level="8.4.1" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#repeated-vs-between-subjects-anova"><i class="fa fa-check"></i><b>8.4.1</b> Repeated vs between-subjects ANOVA</a></li>
<li class="chapter" data-level="8.4.2" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#repeated-measures-designs-are-more-sensitive"><i class="fa fa-check"></i><b>8.4.2</b> repeated measures designs are more sensitive</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#real-data"><i class="fa fa-check"></i><b>8.5</b> Real Data</a></li>
<li class="chapter" data-level="8.6" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#get-subject-mean-rts"><i class="fa fa-check"></i><b>8.6</b> get subject mean RTs</a></li>
<li class="chapter" data-level="8.7" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#get-condition-mean-rts"><i class="fa fa-check"></i><b>8.7</b> get condition mean RTs</a></li>
<li class="chapter" data-level="8.8" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html#plot-the-condition-means"><i class="fa fa-check"></i><b>8.8</b> plot the condition means</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="factorial-anova.html"><a href="factorial-anova.html"><i class="fa fa-check"></i><b>9</b> Factorial ANOVA</a><ul>
<li class="chapter" data-level="9.1" data-path="factorial-anova.html"><a href="factorial-anova.html#x2-designs"><i class="fa fa-check"></i><b>9.1</b> 2x2 Designs</a><ul>
<li class="chapter" data-level="9.1.1" data-path="factorial-anova.html"><a href="factorial-anova.html#factorial-notation"><i class="fa fa-check"></i><b>9.1.1</b> Factorial Notation</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="factorial-anova.html"><a href="factorial-anova.html#x-3-designs"><i class="fa fa-check"></i><b>9.2</b> 2 x 3 designs</a></li>
<li class="chapter" data-level="9.3" data-path="factorial-anova.html"><a href="factorial-anova.html#purpose-of-factorial-designs"><i class="fa fa-check"></i><b>9.3</b> Purpose of Factorial Designs</a><ul>
<li class="chapter" data-level="9.3.1" data-path="factorial-anova.html"><a href="factorial-anova.html#factorials-manipulate-an-effect-of-interest"><i class="fa fa-check"></i><b>9.3.1</b> Factorials manipulate an effect of interest</a></li>
<li class="chapter" data-level="9.3.2" data-path="factorial-anova.html"><a href="factorial-anova.html#spot-the-difference"><i class="fa fa-check"></i><b>9.3.2</b> Spot the difference</a></li>
<li class="chapter" data-level="9.3.3" data-path="factorial-anova.html"><a href="factorial-anova.html#distraction-manipulation"><i class="fa fa-check"></i><b>9.3.3</b> Distraction manipulation</a></li>
<li class="chapter" data-level="9.3.4" data-path="factorial-anova.html"><a href="factorial-anova.html#distraction-effect"><i class="fa fa-check"></i><b>9.3.4</b> Distraction effect</a></li>
<li class="chapter" data-level="9.3.5" data-path="factorial-anova.html"><a href="factorial-anova.html#manipulating-the-distraction-effect"><i class="fa fa-check"></i><b>9.3.5</b> Manipulating the Distraction effect</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="factorial-anova.html"><a href="factorial-anova.html#graphing-the-means"><i class="fa fa-check"></i><b>9.4</b> Graphing the means</a></li>
<li class="chapter" data-level="9.5" data-path="factorial-anova.html"><a href="factorial-anova.html#knowing-what-you-want-to-find-out"><i class="fa fa-check"></i><b>9.5</b> Knowing what you want to find out</a></li>
<li class="chapter" data-level="9.6" data-path="factorial-anova.html"><a href="factorial-anova.html#simple-analysis-of-2x2-repeated-measures-design"><i class="fa fa-check"></i><b>9.6</b> Simple analysis of 2x2 repeated measures design</a><ul>
<li class="chapter" data-level="9.6.1" data-path="factorial-anova.html"><a href="factorial-anova.html#main-effects"><i class="fa fa-check"></i><b>9.6.1</b> Main effects</a></li>
<li class="chapter" data-level="9.6.2" data-path="factorial-anova.html"><a href="factorial-anova.html#interaction"><i class="fa fa-check"></i><b>9.6.2</b> Interaction</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="mixed-design-anova.html"><a href="mixed-design-anova.html"><i class="fa fa-check"></i><b>10</b> Mixed Design ANOVA</a><ul>
<li class="chapter" data-level="10.1" data-path="mixed-design-anova.html"><a href="mixed-design-anova.html#anovaAndRegrWithCategoricalVariables"><i class="fa fa-check"></i><b>10.1</b> Comparing many means with ANOVA</a><ul>
<li class="chapter" data-level="10.1.1" data-path="mixed-design-anova.html"><a href="mixed-design-anova.html#is-batting-performance-related-to-player-position-in-mlb"><i class="fa fa-check"></i><b>10.1.1</b> Is batting performance related to player position in MLB?</a></li>
<li class="chapter" data-level="10.1.2" data-path="mixed-design-anova.html"><a href="mixed-design-anova.html#analysis-of-variance-anova-and-the-f-test"><i class="fa fa-check"></i><b>10.1.2</b> Analysis of variance (ANOVA) and the F test</a></li>
<li class="chapter" data-level="10.1.3" data-path="mixed-design-anova.html"><a href="mixed-design-anova.html#reading-an-anova-table-from-software"><i class="fa fa-check"></i><b>10.1.3</b> Reading an ANOVA table from software</a></li>
<li class="chapter" data-level="10.1.4" data-path="mixed-design-anova.html"><a href="mixed-design-anova.html#graphical-diagnostics-for-an-anova-analysis"><i class="fa fa-check"></i><b>10.1.4</b> Graphical diagnostics for an ANOVA analysis</a></li>
<li class="chapter" data-level="10.1.5" data-path="mixed-design-anova.html"><a href="mixed-design-anova.html#multipleComparisonsAndControllingTheType1ErrorRate"><i class="fa fa-check"></i><b>10.1.5</b> Multiple comparisons and controlling Type 1 Error rate</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="mixed-design-anova.html"><a href="mixed-design-anova.html#bootstrapping-to-study-the-standard-deviation"><i class="fa fa-check"></i><b>10.2</b> Bootstrapping to study the standard deviation</a><ul>
<li class="chapter" data-level="10.2.1" data-path="mixed-design-anova.html"><a href="mixed-design-anova.html#bootstrap-samples-and-distributions"><i class="fa fa-check"></i><b>10.2.1</b> Bootstrap samples and distributions</a></li>
<li class="chapter" data-level="10.2.2" data-path="mixed-design-anova.html"><a href="mixed-design-anova.html#inference-using-the-bootstrap"><i class="fa fa-check"></i><b>10.2.2</b> Inference using the bootstrap</a></li>
<li class="chapter" data-level="10.2.3" data-path="mixed-design-anova.html"><a href="mixed-design-anova.html#frequently-asked-questions"><i class="fa fa-check"></i><b>10.2.3</b> Frequently asked questions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html"><i class="fa fa-check"></i><b>11</b> Introduction to linear regression</a><ul>
<li class="chapter" data-level="11.1" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#lineFittingResidualsCorrelation"><i class="fa fa-check"></i><b>11.1</b> Line fitting, residuals, and correlation</a><ul>
<li class="chapter" data-level="11.1.1" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#beginning-with-straight-lines"><i class="fa fa-check"></i><b>11.1.1</b> Beginning with straight lines</a></li>
<li class="chapter" data-level="11.1.2" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#fitting-a-line-by-eye"><i class="fa fa-check"></i><b>11.1.2</b> Fitting a line by eye</a></li>
<li class="chapter" data-level="11.1.3" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#residuals"><i class="fa fa-check"></i><b>11.1.3</b> Residuals</a></li>
<li class="chapter" data-level="11.1.4" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#describing-linear-relationships-with-correlation"><i class="fa fa-check"></i><b>11.1.4</b> Describing linear relationships with correlation</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#fittingALineByLSR"><i class="fa fa-check"></i><b>11.2</b> Fitting a line by least squares regression</a><ul>
<li class="chapter" data-level="11.2.1" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#an-objective-measure-for-finding-the-best-line"><i class="fa fa-check"></i><b>11.2.1</b> An objective measure for finding the best line</a></li>
<li class="chapter" data-level="11.2.2" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#findingTheLeastSquaresLineSection"><i class="fa fa-check"></i><b>11.2.2</b> Finding the least squares line</a></li>
<li class="chapter" data-level="11.2.3" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#interpreting-regression-line-parameter-estimates"><i class="fa fa-check"></i><b>11.2.3</b> Interpreting regression line parameter estimates</a></li>
<li class="chapter" data-level="11.2.4" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#extrapolation-is-treacherous"><i class="fa fa-check"></i><b>11.2.4</b> Extrapolation is treacherous</a></li>
<li class="chapter" data-level="11.2.5" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#using-r2-to-describe-the-strength-of-a-fit"><i class="fa fa-check"></i><b>11.2.5</b> Using <span class="math inline">\(R^2\)</span> to describe the strength of a fit</a></li>
<li class="chapter" data-level="11.2.6" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#categoricalPredictorsWithTwoLevels"><i class="fa fa-check"></i><b>11.2.6</b> Categorical predictors with two levels</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#typesOfOutliersInLinearRegression"><i class="fa fa-check"></i><b>11.3</b> Types of outliers in linear regression</a></li>
<li class="chapter" data-level="11.4" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#inferenceForLinearRegression"><i class="fa fa-check"></i><b>11.4</b> Inference for linear regression</a><ul>
<li class="chapter" data-level="11.4.1" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#conditions-for-the-least-squares-line"><i class="fa fa-check"></i><b>11.4.1</b> Conditions for the least squares line</a></li>
<li class="chapter" data-level="11.4.2" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#midterm-elections-and-unemployment"><i class="fa fa-check"></i><b>11.4.2</b> Midterm elections and unemployment</a></li>
<li class="chapter" data-level="11.4.3" data-path="linRegrForTwoVar.html"><a href="linRegrForTwoVar.html#testStatisticForTheSlope"><i class="fa fa-check"></i><b>11.4.3</b> Understanding regression output from software</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html"><i class="fa fa-check"></i><b>12</b> Multiple and logistic regression</a><ul>
<li class="chapter" data-level="12.1" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#introductionToMultipleRegression"><i class="fa fa-check"></i><b>12.1</b> Introduction to multiple regression</a><ul>
<li class="chapter" data-level="12.1.1" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#twoSingleVariableModelsForMarioKartData"><i class="fa fa-check"></i><b>12.1.1</b> A single-variable model for the Mario Kart data</a></li>
<li class="chapter" data-level="12.1.2" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#includingAndAssessingManyVariablesInAModel"><i class="fa fa-check"></i><b>12.1.2</b> Including and assessing many variables in a model</a></li>
<li class="chapter" data-level="12.1.3" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#adjusted-r2-as-a-better-estimate-of-explained-variance"><i class="fa fa-check"></i><b>12.1.3</b> Adjusted <span class="math inline">\(R^2\)</span> as a better estimate of explained variance</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#modelSelection"><i class="fa fa-check"></i><b>12.2</b> Model selection</a><ul>
<li class="chapter" data-level="12.2.1" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#identifying-variables-in-the-model-that-may-not-be-helpful"><i class="fa fa-check"></i><b>12.2.1</b> Identifying variables in the model that may not be helpful</a></li>
<li class="chapter" data-level="12.2.2" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#two-model-selection-strategies"><i class="fa fa-check"></i><b>12.2.2</b> Two model selection strategies</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#multipleRegressionModelAssumptions"><i class="fa fa-check"></i><b>12.3</b> Checking model assumptions using graphs</a></li>
<li class="chapter" data-level="12.4" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#logisticRegression"><i class="fa fa-check"></i><b>12.4</b> Logistic regression</a><ul>
<li class="chapter" data-level="12.4.1" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#email-data"><i class="fa fa-check"></i><b>12.4.1</b> Email data</a></li>
<li class="chapter" data-level="12.4.2" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#modelingTheProbabilityOfAnEvent"><i class="fa fa-check"></i><b>12.4.2</b> Modeling the probability of an event</a></li>
<li class="chapter" data-level="12.4.3" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#practical-decisions-in-the-email-application"><i class="fa fa-check"></i><b>12.4.3</b> Practical decisions in the email application</a></li>
<li class="chapter" data-level="12.4.4" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#diagnostics-for-the-email-classifier"><i class="fa fa-check"></i><b>12.4.4</b> Diagnostics for the email classifier</a></li>
<li class="chapter" data-level="12.4.5" data-path="multipleRegressionAndANOVA.html"><a href="multipleRegressionAndANOVA.html#improvingTheSetOfVariablesForASpamFilter"><i class="fa fa-check"></i><b>12.4.5</b> Improving the set of variables for a spam filter</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html"><i class="fa fa-check"></i><b>13</b> Inference for categorical data</a><ul>
<li class="chapter" data-level="13.1" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#singleProportion"><i class="fa fa-check"></i><b>13.1</b> Inference for a single proportion</a><ul>
<li class="chapter" data-level="13.1.1" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#when-the-sample-proportion-is-nearly-normal"><i class="fa fa-check"></i><b>13.1.1</b> When the sample proportion is nearly normal</a></li>
<li class="chapter" data-level="13.1.2" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#confIntForPropSection"><i class="fa fa-check"></i><b>13.1.2</b> Confidence intervals for a proportion</a></li>
<li class="chapter" data-level="13.1.3" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#htForPropSection"><i class="fa fa-check"></i><b>13.1.3</b> Hypothesis testing for a proportion</a></li>
<li class="chapter" data-level="13.1.4" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#choosing-a-sample-size-when-estimating-a-proportion"><i class="fa fa-check"></i><b>13.1.4</b> Choosing a sample size when estimating a proportion</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#differenceOfTwoProportions"><i class="fa fa-check"></i><b>13.2</b> Difference of two proportions</a><ul>
<li class="chapter" data-level="13.2.1" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#SampleDistributionOfTheDiffOfTwoProportions"><i class="fa fa-check"></i><b>13.2.1</b> Sample distribution of the difference of two proportions</a></li>
<li class="chapter" data-level="13.2.2" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#intervals-and-tests-for-p_1--p_2"><i class="fa fa-check"></i><b>13.2.2</b> Intervals and tests for <span class="math inline">\(p_1 -p_2\)</span></a></li>
<li class="chapter" data-level="13.2.3" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#pooledHTForProportionsSection"><i class="fa fa-check"></i><b>13.2.3</b> Hypothesis testing when <span class="math inline">\(H_0: p_1=p_2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#oneWayChiSquare"><i class="fa fa-check"></i><b>13.3</b> Testing for goodness of fit using chi-square (special topic)</a><ul>
<li class="chapter" data-level="13.3.1" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#creating-a-test-statistic-for-one-way-tables"><i class="fa fa-check"></i><b>13.3.1</b> Creating a test statistic for one-way tables</a></li>
<li class="chapter" data-level="13.3.2" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#chiSquareTestStatistic"><i class="fa fa-check"></i><b>13.3.2</b> The chi-square test statistic</a></li>
<li class="chapter" data-level="13.3.3" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#the-chi-square-distribution-and-finding-areas"><i class="fa fa-check"></i><b>13.3.3</b> The chi-square distribution and finding areas</a></li>
<li class="chapter" data-level="13.3.4" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#pValueForAChiSquareTest"><i class="fa fa-check"></i><b>13.3.4</b> Finding a p-value for a chi-square distribution</a></li>
<li class="chapter" data-level="13.3.5" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#evaluating-goodness-of-fit-for-a-distribution"><i class="fa fa-check"></i><b>13.3.5</b> Evaluating goodness of fit for a distribution</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#twoWayTablesAndChiSquare"><i class="fa fa-check"></i><b>13.4</b> Testing for independence in two-way tables (special topic)</a><ul>
<li class="chapter" data-level="13.4.1" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#expected-counts-in-two-way-tables"><i class="fa fa-check"></i><b>13.4.1</b> Expected counts in two-way tables</a></li>
<li class="chapter" data-level="13.4.2" data-path="inferenceForCategoricalData.html"><a href="inferenceForCategoricalData.html#the-chi-square-test-for-two-way-tables"><i class="fa fa-check"></i><b>13.4.2</b> The chi-square test for two-way tables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="gifs.html"><a href="gifs.html"><i class="fa fa-check"></i><b>14</b> GIFs</a><ul>
<li class="chapter" data-level="14.1" data-path="gifs.html"><a href="gifs.html#correlation-gifs"><i class="fa fa-check"></i><b>14.1</b> Correlation GIFs</a><ul>
<li class="chapter" data-level="14.1.1" data-path="gifs.html"><a href="gifs.html#n10-both-variables-drawn-from-a-uniform-distribution"><i class="fa fa-check"></i><b>14.1.1</b> N=10, both variables drawn from a uniform distribution</a></li>
<li class="chapter" data-level="14.1.2" data-path="gifs.html"><a href="gifs.html#correlation-between-random-deviates-from-uniform-distribution-across-four-sample-sizes"><i class="fa fa-check"></i><b>14.1.2</b> Correlation between random deviates from uniform distribution across four sample sizes</a></li>
<li class="chapter" data-level="14.1.3" data-path="gifs.html"><a href="gifs.html#correlation-between-random-deviates-from-normal-distribution-across-four-sample-sizes"><i class="fa fa-check"></i><b>14.1.3</b> Correlation between random deviates from normal distribution across four sample sizes</a></li>
<li class="chapter" data-level="14.1.4" data-path="gifs.html"><a href="gifs.html#type-i-errors-sampling-random-deviates-from-normal-distribution-with-regression-lines"><i class="fa fa-check"></i><b>14.1.4</b> Type I errors, sampling random deviates from normal distribution with regression lines</a></li>
<li class="chapter" data-level="14.1.5" data-path="gifs.html"><a href="gifs.html#cell-size-and-correlation"><i class="fa fa-check"></i><b>14.1.5</b> Cell-size and correlation</a></li>
<li class="chapter" data-level="14.1.6" data-path="gifs.html"><a href="gifs.html#regression"><i class="fa fa-check"></i><b>14.1.6</b> Regression</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="gifs.html"><a href="gifs.html#sampling-distributions"><i class="fa fa-check"></i><b>14.2</b> Sampling distributions</a><ul>
<li class="chapter" data-level="14.2.1" data-path="gifs.html"><a href="gifs.html#sampling-from-a-uniform-distribution"><i class="fa fa-check"></i><b>14.2.1</b> Sampling from a uniform distribution</a></li>
<li class="chapter" data-level="14.2.2" data-path="gifs.html"><a href="gifs.html#sampling-distribution-of-the-mean-normal-population-distribution-and-sample-histograms"><i class="fa fa-check"></i><b>14.2.2</b> Sampling distribution of the mean, Normal population distribution and sample histograms</a></li>
<li class="chapter" data-level="14.2.3" data-path="gifs.html"><a href="gifs.html#null-and-true-effect-samples-and-sampling-means"><i class="fa fa-check"></i><b>14.2.3</b> Null and True effect samples and sampling means</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="gifs.html"><a href="gifs.html#statistical-inference"><i class="fa fa-check"></i><b>14.3</b> Statistical Inference</a><ul>
<li class="chapter" data-level="14.3.1" data-path="gifs.html"><a href="gifs.html#randomization-test"><i class="fa fa-check"></i><b>14.3.1</b> Randomization Test</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Answering questions with data</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="DescribingData" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Describing Data</h1>
<p><span class="newthought"> Far better an approximate answer to the right question, which is often vague, than an exact answer to the wrong question, which can always be made precise. —John W. Tukey </span></p>
<div class="marginnote">
<p>Chapter by Matthew Crump</p>
</div>
<p>This chapter is about <strong>descriptive statistics</strong>. These are tools for describing data. Some things to keep in mind as we go along are:</p>
<ol style="list-style-type: decimal">
<li>There are lots of different ways to describe data</li>
<li>There is more than one “correct” way, and you get to choose the most “useful” way for the data that you are describing</li>
<li>It is possible to invent new ways of describing data, all of the ways we discuss were previously invented by other people, and they are commonly used because they are useful.</li>
<li>Describing data is necessary because there is usually too much of it, so it doesn’t make any sense by itself.</li>
</ol>
<div id="this-is-what-too-many-numbers-looks-like" class="section level2">
<h2><span class="header-section-number">2.1</span> This is what too many numbers looks like</h2>
<p>Let’s say you wanted to know how happy people are. So, you ask thousands of people on the street how happy they are. You let them pick any number they want from negative infinity to positive infinity. Then you record all the numbers. Now what?</p>
<p>Well, how about you look at the numbers and see if that helps you determine anything about how happy people are. What could the numbers look like. Perhaps something like this:</p>
<table>
<tbody>
<tr class="odd">
<td align="right">750</td>
<td align="right">417</td>
<td align="right">500</td>
<td align="right">370</td>
<td align="right">131</td>
<td align="right">268</td>
<td align="right">-209</td>
<td align="right">-144</td>
<td align="right">314</td>
<td align="right">-99</td>
</tr>
<tr class="even">
<td align="right">341</td>
<td align="right">-157</td>
<td align="right">-272</td>
<td align="right">155</td>
<td align="right">-993</td>
<td align="right">607</td>
<td align="right">305</td>
<td align="right">-12</td>
<td align="right">575</td>
<td align="right">654</td>
</tr>
<tr class="odd">
<td align="right">-1514</td>
<td align="right">-507</td>
<td align="right">-305</td>
<td align="right">180</td>
<td align="right">872</td>
<td align="right">298</td>
<td align="right">-752</td>
<td align="right">146</td>
<td align="right">-37</td>
<td align="right">-1</td>
</tr>
<tr class="even">
<td align="right">-285</td>
<td align="right">759</td>
<td align="right">-23</td>
<td align="right">-446</td>
<td align="right">372</td>
<td align="right">-363</td>
<td align="right">312</td>
<td align="right">529</td>
<td align="right">603</td>
<td align="right">-32</td>
</tr>
<tr class="odd">
<td align="right">-7</td>
<td align="right">-19</td>
<td align="right">-940</td>
<td align="right">899</td>
<td align="right">286</td>
<td align="right">1</td>
<td align="right">567</td>
<td align="right">114</td>
<td align="right">497</td>
<td align="right">-434</td>
</tr>
<tr class="even">
<td align="right">-511</td>
<td align="right">854</td>
<td align="right">-496</td>
<td align="right">138</td>
<td align="right">351</td>
<td align="right">693</td>
<td align="right">-285</td>
<td align="right">-599</td>
<td align="right">268</td>
<td align="right">184</td>
</tr>
<tr class="odd">
<td align="right">-257</td>
<td align="right">133</td>
<td align="right">210</td>
<td align="right">-37</td>
<td align="right">474</td>
<td align="right">663</td>
<td align="right">113</td>
<td align="right">1163</td>
<td align="right">1183</td>
<td align="right">215</td>
</tr>
<tr class="even">
<td align="right">-473</td>
<td align="right">303</td>
<td align="right">294</td>
<td align="right">234</td>
<td align="right">-308</td>
<td align="right">474</td>
<td align="right">620</td>
<td align="right">89</td>
<td align="right">-99</td>
<td align="right">529</td>
</tr>
<tr class="odd">
<td align="right">378</td>
<td align="right">-76</td>
<td align="right">-659</td>
<td align="right">652</td>
<td align="right">-981</td>
<td align="right">549</td>
<td align="right">-398</td>
<td align="right">44</td>
<td align="right">286</td>
<td align="right">268</td>
</tr>
<tr class="even">
<td align="right">334</td>
<td align="right">346</td>
<td align="right">259</td>
<td align="right">225</td>
<td align="right">254</td>
<td align="right">373</td>
<td align="right">721</td>
<td align="right">-225</td>
<td align="right">-397</td>
<td align="right">-505</td>
</tr>
<tr class="odd">
<td align="right">718</td>
<td align="right">63</td>
<td align="right">-172</td>
<td align="right">869</td>
<td align="right">143</td>
<td align="right">80</td>
<td align="right">533</td>
<td align="right">-80</td>
<td align="right">-175</td>
<td align="right">88</td>
</tr>
<tr class="even">
<td align="right">600</td>
<td align="right">-274</td>
<td align="right">-474</td>
<td align="right">25</td>
<td align="right">138</td>
<td align="right">688</td>
<td align="right">52</td>
<td align="right">25</td>
<td align="right">584</td>
<td align="right">230</td>
</tr>
<tr class="odd">
<td align="right">151</td>
<td align="right">290</td>
<td align="right">-159</td>
<td align="right">-1127</td>
<td align="right">-81</td>
<td align="right">345</td>
<td align="right">-57</td>
<td align="right">6</td>
<td align="right">111</td>
<td align="right">149</td>
</tr>
<tr class="even">
<td align="right">-261</td>
<td align="right">941</td>
<td align="right">-40</td>
<td align="right">171</td>
<td align="right">-266</td>
<td align="right">226</td>
<td align="right">-558</td>
<td align="right">-144</td>
<td align="right">-358</td>
<td align="right">942</td>
</tr>
<tr class="odd">
<td align="right">-50</td>
<td align="right">23</td>
<td align="right">922</td>
<td align="right">-357</td>
<td align="right">166</td>
<td align="right">-34</td>
<td align="right">-447</td>
<td align="right">42</td>
<td align="right">-161</td>
<td align="right">833</td>
</tr>
<tr class="even">
<td align="right">565</td>
<td align="right">1128</td>
<td align="right">-241</td>
<td align="right">208</td>
<td align="right">-716</td>
<td align="right">-234</td>
<td align="right">-11</td>
<td align="right">5</td>
<td align="right">377</td>
<td align="right">238</td>
</tr>
<tr class="odd">
<td align="right">-271</td>
<td align="right">-813</td>
<td align="right">336</td>
<td align="right">1224</td>
<td align="right">290</td>
<td align="right">-10</td>
<td align="right">-182</td>
<td align="right">413</td>
<td align="right">693</td>
<td align="right">919</td>
</tr>
<tr class="even">
<td align="right">24</td>
<td align="right">114</td>
<td align="right">-74</td>
<td align="right">-549</td>
<td align="right">70</td>
<td align="right">350</td>
<td align="right">-391</td>
<td align="right">560</td>
<td align="right">413</td>
<td align="right">302</td>
</tr>
<tr class="odd">
<td align="right">788</td>
<td align="right">472</td>
<td align="right">135</td>
<td align="right">384</td>
<td align="right">184</td>
<td align="right">128</td>
<td align="right">-662</td>
<td align="right">488</td>
<td align="right">-61</td>
<td align="right">158</td>
</tr>
<tr class="even">
<td align="right">-828</td>
<td align="right">-419</td>
<td align="right">-315</td>
<td align="right">865</td>
<td align="right">-171</td>
<td align="right">468</td>
<td align="right">629</td>
<td align="right">-265</td>
<td align="right">-173</td>
<td align="right">-1196</td>
</tr>
<tr class="odd">
<td align="right">-936</td>
<td align="right">25</td>
<td align="right">801</td>
<td align="right">354</td>
<td align="right">345</td>
<td align="right">730</td>
<td align="right">162</td>
<td align="right">-277</td>
<td align="right">-27</td>
<td align="right">-504</td>
</tr>
<tr class="even">
<td align="right">-127</td>
<td align="right">253</td>
<td align="right">-197</td>
<td align="right">714</td>
<td align="right">678</td>
<td align="right">-317</td>
<td align="right">-422</td>
<td align="right">-1088</td>
<td align="right">230</td>
<td align="right">-654</td>
</tr>
<tr class="odd">
<td align="right">1041</td>
<td align="right">-133</td>
<td align="right">-500</td>
<td align="right">-70</td>
<td align="right">115</td>
<td align="right">-185</td>
<td align="right">210</td>
<td align="right">195</td>
<td align="right">414</td>
<td align="right">-355</td>
</tr>
<tr class="even">
<td align="right">-371</td>
<td align="right">-91</td>
<td align="right">585</td>
<td align="right">3</td>
<td align="right">261</td>
<td align="right">624</td>
<td align="right">118</td>
<td align="right">-501</td>
<td align="right">358</td>
<td align="right">622</td>
</tr>
<tr class="odd">
<td align="right">-459</td>
<td align="right">268</td>
<td align="right">284</td>
<td align="right">217</td>
<td align="right">-878</td>
<td align="right">-838</td>
<td align="right">529</td>
<td align="right">572</td>
<td align="right">-1011</td>
<td align="right">319</td>
</tr>
<tr class="even">
<td align="right">-774</td>
<td align="right">-10</td>
<td align="right">-383</td>
<td align="right">-214</td>
<td align="right">256</td>
<td align="right">-66</td>
<td align="right">228</td>
<td align="right">30</td>
<td align="right">-542</td>
<td align="right">645</td>
</tr>
<tr class="odd">
<td align="right">247</td>
<td align="right">362</td>
<td align="right">569</td>
<td align="right">-162</td>
<td align="right">-320</td>
<td align="right">-786</td>
<td align="right">169</td>
<td align="right">-102</td>
<td align="right">-73</td>
<td align="right">757</td>
</tr>
<tr class="even">
<td align="right">-886</td>
<td align="right">860</td>
<td align="right">165</td>
<td align="right">-927</td>
<td align="right">570</td>
<td align="right">134</td>
<td align="right">406</td>
<td align="right">-546</td>
<td align="right">399</td>
<td align="right">-234</td>
</tr>
<tr class="odd">
<td align="right">-850</td>
<td align="right">131</td>
<td align="right">-880</td>
<td align="right">2</td>
<td align="right">-719</td>
<td align="right">159</td>
<td align="right">123</td>
<td align="right">-814</td>
<td align="right">86</td>
<td align="right">-222</td>
</tr>
<tr class="even">
<td align="right">928</td>
<td align="right">291</td>
<td align="right">312</td>
<td align="right">88</td>
<td align="right">433</td>
<td align="right">172</td>
<td align="right">309</td>
<td align="right">-269</td>
<td align="right">164</td>
<td align="right">-708</td>
</tr>
<tr class="odd">
<td align="right">-660</td>
<td align="right">-6</td>
<td align="right">181</td>
<td align="right">403</td>
<td align="right">-404</td>
<td align="right">199</td>
<td align="right">-217</td>
<td align="right">-192</td>
<td align="right">413</td>
<td align="right">91</td>
</tr>
<tr class="even">
<td align="right">674</td>
<td align="right">-433</td>
<td align="right">-360</td>
<td align="right">492</td>
<td align="right">344</td>
<td align="right">821</td>
<td align="right">457</td>
<td align="right">458</td>
<td align="right">-376</td>
<td align="right">-149</td>
</tr>
<tr class="odd">
<td align="right">-515</td>
<td align="right">464</td>
<td align="right">442</td>
<td align="right">294</td>
<td align="right">396</td>
<td align="right">382</td>
<td align="right">122</td>
<td align="right">-408</td>
<td align="right">222</td>
<td align="right">17</td>
</tr>
<tr class="even">
<td align="right">-372</td>
<td align="right">316</td>
<td align="right">365</td>
<td align="right">81</td>
<td align="right">-23</td>
<td align="right">658</td>
<td align="right">128</td>
<td align="right">217</td>
<td align="right">276</td>
<td align="right">308</td>
</tr>
<tr class="odd">
<td align="right">74</td>
<td align="right">-114</td>
<td align="right">633</td>
<td align="right">-296</td>
<td align="right">-128</td>
<td align="right">-186</td>
<td align="right">502</td>
<td align="right">1219</td>
<td align="right">-567</td>
<td align="right">-249</td>
</tr>
<tr class="even">
<td align="right">214</td>
<td align="right">-41</td>
<td align="right">603</td>
<td align="right">-123</td>
<td align="right">389</td>
<td align="right">-96</td>
<td align="right">376</td>
<td align="right">618</td>
<td align="right">-289</td>
<td align="right">-396</td>
</tr>
<tr class="odd">
<td align="right">205</td>
<td align="right">382</td>
<td align="right">-172</td>
<td align="right">1215</td>
<td align="right">720</td>
<td align="right">-196</td>
<td align="right">5</td>
<td align="right">-111</td>
<td align="right">308</td>
<td align="right">-137</td>
</tr>
<tr class="even">
<td align="right">261</td>
<td align="right">-507</td>
<td align="right">259</td>
<td align="right">-3</td>
<td align="right">506</td>
<td align="right">-922</td>
<td align="right">-311</td>
<td align="right">53</td>
<td align="right">-594</td>
<td align="right">248</td>
</tr>
<tr class="odd">
<td align="right">-701</td>
<td align="right">-370</td>
<td align="right">711</td>
<td align="right">363</td>
<td align="right">-378</td>
<td align="right">458</td>
<td align="right">134</td>
<td align="right">-178</td>
<td align="right">-75</td>
<td align="right">367</td>
</tr>
<tr class="even">
<td align="right">-351</td>
<td align="right">-763</td>
<td align="right">-66</td>
<td align="right">183</td>
<td align="right">-496</td>
<td align="right">-38</td>
<td align="right">-146</td>
<td align="right">257</td>
<td align="right">-314</td>
<td align="right">56</td>
</tr>
<tr class="odd">
<td align="right">85</td>
<td align="right">566</td>
<td align="right">678</td>
<td align="right">806</td>
<td align="right">1068</td>
<td align="right">345</td>
<td align="right">414</td>
<td align="right">601</td>
<td align="right">804</td>
<td align="right">-177</td>
</tr>
<tr class="even">
<td align="right">128</td>
<td align="right">447</td>
<td align="right">517</td>
<td align="right">-659</td>
<td align="right">678</td>
<td align="right">-133</td>
<td align="right">123</td>
<td align="right">-157</td>
<td align="right">1076</td>
<td align="right">1109</td>
</tr>
<tr class="odd">
<td align="right">884</td>
<td align="right">1921</td>
<td align="right">-187</td>
<td align="right">361</td>
<td align="right">-486</td>
<td align="right">-449</td>
<td align="right">-1076</td>
<td align="right">380</td>
<td align="right">95</td>
<td align="right">303</td>
</tr>
<tr class="even">
<td align="right">9</td>
<td align="right">172</td>
<td align="right">-129</td>
<td align="right">-34</td>
<td align="right">393</td>
<td align="right">-349</td>
<td align="right">162</td>
<td align="right">-259</td>
<td align="right">882</td>
<td align="right">-128</td>
</tr>
<tr class="odd">
<td align="right">948</td>
<td align="right">371</td>
<td align="right">856</td>
<td align="right">130</td>
<td align="right">-619</td>
<td align="right">103</td>
<td align="right">505</td>
<td align="right">-1</td>
<td align="right">93</td>
<td align="right">572</td>
</tr>
<tr class="even">
<td align="right">40</td>
<td align="right">505</td>
<td align="right">91</td>
<td align="right">642</td>
<td align="right">871</td>
<td align="right">957</td>
<td align="right">963</td>
<td align="right">-45</td>
<td align="right">854</td>
<td align="right">-419</td>
</tr>
<tr class="odd">
<td align="right">-176</td>
<td align="right">179</td>
<td align="right">680</td>
<td align="right">398</td>
<td align="right">2</td>
<td align="right">-878</td>
<td align="right">314</td>
<td align="right">1728</td>
<td align="right">414</td>
<td align="right">103</td>
</tr>
<tr class="even">
<td align="right">155</td>
<td align="right">328</td>
<td align="right">626</td>
<td align="right">-338</td>
<td align="right">675</td>
<td align="right">-290</td>
<td align="right">-262</td>
<td align="right">132</td>
<td align="right">-189</td>
<td align="right">856</td>
</tr>
<tr class="odd">
<td align="right">-318</td>
<td align="right">-101</td>
<td align="right">-792</td>
<td align="right">734</td>
<td align="right">315</td>
<td align="right">322</td>
<td align="right">-34</td>
<td align="right">73</td>
<td align="right">155</td>
<td align="right">-181</td>
</tr>
<tr class="even">
<td align="right">1092</td>
<td align="right">1314</td>
<td align="right">306</td>
<td align="right">-478</td>
<td align="right">605</td>
<td align="right">799</td>
<td align="right">-348</td>
<td align="right">405</td>
<td align="right">-150</td>
<td align="right">915</td>
</tr>
</tbody>
</table>
<p>Now, what are you going to with that big pile of numbers? Look at it all day long?. When you deal with data, it will deal so many numbers to you that you will be overwhelmed by them. That is why we need ways to describe the data in a more manageable fashion.</p>
<p>The complete description on the data is always the data itself. <strong>Descriptive statistics</strong> and other tools for describing data go one step further to summarize aspects of the data. Summaries are a way to compress the important bits of a thing down to a useful and manageable tidbit. It’s like telling your friends why they should watch a movie. When they ask what it is about, you don’t replay the entire movie for them, instead you hit the highlights. Summarizing the data is just like a movie preview, only for data.</p>
</div>
<div id="look-at-the-data" class="section level2">
<h2><span class="header-section-number">2.2</span> Look at the data</h2>
<p>We already tried one way of looking at the numbers, and it wasn’t useful. Let’s look at some other ways of looking at the numbers in graphs. Graphing data by putting them in plots or figures can help us see the data.</p>
<div id="stop-plotting-time-o-o-oh-u-can-plot-this" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Stop, plotting time (o o oh) U can plot this</h3>
<p>Let’s turn all of the numbers into dots, then show them in a graph. Note, when we do this we have not yet summarized anything about the data. Instead, in this step we just look at all of the data in a visual format, rather than looking at the numbers.</p>
<div class="figure"><span id="fig:happyPlot"></span>
<img src="statistics_files/figure-html/happyPlot-1.png" alt="Pretend happiness ratings from 500 people" width="672" />
<p class="caption">
Figure 2.1: Pretend happiness ratings from 500 people
</p>
</div>
<p>Figure <a href="DescribingData.html#fig:happyPlot">2.1</a> shows 500 measurements of happiness. The graph has two axes. The horizontal <strong>x-axis</strong>, going from left to right is labeled “Index”. The vertical <strong>y-axis</strong>, going up and down, is labelled “happiness”. Each dot represents one measurement of every person’s happiness from our pretend study. Before we talk about what we can and cannot see about the data, it is worth mentioning that the way you plot the data will make some things easier to see and some things harder to see. So, what can we now see about the data?</p>
<p>There are lots of dots everywhere. It looks like there are 500 of them because the index goes to 500. It looks like some dots go as high as 1000-1500 and as low as -1500. It looks like there are more dots in the middle-ish area of the plot, sort of spread about 0.</p>
<blockquote>
<p>Take home: we can see all the numbers at once by putting them in a plot, and that is much easier and more helpful than looking at the raw numbers.</p>
</blockquote>
<p>OK, so if these dots represent how happy 500 people are, what can we say about those people? First, the dots are kind of all over the place, so different people have different levels of happiness. Are there any trends? Are more people happy than unhappy, or vice-versa? It’s hard to see that in the graph, so let’s make a different one, called a <strong>histogram</strong></p>
</div>
<div id="histograms" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Histograms</h3>
<p>Making a histogram will be our first act of officially summarizing something about the data. We will no longer the individual bits of data, instead we will see how the numbers group together. Let’s look at a histogram of the happiness data, and then explain it.</p>
<div class="figure"><span id="fig:happyHist"></span>
<img src="statistics_files/figure-html/happyHist-1.png" alt="A histrogram of the happiness ratings" width="672" />
<p class="caption">
Figure 2.2: A histrogram of the happiness ratings
</p>
</div>
<p>The dots have disappeared, and now we some bars. Each bar is a summary of the dots, representing the number of dots (frequency count) inside a particular range of happiness, also called <strong>bins</strong>. For example, how many people gave a happiness rating between 0 and 500? Well, the fifth bar, the one between 0 and 500 and the x-axis, tells you how many? Look how tall that bar is. How tall is it? Well, the height is shown on the y-axis, which provides a frequency count (the number of dots or data points). It looks like around 150 people sad their happiness was between 0-500.</p>
<p>More generally, we see there are many bins on the x-axis. We have divided the data into bins of 500. Bin #1 goes from -2000 to -1500, bin #2 goes from -1500 to -1000, and so until the last bin. To make the histogram, we just count up the number of data points falling inside each bin, then plot those frequency counts as a function of the bins. Voila, a histogram.</p>
<p>What does the histogram help us see about the data? First, we can see the <strong>shape</strong> of data. The shape of the histogram refers to how it goes up and down. The shape tells us where the data is. For example, when the bars are low we know there isn’t much data there. When the bars are high, we know there is more data there. So, where is most of the data? It looks like it’s mostly in the middle two bins, between -500 and 500. We can also see the <strong>range</strong> of the data. This tells us the minimums and the maximums of the data. Most of the data is between -1500 and +1500, so no infinite sadness or infinite happiness in our data-set.</p>
</div>
</div>
<div id="important-ideas-distribution-central-tendency-and-variance" class="section level2">
<h2><span class="header-section-number">2.3</span> Important Ideas: Distribution, Central Tendency, and Variance</h2>
<p>Let’s introduce a three important terms we will use a lot, <strong>distribution</strong>, <strong>central tendency</strong>, and <strong>variance</strong>. These terms are similar to their everyday meanings (although I suspect most people don’t say central tendency very often).</p>
<p><strong>Distribution.</strong> When you order something from Amazon, where does it come from, and how does it get to your place? That stuff comes from one of Amazon’s distribution centers. They distribute all sorts of things by spreading them around to your doorstep. Distribute is spreading something. Notice, the histogram, distributes the data by spreading the numbers across the bins. We can also talk about a distribution as a noun. The histogram is a distribution of the frequency counts across the bins. Distributions are <strong>very, very, very, very, very</strong> important. They can have many different shapes. They can describe data, like in the histogram above. And as we will learn in later chapters, they can <strong>produce</strong> data. Many times we will be asking questions about where our data came from, and this usually means asking what kind of distribution could have created our data (more on that later.)</p>
<p><strong>Central Tendency</strong> is all about sameness. Is there anything similar about all of the numbers in the histogram? Yes, we can say that most of them are near 0. There is a tendency for most of the numbers to be centered near 0. Notice we are being cautious about our generalization about the numbers. We are not saying they are all 0. We are saying there is a tendency for many of them to be near zero. There are lots of ways to talk about the central tendency of some numbers. There can even be more than one kind of tendency. For example, if lots of the numbers were around -1000, and a similar large amount of numbers were grouped around 1000, we could say there was two tendencies.</p>
<p><strong>Variance</strong> is all about differentness. Is there anything different about all of the numbers in the histogram? YES!!! The numbers are not all the same! When the numbers are not all the same, they must vary. So, the variance in the numbers refers to how the numbers are different. There are many ways to summarize the amount of variance in the numbers, and we discuss these very soon.</p>
</div>
<div id="measures-of-central-tendency-sameness" class="section level2">
<h2><span class="header-section-number">2.4</span> Measures of Central Tendency (Sameness)</h2>
<p>We’ve seen that we can get a sense of data by plotting dots in a graph, and by making a histogram. These tools show us what the numbers look like, approximately how big and small they are, and how similar and different they are from another. It is good to get a feeling about the numbers in this way. But, these visual sensitudes are not very precise. In addition to summarizing numbers with graphs, we can summarize numbers using numbers (NO, please not more numbers, we promise numbers can be your friend).</p>
<div id="from-many-numbers-to-one" class="section level3">
<h3><span class="header-section-number">2.4.1</span> From many numbers to one</h3>
<p>Measures of central have one important summary goal: to reduce a pile of numbers to a single number that we can look at. We already know looking at thousands of numbers is hopeless. Wouldn’t it be nice if we could just look at one number instead? We think so. It turns out there are lots of ways to do this. Then, if your friend ever asks the frightening question, “hey, what are all these numbers like?”. You can say they are like this one number right here.</p>
<p>But, just like in Indiana Jones and the Last Crusade (highly recommended movie), you must choose your measure of central tendency wisely.</p>
</div>
<div id="mode" class="section level3">
<h3><span class="header-section-number">2.4.2</span> Mode</h3>
<p>The <strong>mode</strong> is the most frequently occurring number in your measurement. That is it. How do you find it? You have count the number of times each number appears in your measure, then whichever one occurs the most, is the mode.</p>
<blockquote>
<p>Example: 1 1 1 2 3 4 5 6</p>
</blockquote>
<p>The mode of the above set is 1, which occurs three times. Every other number only occurs once.</p>
<p>OK fine. What happens here:</p>
<blockquote>
<p>Example: 1 1 1 2 2 2 3 4 5 6</p>
</blockquote>
<p>Hmm, now 1 and 2 both occur three times each. What do we do? We say there are two modes, and they are 1 and 2.</p>
<p>Why is the mode a measure of central tendency? Well, when we ask, “what are my numbers like”, we can say, “most of the number are, like a 1 (or whatever the mode is)”.</p>
<p>Is the mode a good measure of central tendency? Well, that depends on your numbers. For example, consider these numbers</p>
<blockquote>
<p>1 1 2 3 4 5 6 7 8 9</p>
</blockquote>
<p>Here, the mode is 1 again, because there are two 1s, and all of the other numbers occur once. But, are most of the numbers like, a 1. No, they are mostly not 1s.</p>
<p>“Argh, so should I or should I not use the mode? I thought this class was supposed to tell me what to do?”. There is no telling you what to do. Every time you use a tool in statistics you have to think about what you are doing and justify why what you are doing makes sense. Sorry.</p>
</div>
<div id="median" class="section level3">
<h3><span class="header-section-number">2.4.3</span> Median</h3>
<p>The <strong>median</strong> is the exact middle of the data. After all, we are asking about central tendency, so why not go to the center of the data and see where we are. What do you mean middle of the data? Let’s look at these numbers:</p>
<blockquote>
<p>1 5 4 3 6 7 9</p>
</blockquote>
<p>Umm, OK. So, three is in the middle? Isn’t that kind of arbitrary. Yes. Before we can compute the median, we need to order the numbers from smallest to largest.</p>
<blockquote>
<p>1 3 4 <strong>5</strong> 6 7 9</p>
</blockquote>
<p>Now, 5 is in the middle. And, by middle we mean in the middle. There are three numbers to the left of 5, and three numbers to the right. So, five is definitely in the middle.</p>
<p>OK fine, but what happens when there aren’t an even number of numbers? Then the middle will be missing right? let’s see</p>
<blockquote>
<p>1 2 3 4 5 6</p>
</blockquote>
<p>There is no number between 3 and 4, the middle is empty. In this case, we compute the median by figuring out the number in between 3 and 4. So, the median would be 3.5.</p>
<p>Is the median a good measure of central tendency? Sure, it is often very useful. One property of the median is that it stays in the middle even when some of the other numbers get really weird. For example, consider these numbers:</p>
<blockquote>
<p>1 2 3 4 4 4 <strong>5</strong> 6 6 6 7 7 1000</p>
</blockquote>
<p>Most of these numbers are smallish, but the 1000 is a big old weird number, very different from the rest. The median is still 5, because it is in the middle of these ordered numbers. We can also see that five is pretty similar to most of the numbers (except for 1000). So, the median does a pretty good job of representing most of the numbers in the set, and it does so even if one or two of the numbers are very different from the others.</p>
<p>Finally, <strong>outlier</strong> is a term will we use to describe numbers that appear in data that are very different from the rest. 1000 is an outlier, because it lies way out there on the number compared to the other numbers. What to do with outliers is another topic we cover later in the book.</p>
</div>
<div id="mean" class="section level3">
<h3><span class="header-section-number">2.4.4</span> Mean</h3>
<p>Have you noticed this is a textbook about statistics that hasn’t used a formula yet? That is about to change, but for those of you with formula anxiety, don’t worry, we will do our best to explain them.</p>
<p>The <strong>mean</strong> is also called the average. And, we’re guessing you might already now what the average of a bunch of numbers is? It’s the sum of the numbers, divided by the number of number right? How do we express that idea in a formula? Just like this:</p>
<p><span class="math inline">\(Mean = \bar{X} = \frac{\sum_{i=1}^{n} x_{i}}{N}\)</span></p>
<p>“That looks like Greek to me”. Yup. The <span class="math inline">\(\sum\)</span> symbol is called <strong>sigma</strong>, and it stands for the operation of summing. The little “i” on the bottom, and the little “n” on the top refers to all of the numbers in the set, from the first number “i” to the last number “n”. The letters are just arbitrary labels, called <strong>variables</strong> that we use for descriptive purposes. The <span class="math inline">\(x_{i}\)</span> refers to individual numbers in the set. We sum up all of the numbers, then divide the sum by <span class="math inline">\(N\)</span>, which is the total number of numbers. Sometime you will see <span class="math inline">\(\bar{X}\)</span> to refer to the mean of all of the numbers inside <span class="math inline">\(X_{i}\)</span>, which refers to all of our numbers.</p>
<p>In plain English, the formula looks like:</p>
<p><span class="math inline">\(mean = \frac{\text{Sum of my numbers}}{\text{Count of my numbers}}\)</span></p>
<p>“Well, why didn’t you just say that?”. We just did.</p>
<p>Let’s compute the mean for these five numbers:</p>
<blockquote>
<p>3 7 9 2 6</p>
</blockquote>
<p>Add em up:</p>
<blockquote>
<p>3+7+9+2+6 = 27</p>
</blockquote>
<p>Count em up:</p>
<blockquote>
<p><span class="math inline">\(i_{1}\)</span> = 3, <span class="math inline">\(i_{2}\)</span> = 7, <span class="math inline">\(i_{3}\)</span> = 9, <span class="math inline">\(i_{4}\)</span> = 2, <span class="math inline">\(i_{5}\)</span> = 6; N=5, because <span class="math inline">\(i\)</span> went from 1 to 5</p>
</blockquote>
<p>Divide em:</p>
<blockquote>
<p>mean = 27 / 5 = 5.4</p>
</blockquote>
<p>Or, to put the numbers in the formula, it looks like this:</p>
<p><span class="math inline">\(Mean = \bar{X} = \frac{\sum_{i=1}^{n} x_{i}}{N} = \frac{3+7+9+2+6}{5} = \frac{27}{5} = 5.4\)</span></p>
<p>OK fine, that is how to compute the mean. But, like we imagined, you probably already knew that, and if you didn’t that’s OK, now you do. What’s next?</p>
<p>Is the mean a good measure of central tendency? You should know now the answer to this question is: it depends.</p>
</div>
<div id="what-does-the-mean-mean" class="section level3">
<h3><span class="header-section-number">2.4.5</span> What does the mean mean?</h3>
<p>It is not enough to know the formula for the mean, or to be able to use the formula to compute a mean for a set of numbers. We believe in your ability to add and divide numbers. What you really need to know is what the mean really “means”. This requires that you know what the mean does, and not just how to do it. Puzzled? Let’s explain.</p>
<p>Can you answer this question: What happens when you divide a sum of numbers by the number of numbers? What are the consequences of doing this? What is the formula doing? What kind of properties does the result give us? FYI, the answer is not that we compute the mean.</p>
<p>OK, so what happens when you divide any number by another number? Of course, the key word here is divide. We literally carve the number up top in the numerator into pieces. How many times do we split the top number? That depends on the bottom number in the denominator. Watch:</p>
<p><span class="math inline">\(\frac{12}{3} = 4\)</span></p>
<p>So, we know the answer is 4. But, what is really going on here is that we are slicing and dicing up 12 aren’t we. The answer 4 tells us that we can slice and dice 12 up into three perfect pieces. So, now we are thinking of 12 as three different pieces <span class="math inline">\(= 4 + 4 + 4\)</span>. I know this will be obvious, but what kind of properties do our pieces have? You mean the fours? Yup. Well, obviously they are all fours. Yes. The pieces are all the same size. They are all equal. So, division equalizes the numerator by the denominator…</p>
<p>“Umm, I think I learned this in elementary school, what does this have to do with the mean?”. The number on top of the formula for the mean is just another numerator being divided by a denominator isn’t it. In this case, the numerator is a sum of all the values in your data. What if it was the sum of all of the happiness ratings? We saw earlier that there were 500 people gave different ratings. The sum of all of them would just be a single number adding up all the different ratings. If we split the sum up into equal parts representing one part for each person’s happiness what would we get? We would get 500 identical and equal numbers for each person. It would be like taking all of the happiness in the world, then dividing it up equally, then to be fair, giving back the same equal amount of happiness to everyone in the world. This would make some people more happy than they were before, and some people less happy right. Of course, that’s because it would be equalizing the distribution of happiness for everybody. This process of equalization by dividing something into equal parts is what the <strong>mean</strong> does. See, it’s more than just a formula. It’s an idea. This is just the beginning of thinking about these kinds of ideas. We will come back to this idea about the mean, and other ideas, in later chapters.</p>
<blockquote>
<p>Pro tip: The mean is the one and only number that can take the place of every number in the data, such that when you add up all the equal parts, you get back the original sum of the data.</p>
</blockquote>
</div>
</div>
<div id="measures-of-variation-differentness" class="section level2">
<h2><span class="header-section-number">2.5</span> Measures of Variation (Differentness)</h2>
<p>What did you do when you wrote essay’s in high school about a book you read? Probably compare and contrast something right? When you summarize data, you do the same thing. Measures of central tendency give us something like comparing does, it tells us stuff about what is the same. Measures of Variation give us something like contrasting does, it tells us stuff about what is different.</p>
<p>First, we note that whenever you see a bunch of numbers that aren’t the same, you already know there are some differences. This means the numbers vary, and there is variation in the size of the numbers.</p>
<div id="the-range" class="section level3">
<h3><span class="header-section-number">2.5.1</span> The Range</h3>
<p>Consider these 10 numbers, that I already ordered from smallest to largest for you:</p>
<blockquote>
<p>1 5 4 3 6 5 7 8 9 24</p>
</blockquote>
<p>The numbers have variation, because they are not all the same. We can use the range to describe the width of the variation. The range refers to the <strong>minimum</strong> (smallest value) and <strong>maximum</strong> (largest value) in the set. So, the range would be 1 and 24.</p>
<p>The range is a good way to quickly summarize the boundaries of your data in just two numbers. By computing the range we know that none of the data is larger or smaller than the range. And, it can alert you to outliers. For example, if you are expecting your numbers to be between 1 and 7, but you find the range is 1 - 340,500, then you know you have some big numbers that shouldn’t be there, and then you can try to figure out why those numbers occurred (and potentially remove them if something went wrong).</p>
</div>
<div id="the-difference-scores" class="section level3">
<h3><span class="header-section-number">2.5.2</span> The Difference Scores</h3>
<p>It would be nice to summarize the amount of differentness in the data. Here’s why. If you thought that raw data (lots of numbers) is too big to look at, then you will be frightened to contemplate how many differences there are to look at. For example, these 10 numbers are easy to look at:</p>
<blockquote>
<p>1 5 4 3 6 5 7 8 9 24</p>
</blockquote>
<p>But, what about the difference between the numbers, what do those look like? We can compute the difference scores between each number, then put them in a matrix like the one below:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">1</th>
<th align="right">5</th>
<th align="right">4</th>
<th align="right">3</th>
<th align="right">6</th>
<th align="right">5</th>
<th align="right">7</th>
<th align="right">8</th>
<th align="right">9</th>
<th align="right">24</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td align="right">0</td>
<td align="right">4</td>
<td align="right">3</td>
<td align="right">2</td>
<td align="right">5</td>
<td align="right">4</td>
<td align="right">6</td>
<td align="right">7</td>
<td align="right">8</td>
<td align="right">23</td>
</tr>
<tr class="even">
<td>5</td>
<td align="right">-4</td>
<td align="right">0</td>
<td align="right">-1</td>
<td align="right">-2</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">4</td>
<td align="right">19</td>
</tr>
<tr class="odd">
<td>4</td>
<td align="right">-3</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">-1</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">20</td>
</tr>
<tr class="even">
<td>3</td>
<td align="right">-2</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">2</td>
<td align="right">4</td>
<td align="right">5</td>
<td align="right">6</td>
<td align="right">21</td>
</tr>
<tr class="odd">
<td>6</td>
<td align="right">-5</td>
<td align="right">-1</td>
<td align="right">-2</td>
<td align="right">-3</td>
<td align="right">0</td>
<td align="right">-1</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">18</td>
</tr>
<tr class="even">
<td>5</td>
<td align="right">-4</td>
<td align="right">0</td>
<td align="right">-1</td>
<td align="right">-2</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">4</td>
<td align="right">19</td>
</tr>
<tr class="odd">
<td>7</td>
<td align="right">-6</td>
<td align="right">-2</td>
<td align="right">-3</td>
<td align="right">-4</td>
<td align="right">-1</td>
<td align="right">-2</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">17</td>
</tr>
<tr class="even">
<td>8</td>
<td align="right">-7</td>
<td align="right">-3</td>
<td align="right">-4</td>
<td align="right">-5</td>
<td align="right">-2</td>
<td align="right">-3</td>
<td align="right">-1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">16</td>
</tr>
<tr class="odd">
<td>9</td>
<td align="right">-8</td>
<td align="right">-4</td>
<td align="right">-5</td>
<td align="right">-6</td>
<td align="right">-3</td>
<td align="right">-4</td>
<td align="right">-2</td>
<td align="right">-1</td>
<td align="right">0</td>
<td align="right">15</td>
</tr>
<tr class="even">
<td>24</td>
<td align="right">-23</td>
<td align="right">-19</td>
<td align="right">-20</td>
<td align="right">-21</td>
<td align="right">-18</td>
<td align="right">-19</td>
<td align="right">-17</td>
<td align="right">-16</td>
<td align="right">-15</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p>We are looking at all of the possible differences between each number and every other number. So, in the top left, the difference between 1 and itself is 0. One column over to the right, the difference between 5 and 1 (5-1) is 4, etc. As you can see, this is a 10x10 matrix, which means there are 100 differences to look at. Not too bad, but if we had 500 numbers, then we would have 500*500 = 250,000 differences to look at (go for it if you like looking at that sort of thing).</p>
<p>Pause for a simple question. What would this matrix look like if all of the 10 numbers in our data were the same number? It should look like a bunch of 0s right? Good. In that case, we could easily see that the numbers have no variation.</p>
<p>But, when the numbers are different, we can see that there is a very large matrix of difference scores. How can we summarize that? How about we apply what we learned from the previous section on measures of central tendency. We have a lot of differences, so we could ask something like, what is the average difference that we have? So, we could just take all of our differences, and compute the mean difference right? What do you think would happen if we did that?</p>
<p>Let’s try it out on these three numbers:</p>
<blockquote>
<p>1 2 3</p>
</blockquote>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">1</th>
<th align="right">2</th>
<th align="right">3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td>2</td>
<td align="right">-1</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td>3</td>
<td align="right">-2</td>
<td align="right">-1</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p>You might already guess what is going to happen. Let’s compute the mean:</p>
<p><span class="math inline">\(\text{mean of difference scores} = \frac{0+1+2-1+0+1-2-1+0}{9} = \frac{0}{9} = 0\)</span></p>
<p>Uh oh, we get zero for the mean of the difference scores. This will always happen whenever you take the mean of the difference scores. We can see that there are some differences between the numbers, so using 0 as the summary value for the variation in the numbers doesn’t make much sense.</p>
<p>Furthermore, you might also notice that the matrices of difference scores are redundant. The diagonal is always zero, and the top numbers are the same as the bottom numbers, except their signs are reversed.</p>
<p>These are little problems that can be solved by computing the <strong>variance</strong> and the <strong>standard deviation</strong>. For now, the standard deviation is a just a trick that we use to avoid getting a zero. But, later we will see it has properties that are important for other reasons.</p>
</div>
<div id="the-variance" class="section level3">
<h3><span class="header-section-number">2.5.3</span> The Variance</h3>
<p>Variability, variation, variance, vary, variable, varying, variety. Confused yet? Before we describe <strong>the variance</strong>, we want to you be OK with how this word is used. First, don’t forget the big picture. We know that variability and variation refers to the big idea of differences between numbers. We can even use the word variance in the same way. When numbers are different, they have variance.</p>
<div class="marginnote">
<p>The formulas for variance and standard deviation depend on whether you think your data represents an entire population of numbers, or is sample from the population. We discuss this issue in later on. For now, we divide by N, later we discuss why you will often divide by N-1 instead.</p>
</div>
<p>The word <strong>variance</strong> also refers to a specific summary statistic, the sum of the squared deviations from the mean. Hold on what? Plain English please. The variance is the sum of the squared difference scores, where the difference scores are computed between each score and the mean. What are these scores? The scores are the numbers in the data set. Let’s see the formula in English first:</p>
<p><span class="math inline">\(variance = \frac{\text{Sum of squared difference scores}}{\text{Number of Scores}}\)</span></p>
<div id="deviations-from-the-mean-difference-scores-from-the-mean" class="section level4">
<h4><span class="header-section-number">2.5.3.1</span> Deviations from the mean, Difference scores from the mean</h4>
<p>We got a little bit complicated before when we computed the difference scores between all of the numbers in the data. Let’s do it again, but in more manageable way. This time, we calculate the difference between each score and the mean. The idea here is</p>
<ol style="list-style-type: decimal">
<li>We can figure out how similar our scores our by computing the mean</li>
<li>Then we can figure out how different our scores our from the mean</li>
</ol>
<p>This could tell us, 1) something about whether our scores are really all very close to the mean (which could help us know if the mean is good representative number of the data), and 2) something about how much differences there are in the numbers.</p>
<p>Take a look at this table:</p>
<table>
<thead>
<tr class="header">
<th align="left">scores</th>
<th align="left">values</th>
<th align="left">mean</th>
<th align="left">Difference_from_Mean</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left">1</td>
<td align="left">4.5</td>
<td align="left">-3.5</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">6</td>
<td align="left">4.5</td>
<td align="left">1.5</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="left">4</td>
<td align="left">4.5</td>
<td align="left">-0.5</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="left">2</td>
<td align="left">4.5</td>
<td align="left">-2.5</td>
</tr>
<tr class="odd">
<td align="left">5</td>
<td align="left">6</td>
<td align="left">4.5</td>
<td align="left">1.5</td>
</tr>
<tr class="even">
<td align="left">6</td>
<td align="left">8</td>
<td align="left">4.5</td>
<td align="left">3.5</td>
</tr>
<tr class="odd">
<td align="left">Sums</td>
<td align="left">27</td>
<td align="left">27</td>
<td align="left">0</td>
</tr>
<tr class="even">
<td align="left">Means</td>
<td align="left">4.5</td>
<td align="left">4.5</td>
<td align="left">0</td>
</tr>
</tbody>
</table>
<p>The first column shows we have 6 scores in the data set, and the ‘value’ columns shows each score. The sum of the values, and the mean is presented on the last two rows. These values were obtained by <span class="math inline">\(\frac{1+6+4+2+6+8}{6} = \frac{27}{6} = 4.5\)</span>.</p>
<p>The third column ‘mean’, appears a bit silly. We are just listing the mean once for every score. If you think back to our discussion about the meaning of the mean, then you will remember that it equally distributes the total sum across each data point. We can see that here, if we treat each score as the mean, then every score is a 4.5. We can also see that adding up all of the means for each score gives us back 27, which is the sum of the original values. Also, we see that if we find the mean of the mean scores, we get back the mean (4.5 again).</p>
<p>All of the action is occurring in the fourth column, ‘Difference_from_Mean’. Here, we are showing the difference scores from the mean, using <span class="math inline">\(X_{i}-\bar{X}\)</span>. In other words, we subtracted the mean from each score. So, the first score, 1, is -3.5 from the mean, the second score, 6, is +1.5 from the mean, and so on.</p>
<p>Now, we can look at our original scores, and we can look at their differences from the mean. Notice, we don’t have a matrix of raw difference scores, so it is much easier to look at out. But, we still have a problem. We can see that there are non-zero values in the difference scores. But, when we add them all up, we still get zero, which makes it seem like there are a total of zero differences in the data…Why does this happen…and what to do about it?</p>
</div>
<div id="the-mean-is-the-balancing-point-in-the-data" class="section level4">
<h4><span class="header-section-number">2.5.3.2</span> The mean is the balancing point in the data</h4>
<p>One brief pause here to point out another wonderful property of the mean. It is the balancing point in the data. If you take a pen or pencil and try to balance it on your figure so it lays flat what are you doing. You need to find the center of mass in the pen, so that have of it is one side, and the other half is on the other side. That’s how balancing works. One side = the other side.</p>
<p>We can think of data as having mass or weight to it. If we put our data on our bathroom scale, we could figure out how heavy it was by summing it up. If we wanted to split the data down the middle so that half of it’s weight was equal to the other half, then we could balance the data on top of a pin. The mean of the data tells you where to put the pin. It is the location in the data, where on the one side the numbers add to the same sum as the numbers on the other side.</p>
<p>If we think this through, it means that the sum of the difference scores from the mean will always add up to zero. This is because the numbers on one side of the mean will always add up to -x (whatever the sum of those numbers is), and the numbers of the other side of the mean will always add up to +x (which will be the same value only positive). And:</p>
<p><span class="math inline">\(-x + x = 0\)</span>, right.</p>
<p>Right.</p>
</div>
<div id="the-squared-deviations" class="section level4">
<h4><span class="header-section-number">2.5.3.3</span> The squared deviations</h4>
<p>Some devious someone divined a solution to the fact that differences scores from the mean always add to zero. Can you think of any solutions? For example, what could you do to the difference scores so that you could add them up, and they would weigh something useful, that is they would not be zero?</p>
<p>The devious solution is to square the numbers. Squaring numbers converts all the negative numbers to positive numbers. For example, <span class="math inline">\(2^2 = 4\)</span>, and <span class="math inline">\(-2^2 = 4\)</span>. Remember how squaring works, we multiply the number twice: <span class="math inline">\(2^2 = 2*2 = 4\)</span>, and <span class="math inline">\(-2^2 = -2*-2 = 4\)</span>. We use the term <strong>squared deviations</strong> to refer to differences scores that have been squared. Deviations are things that move away from something. The difference scores move away from the mean, so we also call them <strong>deviations</strong>.</p>
<p>Let’s look at our table again, but add the squared deviations.</p>
<table>
<thead>
<tr class="header">
<th align="left">scores</th>
<th align="left">values</th>
<th align="left">mean</th>
<th align="left">Difference_from_Mean</th>
<th align="left">Squared_Deviations</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left">1</td>
<td align="left">4.5</td>
<td align="left">-3.5</td>
<td align="left">12.25</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">6</td>
<td align="left">4.5</td>
<td align="left">1.5</td>
<td align="left">2.25</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="left">4</td>
<td align="left">4.5</td>
<td align="left">-0.5</td>
<td align="left">0.25</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="left">2</td>
<td align="left">4.5</td>
<td align="left">-2.5</td>
<td align="left">6.25</td>
</tr>
<tr class="odd">
<td align="left">5</td>
<td align="left">6</td>
<td align="left">4.5</td>
<td align="left">1.5</td>
<td align="left">2.25</td>
</tr>
<tr class="even">
<td align="left">6</td>
<td align="left">8</td>
<td align="left">4.5</td>
<td align="left">3.5</td>
<td align="left">12.25</td>
</tr>
<tr class="odd">
<td align="left">Sums</td>
<td align="left">27</td>
<td align="left">27</td>
<td align="left">0</td>
<td align="left">35.5</td>
</tr>
<tr class="even">
<td align="left">Means</td>
<td align="left">4.5</td>
<td align="left">4.5</td>
<td align="left">0</td>
<td align="left">5.91666666666667</td>
</tr>
</tbody>
</table>
<p>OK, now we have new column called <code>squared_deviations</code>. These are just the difference scores squared. So, <span class="math inline">\(-3.5^2 = 12.25\)</span>, etc. You can confirm for yourself with your cellphone calculator.</p>
<p>Now that all of the squared deviations are positive, we can add them up. When we do this create something very special called the sum of squares (SS), also known as the sum of the squared deviations from the mean. We will talk at length about this SS later on in the ANOVA chapter. So, when you get there, remember that you already know what it is, just some sums of some squared deviations, nothing fancy.</p>
</div>
<div id="finally-the-variance" class="section level4">
<h4><span class="header-section-number">2.5.3.4</span> Finally, the variance</h4>
<p>Guess what, we already computed the variance. It already happened, and maybe you didn’t notice. “Wait, I missed that, what happened?”.</p>
<p>First, see if you can remember what we are trying to do here. Trying pausing before reading to see you if can tell yourself what problem we are trying solve.</p>
<p>Without further ado, we are trying to get a summary of the differences in our data. There are just as many difference scores from the mean as there are data points, which can be a lot, so it would be nice to have a single number to look at, something like a mean, that would tell us about the average differences in the data.</p>
<p>If you look at the table, you can see already computed the mean of the squared deviations. First, we found the sum (SS), then below that we calculated the mean = 5.916 repeating. This is <strong>the variance</strong>. The variance is the mean of the sum of the squared deviations:</p>
<p><span class="math inline">\(variance = \frac{SS}{N}\)</span>, where SS is the sum of the squared deviations, and N is the number of observations.</p>
<p>OK, now what. What do I do with the variance? What does this number mean? Good question. The variance is often an unhelpful number to look at. Why? Because it is not in the same scale as the original data. This is because we squared the difference scores before taking the mean. Squaring produces large numbers. For example, we see a 12.25 in there. That’s a big difference, bigger than any difference between any two original values. What to do? How can we bring the numbers back down to their original unsquared size?</p>
<p>If you are thinking about taking the square root, that’s a ding ding ding, correct answer for you. We can always unsquare anything by taking the square root. So, let’s do that to 5.916. <span class="math inline">\(\sqrt{5.916} =\)</span> 2.4322829.</p>
</div>
</div>
<div id="the-standard-deviation" class="section level3">
<h3><span class="header-section-number">2.5.4</span> The Standard Deviation</h3>
<p>Oops, we did it again. We already computed the standard deviation, and we didn’t tell you. The standard deviation is the square root of the variance…At least, it is right now, until we complicate matters for you in the next chapter.</p>
<p>Here is the formula for the standard deviation:</p>
<p><span class="math inline">\(\text{standard deviation} = \sqrt{Variance} = \sqrt{\frac{SS}{N}}\)</span>.</p>
<p>We could also expand this to say:</p>
<p><span class="math inline">\(\text{standard deviation} = \sqrt{\frac{\sum_{i}^{n}({x_{i}-\bar{x})^2}}{N}}\)</span></p>
<p>Don’t let those big square root signs put you off. Now, you know what they are doing there. Just bringing our measure of the variance back down to the original size of the data. Let’s look at our table again:</p>
<table>
<thead>
<tr class="header">
<th align="left">scores</th>
<th align="left">values</th>
<th align="left">mean</th>
<th align="left">Difference_from_Mean</th>
<th align="left">Squared_Deviations</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left">1</td>
<td align="left">4.5</td>
<td align="left">-3.5</td>
<td align="left">12.25</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">6</td>
<td align="left">4.5</td>
<td align="left">1.5</td>
<td align="left">2.25</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="left">4</td>
<td align="left">4.5</td>
<td align="left">-0.5</td>
<td align="left">0.25</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="left">2</td>
<td align="left">4.5</td>
<td align="left">-2.5</td>
<td align="left">6.25</td>
</tr>
<tr class="odd">
<td align="left">5</td>
<td align="left">6</td>
<td align="left">4.5</td>
<td align="left">1.5</td>
<td align="left">2.25</td>
</tr>
<tr class="even">
<td align="left">6</td>
<td align="left">8</td>
<td align="left">4.5</td>
<td align="left">3.5</td>
<td align="left">12.25</td>
</tr>
<tr class="odd">
<td align="left">Sums</td>
<td align="left">27</td>
<td align="left">27</td>
<td align="left">0</td>
<td align="left">35.5</td>
</tr>
<tr class="even">
<td align="left">Means</td>
<td align="left">4.5</td>
<td align="left">4.5</td>
<td align="left">0</td>
<td align="left">5.91666666666667</td>
</tr>
</tbody>
</table>
<p>We measured the standard deviation as 2.4322829. Notice this number fits right in the with differences scores from the mean. All of the scores are kind of in and around + or - 2.4322829. Whereas, if we looked at the variance, 5.916 is just too big, it doesn’t summarize the actual differences very well.</p>
<p>What does all this mean? Well, if someone told they had some number with a mean of 4.5 (like the values in our table), and a standard deviation of 2.4322829, you would get a pretty good summary of the numbers. You would know that lots of the numbers are spread about 4.5, and are + or - 2.4322829 from 4.5. That’s a good start for describing numbers. If you had loads of numbers, you could reduce them down to the mean and the standard deviation, and still be pretty well off in terms of getting a sense of those numbers.</p>
</div>
</div>
<div id="using-descriptive-statistics-with-data" class="section level2">
<h2><span class="header-section-number">2.6</span> Using Descriptive Statistics with data</h2>
<p>Example here:</p>
</div>
<div id="rolling-your-own-descriptive-statistics" class="section level2">
<h2><span class="header-section-number">2.7</span> Rolling your own descriptive statistics</h2>
<p>We spent many paragraphs talking about variation in numbers, and how to use calculate the <strong>variance</strong> and <strong>standard deviation</strong> to summarize the average differences between numbers in a data set. The basic process was to 1) calculate some measure of the differences, then 2) average the differences to create a summary. We found that we couldn’t average the raw difference scores, because we would always get a zero. So, we squared the differences from the mean, then averaged the squared differences differences. Finally, we square rooted our measure to bring the summary back down to the scale of the original numbers.</p>
<p>Perhaps you haven’t heard, but there is more than one way to skin a cat, but we prefer to think of this in terms of petting cats, because some of us love cats. Jokes aside, perhaps you were also thinking that the problem of summing differences scores (so that they don’t equal zero), can be solved in more than one way. Can you think of a different way, besides squaring?</p>
<div id="absolute-deviations" class="section level3">
<h3><span class="header-section-number">2.7.1</span> Absolute deviations</h3>
<p>How about just taking the absolute value of the difference scores. Remember, the absolute value converts any number to a positive value. Check out the following table:</p>
<table>
<thead>
<tr class="header">
<th align="left">scores</th>
<th align="left">values</th>
<th align="left">mean</th>
<th align="left">Difference_from_Mean</th>
<th align="left">Absolute_Deviations</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left">1</td>
<td align="left">4.5</td>
<td align="left">-3.5</td>
<td align="left">3.5</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">6</td>
<td align="left">4.5</td>
<td align="left">1.5</td>
<td align="left">1.5</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="left">4</td>
<td align="left">4.5</td>
<td align="left">-0.5</td>
<td align="left">0.5</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="left">2</td>
<td align="left">4.5</td>
<td align="left">-2.5</td>
<td align="left">2.5</td>
</tr>
<tr class="odd">
<td align="left">5</td>
<td align="left">6</td>
<td align="left">4.5</td>
<td align="left">1.5</td>
<td align="left">1.5</td>
</tr>
<tr class="even">
<td align="left">6</td>
<td align="left">8</td>
<td align="left">4.5</td>
<td align="left">3.5</td>
<td align="left">3.5</td>
</tr>
<tr class="odd">
<td align="left">Sums</td>
<td align="left">27</td>
<td align="left">27</td>
<td align="left">0</td>
<td align="left">13</td>
</tr>
<tr class="even">
<td align="left">Means</td>
<td align="left">4.5</td>
<td align="left">4.5</td>
<td align="left">0</td>
<td align="left">2.16666666666667</td>
</tr>
</tbody>
</table>
<p>This works pretty well too. By converting the difference scores from the mean to positive values, we can now add them up and get a non-zero value (if there are differences). Then, we can find the mean of the sum of the absolute deviations. If we were to map the terms sum of squares (SS), variance and standard deviation onto these new measures based off of the absolute deviation, how would the mapping go? For example, what value in the table corresponds to the SS? That would be the sum of absolute deviations in the last column. How about the variance and standard deviation, what do those correspond to? Remember that the variance is mean (<span class="math inline">\(SS/N\)</span>), and the standard deviation is a square-rooted mean (<span class="math inline">\(\sqrt{SS/N}\)</span>). In the table above we only have one corresponding mean, the mean of the sum of the absolute deviations. So, we have a <strong>variance</strong> measure that does not need to be square rooted. We might say the mean absolute deviation, is doing double-duty as a variance and a standard-deviation. Neat.</p>
</div>
<div id="other-sign-inverting-operations" class="section level3">
<h3><span class="header-section-number">2.7.2</span> Other sign-inverting operations</h3>
<p>In principle, we could create lots of different summary statistics for variance that solve the summing to zero problem. For example, we could raise every difference score to any even numbered power beyond 2 (which is the square). We could use, 4, 6, 8, 10, etc. There is an infinity of even numbers, so there is an infinity of possible variance statistics. We could also use odd numbers as powers, and then take their absolute value. Many things are possible. The important aspect to any of this is to have a reason for what you are doing, and to choose a method that works for the data-analysis problem you are trying to solve. Note also, we bring up this general issue because we want you to understand that statistics is a creative exercise. We invent things when we need them, and we use things that have already been invented when they work for the problem at hand.</p>
<!--


## Examining numerical data {#numericalData}

This section introduces techniques for exploring and summarizing numerical variables, and the **email50** and **county** data sets from Section \@ref(dataBasics) provide rich opportunities for examples. Recall that outcomes of numerical variables are numbers on which it is reasonable to perform basic arithmetic operations. For example, the **pop20** variable, which represents the populations of counties in 2010, is numerical since we can sensibly discuss the difference or ratio of the populations in two counties. On the other hand, area codes and zip codes are not numerical.

### Scatterplots for paired data {#scatterPlots}

A provides a case-by-case view of data for two numerical variables. In Figure \@ref(fig:countyfedspendVsPoverty), a scatterplot was used to examine how federal spending and poverty were related in the data set. Another scatterplot is shown in Figure \@ref(fig:email50LinesCharacters), comparing the number of line breaks (**line_breaks**) and number of characters (**num_char**) in emails for the **email50** data set. In any scatterplot, each point represents a single case. Since there are 50 cases in **email50**, there are 50 points in Figure [email50LinesCharacters].

<div class="figure">
<img src="figures01/email50LinesCharacters/email50LinesCharacters.pdf" alt="A scatterplot of versus for thedata."  />
<p class="caption">(\#fig:email50LinesCharacters)A scatterplot of versus for thedata.</p>
</div>


To put the number of characters in perspective, this paragraph has 363 characters. Looking at Figure \@ref(email50LinesCharacters), it seems that some emails are incredibly long! Upon further investigation, we would actually find that most of the long emails use the HTML format, which means most of the characters in those emails are used to format the email rather than provide text.

<div class="marginnote">
Guided Practice 1.15

What do scatterplots reveal about the data, and how might they be
useful?[^21]
</div>

<div class="marginnote">
Guided Practice 1.17

Describe two variables that would have a horseshoe shaped association in
a scatterplot.[^23]
</div>


> **Example 1.16** Consider a new data set of 54 cars with two variables: vehicle price and weight.[^22] A scatterplot of vehicle price versus weight is shown in Figure \@ref(fig:carsPriceVsWeight). What can be said about the relationship between these variables?

<div class="figure">
<img src="figures01/carsPriceVsWeight/carsPriceVsWeight.pdf" alt="A scatterplot of versus for 54 cars."  />
<p class="caption">(\#fig:carsPriceVsWeight)A scatterplot of versus for 54 cars.</p>
</div>

> The relationship is evidently nonlinear, as highlighted by the dashed line. This is different from previous scatterplots we’ve seen, such as Figure \@ref(fig:countyfedspendVsPoverty) and Figure \@ref(fig:email50LinesCharacters), which show relationships that are very linear.


### Dot plots and the mean {#dotPlot}

Sometimes two variables is one too many: only one variable may be of interest. In these cases, a dot plot provides the most basic of displays. A **dot plot** is a one-variable scatterplot; an example using the number of characters from 50 emails is shown in Figure \@ref(fig:emailCharactersDotPlot). A stacked version of this dot plot is shown in Figure \@ref(fig:emailCharactersDotPlotStacked).

<div class="figure">
<img src="figures01/emailCharactersDotPlot/emailCharactersDotPlot.pdf" alt="A dot plot of for the data set."  />
<p class="caption">(\#fig:emailCharactersDotPlot)A dot plot of for the data set.</p>
</div>

<div class="figure">
<img src="figures01/emailCharactersDotPlot/emailCharactersDotPlotStacked.pdf" alt="A stacked dot plot of for the data set."  />
<p class="caption">(\#fig:emailCharactersDotPlotStacked)A stacked dot plot of for the data set.</p>
</div>

The **mean**, sometimes called the average, is a common way to measure the center of a **distribution** of data. To find the mean number of characters in the 50 emails (see Equation \@ref(eq:mean)), we add up all the character counts and divide by the number of emails. For computational convenience, the number of characters is listed in the thousands and rounded to the first decimal.

\begin{equation}
  \bar{x} = \frac{21.7 + 7.0 + \cdots + 15.8}{50} = 11.6
  (\#eq:mean)
\end{equation}

The sample mean is often labeled $\bar{x}$, and the letter $x$ is being used as a generic placeholder for the variable of interest, **num_char**. The sample mean is shown as a triangle in Figures \@ref(emailCharactersDotPlot) and \@ref(fig:emailCharactersDotPlotStacked).

___

> **Mean** 

The sample mean of a numerical variable is the sum of all of the observations divided by the number of observations:

\begin{equation}
  \bar{x} = \frac{x_1+x_2+\cdots+x_n}{n}
  (\#eq:meanb)
\end{equation}

where $x_1, x_2, \dots, x_n$ represent the $n$ observed values.

___

<div class="marginnote">
Guided Practice 1.20

Examine Equations \@ref(eq:mean) and \@ref(eq:meanb) above. What does $x_1$ correspond to? And $x_2$?
Can you infer a general meaning to what $x_i$ might represent?[^24]
</div>

<div class="marginnote">
Guided Practice 1.21

What was $n$ in this sample of emails?[^25]
</div>


The **email50** data set is a sample from a larger population of emails that were received in January and March. We could compute a mean for this population in the same way as the sample mean. However, there is a difference in notation: the population mean has a special label: $\mu$. The symbol $\mu$ is the Greek letter *mu* and represents the average of all observations in the population. Sometimes a subscript, such as $_x$, is used to represent which variable the population mean refers to, e.g. $\mu_x$.

___

> **Example 1.22** The average number of characters across all emails can be estimated using the sample data. Based on the sample of 50 emails, what would be a reasonable estimate of $\mu_x$, the mean number of characters in all emails in the **email** data set? (Recall that **email50** is a sample from **email**.)</span> 

>The sample mean, 11,600, may provide a reasonable estimate of $\mu_x$. While this number will not be perfect, it provides a **point estimate** of the population mean. In Chapter 2 and beyond, we will develop tools to characterize the accuracy of point estimates, and we will find that point estimates based on larger samples tend to be more accurate than those based on smaller samples.

___

> **Example 1.23** We might like to compute the average income per person in the US. To do so, we might first think to take the mean of the per capita incomes from the 3,143 counties in the data set. What would be a better approach? 

> The **county** data set is special in that each county actually represents many individual people. If we were to simply average across the variable, we would be treating counties with 5,000 and 5,000,000 residents equally in the calculations. Instead, we should compute the total income for each county, add up all the counties’ totals, and then divide by the number of people in all the counties. If we completed these steps with the data, we would find that the per capita income for the US is \$27,348.43. Had we computed the *simple* mean of per capita income across counties, the result would have been just \$22,504.70!

___

Example 1.23 used what is called a **weighted mean**, which will not be a key topic in this textbook. However, we have provided an online supplement on weighted means for interested readers: [http://www.openintro.org/stat/down/supp/wtdmean.pdf](http://www.openintro.org/stat/down/supp/wtdmean.pdf)

### Histograms and shape {#histogramsAndShape}

Dot plots show the exact value of each observation. This is useful for small data sets, but they can become hard to read with larger samples. Rather than showing the value of each observation, think of the value as belonging to a *bin*. For example, in the data set, we create a table of counts for the number of cases with character counts between 0 and 5,000, then the number of cases between 5,000 and 10,000, and so on. Observations that fall on the boundary of a bin (e.g. 5,000) are allocated to the lower bin. This tabulation is shown in Table\@ref(tab:binnedNumCharTable). These binned counts are plotted as bars in Figure \@ref(fig:email50NumCharHist) into what is called a , which resembles the stacked dot plot shown in Figure \@ref(fig:emailCharactersDotPlotStacked).

  ---------------- ----------------------- ------------------------ ------------------------- ------------------------- ------------------------- ------------------------- ---------------------------- ------------------------- ------------------------- --
  Characters                                                                                                                                                                                                                                                 
  (in thousands)    <span>0-5</span>   <span>5-10</span>   <span>10-15</span>   <span>15-20</span>   <span>20-25</span>   <span>25-30</span>   <span>$\cdots$</span>   <span>55-60</span>   <span>60-65</span>  
  Count                      19                       12                        6                         2                         3                         5                       $\cdots$                       0                         1             
  ---------------- ----------------------- ------------------------ ------------------------- ------------------------- ------------------------- ------------------------- ---------------------------- ------------------------- ------------------------- --

Table: (\#tab:binnedNumCharTable) The counts for the binned *num_char** data.

<div class="figure">
<img src="figures01/email50NumCharHist/email50NumCharHist.pdf" alt="A histogram of num_char. This distribution is very strongly skewed to the right."  />
<p class="caption">(\#fig:email50NumCharHist)A histogram of num_char. This distribution is very strongly skewed to the right.</p>
</div>

Histograms provide a view of the **data density**. Higher bars represent where the data are relatively more dense. For instance, there are many more emails between 0 and 10,000 characters than emails between 10,000 and 20,000 characters in the data set. The bars make it easy to see how the density of the data changes relative to the number of characters.

Histograms are especially convenient for describing the shape of the data distribution. Figure \@ref(fig:email50NumCharHist) shows that most emails have a relatively small number of characters, while fewer emails have a very large number of characters. When data trail off to the right in this way and have a longer right , the shape is said to be **right skewed**.[^26]

Data sets with the reverse characteristic – a long, thin tail to the left – are said to be **left skewed**. We also say that such a distribution has a long left tail. Data sets that show roughly equal trailing off in both directions are called .

> Tip: **Use Long tails identify skew** When data trail off in one direction, the distribution has a . If a distribution has a long left tail, it is left skewed. If a distribution has a long right tail, it is right skewed.


<div class="marginnote">
Guided Practice 1.24

Take a look at the dot plots in Figures \@ref(fig:emailCharactersDotPlot)
and <a href="#fig:emailCharactersDotPlotStacked"><strong>??</strong></a>. Can you see the skew in the data?
Is it easier to see the skew in this histogram or the dot plots?[^27]
</div>


<div class="marginnote">
Guided Practice 1.25

Besides the mean (since it was labeled), what can you see in the dot
plots that you cannot see in the histogram?[^28]
</div>


In addition to looking at whether a distribution is skewed or symmetric, histograms can be used to identify modes. A **mode** is represented by a prominent peak in the distribution.[^29] There is only one prominent peak in the histogram of **num_char**.

<div class="figure">
<img src="figures01/singleBiMultiModalPlots/singleBiMultiModalPlots.pdf" alt="Counting only prominent peaks, the distributions are (left to right) unimodal, bimodal, and multimodal."  />
<p class="caption">(\#fig:singleBiMultiModalPlots)Counting only prominent peaks, the distributions are (left to right) unimodal, bimodal, and multimodal.</p>
</div>

Figure \@ref(fig:singleBiMultiModalPlots) shows histograms that have one, two, or three prominent peaks. Such distributions are called **unimodal**, **bimodal**, and **multimodal**, respectively. Any distribution with more than 2 prominent peaks is called multimodal. Notice that there was one prominent peak in the unimodal distribution with a second less prominent peak that was not counted since it only differs from its neighboring bins by a few observations.

<div class="marginnote">
Guided Practice 1.26

Figure \@ref(fig:email50NumCharHist) reveals only one prominent mode in the
number of characters. Is the distribution unimodal, bimodal, or
multimodal?[^30]
</div>

<div class="marginnote">
Guided Practice 1.27

Height measurements of young students and adult teachers at a K-3
elementary school were taken. How many modes would you anticipate in
this height data set?[^31]
</div>



> Tip: **Looking for modes** isn’t about finding a clear and correct answer about the number of modes in a distribution, which is why *prominent* is not rigorously defined in this book. The important part of this examination is to better understand your data and how it might be structured.</span>

### Variance and standard deviation {#variability}

The mean is used to describe the center of a data set, but the in the data is also important. Here, we introduce two measures of variability: the variance and the standard deviation. Both of these are very useful in data analysis, even though the formulas are a bit tedious to calculate by hand. The standard deviation is the easier of the two to conceptually understand, and it roughly describes how far away the typical observation is from the mean.

We call the distance of an observation from its mean its *deviation*. Below are the deviations for the $1^{st}_{}$, $2^{nd}_{}$, $3^{rd}$, and $50^{th}_{}$ observations in the variable. For computational convenience, the number of characters is listed in the thousands and rounded to the first decimal.

$$\begin{aligned}
x_1^{}-\bar{x} &= 21.7 - 11.6 = 10.1 \hspace{5mm}\text{ } \\
x_2^{}-\bar{x} &= 7.0 - 11.6 = -4.6 \\
x_3^{}-\bar{x} &= 0.6 - 11.6 = -11.0 \\
            &\ \vdots \\
x_{50}^{}-\bar{x} &= 15.8 - 11.6 = 4.2\end{aligned}$$

If we square these deviations and then take an average, the result is about equal to the sample *variance*, denoted by $s_{}^2$:

$$\begin{aligned}
s_{}^2 &= \frac{10.1_{}^2 + (-4.6)_{}^2 + (-11.0)_{}^2 + \cdots + 4.2_{}^2}{50-1} \\
    &= \frac{102.01 + 21.16 + 121.00 + \cdots + 17.64}{49} \\
    &= 172.44\end{aligned}$$

We divide by $n-1$, rather than dividing by $n$, when computing the variance; you need not worry about this mathematical nuance for the material in this textbook. Notice that squaring the deviations does two things. First, it makes large values much larger, seen by comparing $10.1^2$, $(-4.6)^2$, $(-11.0)^2$, and $4.2^2$. Second, it gets rid of any negative signs.

The *standard deviation* is the square root of the variance: $$s=\sqrt{172.44} = 13.13$$ [

The standard deviation of the number of characters in an email is about 13.13 thousand. A subscript of $_x$ may be added to the variance and standard deviation, i.e. $s_x^2$ and $s_x^{}$, as a reminder that these are the variance and standard deviation of the observations represented by $x_1^{}$, $x_2^{}$, ..., $x_n^{}$. The $_{x}$ subscript is usually omitted when it is clear which data the variance or standard deviation is referencing.

> **Variance and Standard Deviation** The variance is roughly the average squared distance from the mean. The standard deviation is the square root of the variance and describes how close the data are to the mean.

Formulas and methods used to compute the variance and standard deviation for a population are similar to those used for a sample.[^32] However, like the mean, the population values have special symbols: $\sigma_{}^2$ for the variance and $\sigma$ for thge standard deviation. The symbol $\sigma$ is the Greek letter *sigma*.

<div class="figure">
<img src="figures01/sdAsRuleForEmailNumChar/sdAsRuleForEmailNumChar.pdf" alt="In the data, 41 of the 50 emails (82%) are within 1 standard deviation of the mean, and 47 of the 50 emails (94%) are within 2 standard deviations. Usually about 70% of the data are within 1 standard deviation of the mean and 95% are within 2 standard deviations, though this rule of thumb is less accurate for skewed data, as shown in this example."  />
<p class="caption">(\#fig:sdAsRuleForEmailNumChar)In the data, 41 of the 50 emails (82%) are within 1 standard deviation of the mean, and 47 of the 50 emails (94%) are within 2 standard deviations. Usually about 70% of the data are within 1 standard deviation of the mean and 95% are within 2 standard deviations, though this rule of thumb is less accurate for skewed data, as shown in this example.</p>
</div>

> Tip: **Standard Deviation describes variability** Focus on the conceptual meaning of the standard deviation as a descriptor of variability rather than the formulas. Usually 70% of the data will be within one standard deviation of the mean and about 95% will be within two standard deviations. However, as seen in Figures \@ref(fig:sdAsRuleForEmailNumChar) and \@ref(fig:severalDiffDistWithSdOf1), these percentages are not strict rules.

<div class="figure">
<img src="figures01/severalDiffDistWithSdOf1/severalDiffDistWithSdOf1.pdf" alt="Three very different population distributions with the same mean and standard deviation."  />
<p class="caption">(\#fig:severalDiffDistWithSdOf1)Three very different population distributions with the same mean and standard deviation.</p>
</div>

<div class="marginnote">
Guided Practice 1.28

A good description of the shape of a distribution should include modality and whether the distribution is symmetric or skewed to one side. Using Figure \@ref(fig:severalDiffDistWithSdOf1) as an example, explain why such a description is important.[^33]
</div>

> **Example 1.29** Describe the distribution of the variable using the histogram in Figure \@ref(fig:email50NumCharHist). The description should incorporate the center, variability, and shape of the distribution, and it should also be placed in context: the number of characters in emails. Also note any especially unusual cases.

> The distribution of email character counts is unimodal and very strongly skewed to the high end. Many of the counts fall near the mean at 11,600, and most fall within one standard deviation (13,130) of the mean. There is one exceptionally long email with about 65,000 characters.

In practice, the variance and standard deviation are sometimes used as a means to an end, where the  "end" is being able to accurately estimate the uncertainty associated with a sample statistic. For example, in Chapter 2 we will use the variance and standard deviation to assess how close the sample mean is to the population mean.

### Box plots, quartiles, and the median

A *box plot* summarizes a data set using five statistics while also plotting unusual observations. Figure \@ref(fig:boxPlotLayoutNumVar) provides a vertical dot plot alongside a box plot of the variable from the data set.

<div class="figure">
<img src="figures01/boxPlotLayoutNumVar/boxPlotLayoutNumVar.pdf" alt="A vertical dot plot next to a labeled box plot for the number of characters in 50 emails. The median (6,890), splits the data into the bottom 50% and the top 50%, marked in the dot plot by horizontal dashes and open circles, respectively."  />
<p class="caption">(\#fig:boxPlotLayoutNumVar)A vertical dot plot next to a labeled box plot for the number of characters in 50 emails. The median (6,890), splits the data into the bottom 50% and the top 50%, marked in the dot plot by horizontal dashes and open circles, respectively.</p>
</div>


The first step in building a box plot is drawing a dark line denoting the *median*, which splits the data in half. Figure \@ref(fig:boxPlotLayoutNumVar) shows 50% of the data falling below the median (dashes) and other 50% falling above the median (open circles). There are 50 character counts in the data set (an even number) so the data are perfectly split into two groups of 25. We take the median in this case to be the average of the two observations closest to the $50^{th}$ percentile: $(\text{6,768} + \text{7,012}) / 2 = \text{6,890}$. When there are an odd number of observations, there will be exactly one observation that splits the data into two halves, and in this case that observation is the median (no average needed).

> **Median: the number in the middle** If the data are ordered from smallest to largest, the *median* is the observation right in the middle. If there are an even number of observations, there will be two values in the middle, and the median is taken as their average.

The second step in building a box plot is drawing a rectangle to represent the middle 50% of the data. The total length of the box, shown vertically in Figure \@ref(fig:boxPlotLayoutNumVar, is called the *interquartile range* (, for short). It, like the standard deviation, is a measure of in data. The more variable the data, the larger the standard deviation and IQR. The two boundaries of the box are called the *first quartile* (the $25^{th}$ , i.e. 25% of the data fall below this value) and the *third quartile* (the $75^{th}$ percentile), and these are often labeled $Q_1$ and $Q_3$, respectively.

___

> **Interquartile range (IQR)** The IQR is the length of the box in a box plot. It is computed as

$$\begin{aligned}
IQR = Q_3 - Q_1\end{aligned}$$

where $Q_1$ and $Q_3$ are the $25^{th}$ and $75^{th}$ percentiles.

___

<div class="marginnote">
Guided Practice 1.30

What percent of the data fall between $Q_1$ and the median? What percent is between the median and $Q_3$?[^34]
</div>

Extending out from the box, the *whiskers* attempt to capture the data outside of the box, however, their reach is never allowed to be more than $1.5\times IQR$.[^35] They capture everything within this reach. In Figure [boxPlotLayoutNumVar], the upper whisker does not extend to the last three points, which are beyond $Q_3 + 1.5\times IQR$, and so it extends only to the last point below this limit. The lower whisker stops at the lowest value, 33, since there is no additional data to reach; the lower whisker’s limit is not shown in the figure because the plot does not extend down to $Q_1 - 1.5\times IQR$. In a sense, the box is like the body of the box plot and the whiskers are like its arms trying to reach the rest of the data.

Any observation that lies beyond the whiskers is labeled with a dot. The purpose of labeling these points – instead of just extending the whiskers to the minimum and maximum observed values – is to help identify any observations that appear to be unusually distant from the rest of the data. Unusually distant observations are called . In this case, it would be reasonable to classify the emails with character counts of 41,623, 42,793, and 64,401 as outliers since they are numerically distant from most of the data.

> **Outliers are extreme.** An *outlier* is an observation that is extreme relative to the rest of the data.

> **Tip: Why it is important to look for outliers.** Examination of data for possible outliers serves many useful purposes, including:

1.  Identifying in the distribution.

2.  Identifying data collection or entry errors. For instance, we re-examined the email purported to have 64,401 characters to ensure this value was accurate.

3.  Providing insight into interesting properties of the data.

___

<div class="marginnote">
Guided Practice 1.31

The observation 64,401, an outlier, was found to be an accurate observation. What would such an observation suggest about the nature of character counts in emails?[^36]
</div>

<div class="marginnote">
Guided Practice 1.32

Using Figure \@ref(fig:boxPlotLayoutNumVar), estimate the following values for in the data set: (a) $Q_1$, (b) $Q_3$, and (c) IQR.[^37]
</div>


### Robust statistics

How are the sample statistics of the **num_char** data set affected by the observation, 64,401? What would have happened if this email wasn’t observed? What would happen to these summary statistics if the observation at 64,401 had been even larger, say 150,000? These scenarios are plotted alongside the original data in Figure \@ref(fig:email50NumCharDotPlotRobustEx), and sample statistics are computed under each scenario in Table \@ref(tab:robustOrNotTable).

<div class="figure">
<img src="figures01/email50NumCharDotPlotRobustEx/email50NumCharDotPlotRobustEx.pdf" alt="Dot plots of the original character count data and two modified data sets."  />
<p class="caption">(\#fig:email50NumCharDotPlotRobustEx)Dot plots of the original character count data and two modified data sets.</p>
</div>

<span>l c cc c cc</span> &

& &

&\
scenario && median & IQR && $\bar{x}$ & $s$\
original data && 6,890 & 12,875 && 11,600 & 13,130\
drop 66,924 observation && 6,768 & 11,702 && 10,521 & 10,798\
move 66,924 to 150,000 && 6,890 & 12,875 && 13,310 & 22,434\

[robustOrNotTable]


<div class="marginnote">
Guided Practice 1.33

Which is more affected by extreme observations, the mean or median? Table \@ref(tab:robustOrNotTable) may be helpful. Is the standard deviation or IQR more affected by extreme observations?[^38]
</div>

The median and IQR are called *robust estimates* because extreme observations have little effect on their values. The mean and standard deviation are much more affected by changes in extreme observations.

> **Example 1.34** The median and IQR do not change much under the three scenarios in Table \@ref(tab:robustOrNotTable). Why might this be the case?
> The median and IQR are only sensitive to numbers near $Q_1$, the median, and $Q_3$. Since values in these regions are relatively stable – there aren’t large jumps between observations – the median and IQR estimates are also quite stable.

<div class="marginnote">
Guided Practice 1.34

The distribution of vehicle prices tends to be right skewed, with a few luxury and sports cars lingering out into the right tail. If you were searching for a new car and cared about price, should you be more interested in the mean or median price of vehicles sold, assuming you are in the market for a regular car?[^39]
</div>


### Transforming data (special topic) {#transformingDataSubsection}

When data are very strongly skewed, we sometimes transform them so they are easier to model. Consider the histogram of salaries for Major League Baseball players’ salaries from 2010, which is shown in Figure \@ref(fig:histMLBSalariesReg).

<div class="figure">
<img src="figures01/histMLBSalaries/histMLBSalariesReg.pdf" alt="Histogram of MLB player salaries for 2010, in millions of dollars."  />
<p class="caption">(\#fig:histMLBSalariesReg)Histogram of MLB player salaries for 2010, in millions of dollars.</p>
</div>

<div class="figure">
<img src="figures01/histMLBSalaries/histMLBSalariesLog.pdf" alt="Histogram of the log-transformed MLB player salaries for 2010."  />
<p class="caption">(\#fig:histMLBSalariesLog)Histogram of the log-transformed MLB player salaries for 2010.</p>
</div>


> **Example 1.36** The histogram of MLB player salaries is useful in that we can see the data are extremely skewed and centered (as gauged by the median) at about \$1 million. What isn’t useful about this plot?

> Most of the data are collected into one bin in the histogram and the data are so strongly skewed that many details in the data are obscured.

There are some standard transformations that are often applied when much of the data cluster near zero (relative to the larger values in the data set) and all observations are positive. A *transformation* is a rescaling of the data using a function. For instance, a plot of the natural logarithm[^40] of player salaries results in a new histogram in Figure \@ref(fig:histMLBSalariesLog). Transformed data are sometimes easier to work with when applying statistical models because the transformed data are much less skewed and outliers are usually less extreme.

Transformations can also be applied to one or both variables in a scatterplot. A scatterplot of the and variables is shown in Figure \@ref(fig:email50LinesCharactersMod), which was earlier shown in Figure \@ref(fig:email50LinesCharacters). We can see a positive association between the variables and that many observations are clustered near zero. In Chapter 5], we might want to use a straight line to model the data. However, we’ll find that the data in their current state cannot be modeled very well. Figure \@ref(fig:email50LinesCharactersModLog) shows a scatterplot where both the and variables have been transformed using a log (base $e$) transformation. While there is a positive association in each plot, the transformed data show a steadier trend, which is easier to model than the untransformed data.

<div class="figure">
<img src="figures01/email50LinesCharactersMod/email50LinesCharactersMod.pdf" alt="Scatterplot of line breaks against num char for 50 emails."  />
<p class="caption">(\#fig:email50LinesCharactersMod)Scatterplot of line breaks against num char for 50 emails.</p>
</div>

<div class="figure">
<img src="figures01/email50LinesCharactersMod/email50LinesCharactersModLog.pdf" alt="A scatterplot of the same data but where each variable has been log- transformed."  />
<p class="caption">(\#fig:email50LinesCharactersModLog)A scatterplot of the same data but where each variable has been log- transformed.</p>
</div>

Transformations other than the logarithm can be useful, too. For instance, the square root ($\sqrt{\text{original observation}}$) and inverse ($\frac{1}{\text{original observation}}$) are used by statisticians. Common goals in transforming data are to see the data structure differently, reduce skew, assist in modeling, or straighten a nonlinear relationship in a scatterplot.

### Mapping data (special topic)

The data set offers many numerical variables that we could plot using dot plots, scatterplots, or box plots, but these miss the true nature of the data. Rather, when we encounter geographic data, we should map it using an *intensity map*, where colors are used to show higher and lower values of a variable. Figures \@ref(fig:countyIntensityMaps1) and \@ref(fig:countyIntensityMaps2) shows intensity maps for federal spending per capita (fed_spend), poverty rate in percent (poverty), homeownership rate in percent (homeownership), and median household income (med_income). The color key indicates which colors correspond to which values. Note that the intensity maps are not generally very helpful for getting precise values in any given county, but they are very helpful for seeing geographic trends and generating interesting research questions.

<div class="figure">
<img src="figures01/countyIntensityMaps/countyFedSpendMap.pdf" alt="Map of federal spending (dollars per capita)."  />
<p class="caption">(\#fig:countyIntensityMaps1)Map of federal spending (dollars per capita).</p>
</div>

<div class="figure">
<img src="figures01/countyIntensityMaps/countyPovertyMap.pdf" alt="Intensity map of poverty rate"  />
<p class="caption">(\#fig:countyIntensityMaps2)Intensity map of poverty rate</p>
</div>

<div class="figure">
<img src="figures01/countyIntensityMaps/countyHomeownershipMap.pdf" alt="Intensity map of homeownership rate (percent)"  />
<p class="caption">(\#fig:countyHomeownershipMap)Intensity map of homeownership rate (percent)</p>
</div>

<div class="figure">
<img src="figures01/countyIntensityMaps/countyMedIncomeMap.pdf" alt="Intensity map of median household income ($1000s)."  />
<p class="caption">(\#fig:countyMedIncomeMap)Intensity map of median household income ($1000s).</p>
</div>

<div class="marginnote">
Guided Practice 1.38

What interesting features are evident in the intensity map?[^41]
</div>

> **Example 1.37** What interesting features are evident in the fed_spend and poverty intensity maps?

> The federal spending intensity map shows substantial spending in the Dakotas and along the central-to-western part of the Canadian border, which may be related to the oil boom in this region. There are several other patches of federal spending, such as a vertical strip in eastern Utah and Arizona and the area where Colorado, Nebraska, and Kansas meet. There are also seemingly random counties with very high federal spending relative to their neighbors. If we did not cap the federal spending range at \$18 per capita, we would actually find that some counties have extremely high federal spending while there is almost no federal spending in the neighboring counties. These high-spending counties might contain military bases, companies with large government contracts, or other government facilities with many employees. Poverty rates are evidently higher in a few locations. Notably, the deep south shows higher poverty rates, as does the southwest border of Texas. The vertical strip of eastern Utah and Arizona, noted above for its higher federal spending, also appears to have higher rates of poverty (though generally little correspondence is seen between the two variables). High poverty rates are evident in the Mississippi flood plains a little north of New Orleans and also in a large section of Kentucky and West Virginia.




## Considering categorical data {#categoricalData}

Like numerical data, categorical data can also be organized and analyzed. This section introduces tables and other basic tools for categorical data that are used throughout this book. The **email50** data set represents a sample from a larger email data set called . This larger data set contains information on 3,921 emails. In this section we will examine whether the presence of numbers, small or large, in an email provides any useful value in classifying email as spam or not spam.

### Contingency tables and bar plots

Table \@ref(tab:emailSpamNumberTableTotals) summarizes two variables: **spam** and **number**. Recall that is a categorical variable that describes whether an email contains no numbers, only small numbers (values under 1 million), or at least one big number (a value of 1 million or more). A table that summarizes data for two categorical variables in this way is called a *contingency table*. Each value in the table represents the number of times a particular combination of variable outcomes occurred. For example, the value 149 corresponds to the number of emails in the data set that are spam *and* had no number listed in the email. Row and column totals are also included. The *row totals* provide the total counts across each row (e.g. $149 + 168 + 50 = 367$), and *column totals* are total counts down each column.

A table for a single variable is called a *frequency table*. Table \@ref(tab:emailNumberTable) is a frequency table for the variable. If we replaced the counts with percentages or proportions, the table would be called a *relative frequency table*.

<span>ll ccc rr</span> & & &\
 & & none & small & big & Total &

 \
 & spam & 149 & 168 & 50 & 367\
[0pt] & not spam & 400 & 2659 & 495 & 3554\
 & Total & 549 & 2827 & 545 & 3921\

[emailSpamNumberTableTotals]

  ------ ------- ----- -------
   none   small   big   Total
   549    2827    545   3921
  ------ ------- ----- -------

  : A frequency table for the variable.

[emailNumberTable]

A bar plot is a common way to display a single categorical variable. The left panel of Figure \@ref(fig:emailNumberBarPlot) shows a *bar plot* for the variable. In the right panel, the counts are converted into proportions (e.g. $549/3921=0.140$ for ).

<div class="figure">
<img src="figures01/emailNumberBarPlot/emailNumberBarPlot.pdf" alt="Two bar plots of *number*. The left panel shows the counts, and the right panel shows the proportions in each group."  />
<p class="caption">(\#fig:emailNumberBarPlot)Two bar plots of *number*. The left panel shows the counts, and the right panel shows the proportions in each group.</p>
</div>

### Row and column proportions

Table \@ref(tab:rowPropSpamNumber) shows the row proportions for Table \@ref(tab:emailSpamNumberTableTotals). The are computed as the counts divided by their row totals. The value 149 at the intersection of and is replaced by $149/367=0.406$, i.e. 149 divided by its row total, 367. So what does 0.406 represent? It corresponds to the proportion of spam emails in the sample that do not have any numbers.

                             none                 small                  big   Total
  ---------- -------------------- --------------------- -------------------- -------
  spam          $149/367 = 0.406$     $168/367 = 0.458$     $50/367 = 0.136$   1.000
  not spam     $400/3554 = 0.113$   $2657/3554 = 0.748$   $495/3554 = 0.139$   1.000
  Total        $549/3921 = 0.140$   $2827/3921 = 0.721$   $545/3921 = 0.139$   1.000

  : A contingency table with row proportions for the and variables.

[rowPropSpamNumber]

A contingency table of the column proportions is computed in a similar way, where each is computed as the count divided by the corresponding column total. Table \@ref(tab:colPropSpamNumber) shows such a table, and here the value 0.271 indicates that 27.1% of emails with no numbers were spam. This rate of spam is much higher than emails with only small numbers (5.9%) or big numbers (9.2%). Because these spam rates vary between the three levels of **number** (none, small ,big ), this provides evidence that the and variables are associated.

                            none                 small                 big                 Total
  ---------- ------------------- --------------------- ------------------- ---------------------
  spam         $149/549 = 0.271$    $168/2827 = 0.059$    $50/545 = 0.092$    $367/3921 = 0.094$
  not spam     $400/549 = 0.729$   $2659/2827 = 0.941$   $495/545 = 0.908$   $3684/3921 = 0.906$
  Total                    1.000                 1.000               1.000                 1.000

  : A contingency table with column proportions for the spam and number variables.

[colPropSpamNumber]

We could also have checked for an association between **spam** and **number** in Table \@ref(tab:rowPropSpamNumber) using row proportions. When comparing these row proportions, we would look down columns to see if the fraction of emails with no numbers, small numbers, and big numbers varied from to .

<div class="marginnote">
Guided Practice 1.39

What does 0.458 represent in Table \@ref(tab:rowPropSpamNumber)? What does 0.059 represent in Table \@ref(tab:colPropSpamNumber)?[^42]
</div>

<div class="marginnote">
Guided Practice 1.40

What does 0.139 at the intersection of and represent in Table \@ref(tab:rowPropSpamNumber)? What does 0.908 represent in the Table \@ref(tab:colPropSpamNumber)?[^43]
</div>


> **Example 1.41** Data scientists use statistics to filter spam from incoming email messages. By noting specific characteristics of an email, a data scientist may be able to classify some emails as spam or not spam with high accuracy. One of those characteristics is whether the email contains no numbers, small numbers, or big numbers. Another characteristic is whether or not an email has any HTML content. A contingency table for the and variables from the data set are shown in Table \@ref(tab:emailSpamHTMLTableTotals). Recall that an HTML email is an email with the capacity for special formatting, e.g. bold text. In Table \@ref(tab:emailSpamHTMLTableTotals), which would be more helpful to someone hoping to classify email as spam or regular email: row or column proportions?

>Such a person would be interested in how the proportion of spam changes within each email format. This corresponds to column proportions: the proportion of spam in plain text emails and the proportion of spam in HTML emails. If we generate the column proportions, we can see that a higher fraction of plain text emails are spam ($209/1195 = 17.5\%$) than compared to HTML emails ($158/2726 = 5.8\%$). This information on its own is insufficient to classify an email as spam or not spam, as over 80% of plain text emails are not spam. Yet, when we carefully combine this information with many other characteristics, such as and other variables, we stand a reasonable chance of being able to classify some email as spam or not spam.

              text   HTML    Total
  ---------- ------ ------ -------
  spam        209    158       367
  not spam    986    2568     3554
  Total       1195   2726     3921

  : A contingency table for and .

[emailSpamHTMLTableTotals]

The example points out that row and column proportions are not equivalent. Before settling on one form for a table, it is important to consider each to ensure that the most useful table is constructed.

<div class="marginnote">
Guided Practice 1.27

Look back to Tables \@ref(tab:rowPropSpamNumber) and \@ref(tab:colPropSpamNumber). Which would be more useful to someone hoping to identify spam emails using the variable?[^44]
</div>


### Segmented bar and mosaic plots {#segmentedBarPlotsAndIndependence}

Contingency tables using row or column proportions are especially useful for examining how two categorical variables are related. Segmented bar and mosaic plots provide a way to visualize the information in these tables.

A **segmented bar plot** is a graphical display of contingency table information. For example, a segmented bar plot representing Table \@ref(tab:colPropSpamNumber) is shown in Figure \@ref(fig:emailSpamNumberSegBar), where we have first created a bar plot using the **number** variable and then separated each group by the levels of **spam**. The column proportions of Table \@ref(tab:colPropSpamNumber) have been translated into a standardized segmented bar plot in Figure \@ref(fig:emailSpamNumberSegBarSta), which is a helpful visualization of the fraction of spam emails in each level of **number**.

<div class="figure">
<img src="figures01/emailSpamNumberSegBar/emailSpamNumberSegBar.pdf" alt="Segmented bar plot for numbers found in emails, where the counts have been further broken down by spam"  />
<p class="caption">(\#fig:emailSpamNumberSegBar)Segmented bar plot for numbers found in emails, where the counts have been further broken down by spam</p>
</div>

<div class="figure">
<img src="figures01/emailSpamNumberSegBar/emailSpamNumberSegBarSta.pdf" alt="Standardized version."  />
<p class="caption">(\#fig:emailSpamNumberSegBarSta)Standardized version.</p>
</div>


> **Example 1.43** Examine both of the segmented bar plots. Which is more useful?

> Figure \@ref(fig:emailSpamNumberSegBar) contains more information, but Figure \@ref(fig:emailSpamNumberSegBarSta) presents the information more clearly. This second plot makes it clear that emails with no number have a relatively high rate of spam email – about 27%! On the other hand, less than 10% of email with small or big numbers are spam.

Since the proportion of spam changes across the groups in Figure [emailSpamNumberSegBarSta], we can conclude the variables are dependent, which is something we were also able to discern using table proportions. Because both the and groups have relatively few observations compared to the group, the association is more difficult to see in Figure [emailSpamNumberSegBar].

In some other cases, a segmented bar plot that is not standardized will be more useful in communicating important information. Before settling on a particular segmented bar plot, create standardized and non-standardized forms and decide which is more effective at communicating features of the data.

[emailSpamNumberMosaicPlot]

A *mosaic plot* is a graphical display of contingency table information that is similar to a bar plot for one variable or a segmented bar plot when using two variables. Figure [emailNumberMosaic] shows a mosaic plot for the variable. Each column represents a level of , and the column widths correspond to the proportion of emails of each number type. For instance, there are fewer emails with no numbers than emails with only small numbers, so the no number email column is slimmer. In general, mosaic plots use box *areas* to represent the number of observations.

<div class="figure">
<img src="figures01/emailSpamNumberMosaicPlot/emailSpamNumberMosaicRev.pdf" alt="Mosaic plot where emails are grouped by the variable after they’ve been divided into and ."  />
<p class="caption">(\#fig:emailSpamNumberMosaicRev)Mosaic plot where emails are grouped by the variable after they’ve been divided into and .</p>
</div>


This one-variable mosaic plot is further divided into pieces in Figure [emailSpamNumberMosaic] using the variable. Each column is split proportionally according to the fraction of emails that were spam in each number category. For example, the second column, representing emails with only small numbers, was divided into emails that were spam (lower) and not spam (upper). As another example, the bottom of the third column represents spam emails that had big numbers, and the upper part of the third column represents regular emails that had big numbers. We can again use this plot to see that the and variables are associated since some columns are divided in different vertical locations than others, which was the same technique used for checking an association in the standardized version of the segmented bar plot.

In a similar way, a mosaic plot representing row proportions of Table [emailSpamNumberTableTotals] could be constructed, as shown in Figure [emailSpamNumberMosaicRev]. However, because it is more insightful for this application to consider the fraction of spam in each category of the variable, we prefer Figure [emailSpamNumberMosaic].

### The only pie chart you will see in this book

While pie charts are well known, they are not typically as useful as other charts in a data analysis. A *pie chart* is shown in Figure  alongside a bar plot. It is generally more difficult to compare group sizes in a pie chart than in a bar plot, especially when categories have nearly identical counts or proportions. In the case of the and categories, the difference is so slight you may be unable to distinguish any difference in group sizes for either plot!

<div class="figure">
<img src="figures01/emailNumberPieChart/emailNumberPieChart.pdf" alt="A pie chart and bar plot of for the data set."  />
<p class="caption">(\#fig:emailNumberPieChart)A pie chart and bar plot of for the data set.</p>
</div>


### Comparing numerical data across groups {#comparingAcrossGroups}

Some of the more interesting investigations can be considered by examining numerical data across groups. The methods required here aren’t really new. All that is required is to make a numerical plot for each group. Here two convenient methods are introduced: side-by-side box plots and hollow histograms.

We will take a look again at the data set and compare the median household income for counties that gained population from 2000 to 2010 versus counties that had no gain. While we might like to make a causal connection here, remember that these are observational data and so such an interpretation would be unjustified.

There were 2,041 counties where the population increased from 2000 to 2010, and there were 1,099 counties with no gain (all but one were a loss). A random sample of 100 counties from the first group and 50 from the second group are shown in Table [countyIncomeSplitByPopGainTable] to give a better sense of some of the raw data.

<span> ccc ccc c ccc </span> &&\
 41.2 & 33.1 & 30.4 & 37.3 & 79.1 & 34.5 &

 & 40.3 & 33.5 & 34.8\
22.9 & 39.9 & 31.4 & 45.1 & 50.6 & 59.4 && 29.5 & 31.8 & 41.3\
47.9 & 36.4 & 42.2 & 43.2 & 31.8 & 36.9 && 28 & 39.1 & 42.8\
50.1 & 27.3 & 37.5 & 53.5 & 26.1 & 57.2 && 38.1 & 39.5 & 22.3\
57.4 & 42.6 & 40.6 & 48.8 & 28.1 & 29.4 && 43.3 & 37.5 & 47.1\
43.8 & 26 & 33.8 & 35.7 & 38.5 & 42.3 && 43.7 & 36.7 & 36\
41.3 & 40.5 & 68.3 & 31 & 46.7 & 30.5 && 35.8 & 38.7 & 39.8\
68.3 & 48.3 & 38.7 & 62 & 37.6 & 32.2 && 46 & 42.3 & 48.2\
42.6 & 53.6 & 50.7 & 35.1 & 30.6 & 56.8 && 38.6 & 31.9 & 31.1\
66.4 & 41.4 & 34.3 & 38.9 & 37.3 & 41.7 && 37.6 & 29.3 & 30.1\
51.9 & 83.3 & 46.3 & 48.4 & 40.8 & 42.6 && 57.5 & 32.6 & 31.1\
44.5 & 34 & 48.7 & 45.2 & 34.7 & 32.2 && 46.2 & 26.5 & 40.1\
39.4 & 38.6 & 40 & 57.3 & 45.2 & 33.1 && 38.4 & 46.7 & 25.9\
43.8 & 71.7 & 45.1 & 32.2 & 63.3 & 54.7 && 36.4 & 41.5 & 45.7\
71.3 & 36.3 & 36.4 & 41 & 37 & 66.7 && 39.7 & 37 & 37.7\
50.2 & 45.8 & 45.7 & 60.2 & 53.1 & && 21.4 & 29.3 & 50.1\
35.8 & 40.4 & 51.5 & 66.4 & 36.1 & && 43.6 & 39.8 &\

[countyIncomeSplitByPopGainTable]

The *side-by-side box plot* is a traditional tool for comparing across groups. An example is shown in the left panel of Figure [countyIncomeSplitByPopGain], where there are two box plots, one for each group, placed into one plotting window and drawn on the same scale.

<div class="figure">
<img src="figures01/countyIncomeSplitByPopGain/countyIncomeSplitByPopGain.pdf" alt="A pie chart and bar plot of for the data set."  />
<p class="caption">(\#fig:countyIncomeSplitByPopGain)A pie chart and bar plot of for the data set.</p>
</div>


Another useful plotting method uses to compare numerical data across groups. These are just the outlines of histograms of each group put on the same plot, as shown in the right panel of Figure [countyIncomeSplitByPopGain].

<div class="marginnote">
Guided Practice 1.27

Use the plots in the Figure to compare the incomes for counties across the two groups. What do you notice about the approximate center of each group? What do you notice about the variability between groups? Is the shape relatively consistent between groups? How many *prominent* modes are there for each group?[^45]
</div>

<div class="marginnote">
Guided Practice 1.27

What components of each plot in the Figure do you find most useful?[^46]
</div>


[^21]: Answers may vary. Scatterplots are helpful in quickly spotting associations between variables, whether those associations represent simple or more complex relationships.

[^22]: Subset of data from

[^23]: Consider the case where your vertical axis represents something  "good " and your horizontal axis represents something that is only good in moderation. Health and water consumption fit this description since water becomes toxic when consumed in excessive quantities.

[^24]: $x_1$ corresponds to the number of characters in the first email in the sample (21.7, in thousands), $x_2$ to the number of characters in the second email (7.0, in thousands), and $x_i$ corresponds to the number of characters in the $i^{th}$ email in the data set.

[^25]: The sample size was $n=50$.

[^26]: Other ways to describe data that are skewed to the right: , , or .

[^27]: The skew is visible in all three plots, though the flat dot plot is the least useful. The stacked dot plot and histogram are helpful visualizations for identifying skew.

[^28]: Character counts for individual emails.

[^29]: Another definition of mode, which is not typically used in statistics, is the value with the most occurrences. It is common to have *no* observations with the same value in a data set, which makes this other definition useless for many real data sets.

[^30]: Unimodal. Remember that *uni* stands for 1 (think *uni*cycles). Similarly, *bi* stands for 2 (think *bi*cycles). (We’re hoping a *multicycle* will be invented to complete this analogy.)

[^31]: There might be two height groups visible in the data set: one of the students and one of the adults. That is, the data are probably bimodal.

[^32]: The only difference is that the population variance has a division by $n$ instead of $n-1$.

[^33]: Figure [severalDiffDistWithSdOf1] shows three distributions that look quite different, but all have the same mean, variance, and standard deviation. Using modality, we can distinguish between the first plot (bimodal) and the last two (unimodal). Using skewness, we can distinguish between the last plot (right skewed) and the first two. While a picture, like a histogram, tells a more complete story, we can use modality and shape (symmetry/skew) to characterize basic information about a distribution.

[^34]: Since $Q_1$ and $Q_3$ capture the middle 50% of the data and the median splits the data in the middle, 25% of the data fall between $Q_1$ and the median, and another 25% falls between the median and $Q_3$.

[^35]: While the choice of exactly 1.5 is arbitrary, it is the most commonly used value for box plots.

[^36]: That occasionally there may be very long emails.

[^37]: These visual estimates will vary a little from one person to the next: $Q_1\approx$ 3,000, $Q_3\approx$ 15,000, $\text{IQR}=Q_3 - Q_1 \approx $ 12,000. (The true values: $Q_1=$ 2,536, $Q_3=$ 15,411, $\text{IQR} = $ 12,875.)

[^38]: \(a) Mean is affected more. (b) Standard deviation is affected more. Complete explanations are provided in the material following Guided Practice [numCharWhichIsMoreRobust].

[^39]: Buyers of a  "regular car " should be concerned about the median price. High-end car sales can drastically inflate the mean price while the median will be more robust to the influence of those sales.

[^40]: Statisticians often write the natural logarithm as $\log$. You might be more familiar with it being written as $\ln$.

[^41]: Note: answers will vary. There is a very strong correspondence between high earning and metropolitan areas. You might look for large cities you are familiar with and try to spot them on the map as dark spots.

[^42]: 0.458 represents the proportion of spam emails that had a small number. 0.058 represents the fraction of emails with small numbers that are spam.

[^43]: 0.139 represents the fraction of non-spam email that had a big number. 0.908 represents the fraction of emails with big numbers that are non-spam emails.

[^44]: The column proportions in Table [colPropSpamNumber] will probably be most useful, which makes it easier to see that emails with small numbers are spam about 5.9% of the time (relatively rare). We would also see that about 27.1% of emails with no numbers are spam, and 9.2% of emails with big numbers are spam.

[^45]: Answers may vary a little. The counties with population gains tend to have higher income (median of about \$45,000) versus counties without a gain (median of about \$40,000). The variability is also slightly larger for the population gain group. This is evident in the IQR, which is about 50% bigger in the *gain* group. Both distributions show slight to moderate right skew and are unimodal. There is a secondary small bump at about \$60,000 for the *no gain* group, visible in the hollow histogram plot, that seems out of place. (Looking into the data set, we would find that 8 of these 15 counties are in Alaska and Texas.) The box plots indicate there are many observations far above the median in each group, though we should anticipate that many observations will fall beyond the whiskers when using such a large data set.

[^46]: Answers will vary. The side-by-side box plots are especially useful for comparing centers and spreads, while the hollow histograms are more useful for seeing distribution shape, skew, and groups of anomalies.

-->

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="why-statistics.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="Correlation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/CrumpLab/statistics/blob/master/02-Describing_Data.Rmd",
"text": "Edit"
},
"download": ["statistics.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
